# Multivariate Datenanalyse

In diesem Kapitel werden unsere Ansätze vorgestellt, um multivariate Datenanalysen in R durchzuführen. Dabei müssen wir an verschiedenen Stellen auf andere Pakete zurück greifen, um die Analysen durchzuführen. Zwar beinhalten auch die bisher verwendeten Pakete tw. multivariate Analysemöglichkeiten, doch häufig ohne die Möglichkeit die Analysen auch zu gewichten.
Das Kaptiel umfasst die Korrelationsanalyse, Faktorenanalysen und Regressionsanalysen.

## Korrelationsmatrix

| Packet       | Funktion                | Verwendung                |
| :----------- | :---------------------- | :------------------------ |
| weights      | wtd.cor()               | Korrelationsmatrix |
| corrplot     | corrplot()              | Grafiken zu Korrelationsanalysen |

### `Wtd.cor()` {-}

Zur Berechnung der Korrelationsmatrix verwenden wir die `wtd.cor()` Funktion aus dem `weights` Paket. In getrennter tabellarischen Darstellung werden die Korrelationskoeffizienten, die Standardfehler, die t-Werte sowie die p-Werte ausgegeben.

```{}
library(weights)
```

```{r, include=F}
library(weights)
```

**Syntax:** 

```{}
# Ohne Pipe

wtd.cor(datensatz[c("Variable1", "variable2", "variable3")], weight = datensatz$gewicht)

# Mit Pipe
# Nicht gut zu handhaben!
```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Datensatz erstellen

ds <- allbus2018 %>% 
  select(im19:im21, id01, wghtpew)

#Berechnung der Korrelationsmatrix

corMatrix <- wtd.cor(ds[1:4], weight = ds$wghtpew)

corMatrix

```

### `Corrplot()` {-}

Für die grafische Aufbereitung der Korrelationsmatrix bietet das Paket `corrplot` mit der Funktion `corrplot` eine einfache, aber anschauliche Möglichkeit. Auch für diese Funktion stehen eine Reihe verschiedener Argumente zur Verfügung, mit denen die Grafik angepasst werden kann.

```{}
library(corrplot)
```

```{r, include=F}
library(corrplot)
```

**Syntax:** 

```{}
# Ohne Pipe

corrplot(korrelationsmatrix, method=number)

# Mit Pipe
# Nicht gut zu handhaben!
```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Grafik der Korrelationsmatrix erstellen
# Achtung! Die Funktionen corrplot() und corrplot.mixed laufen noch nicht 100% stabil

corrplot(corMatrix$correlation, p.mat = corMatrix$p.value, method = "circle", 
         tl.col = "black", addCoef.col = "black", cl.cex = .7, number.cex = .7, 
         insig = "pch")
```

## Explorative Faktoranalyse und Hauptkomponentenanalyse

Für die explorative Faktorenanalyse werdeb im folgenden zwei gängige Tests zur Prüfung der Voraussetzung (KMO, Bartlett), eine grafische Veranschaulichung zur Bestimmung der Anzahl der Faktoren (Screeplot), die Hauptkomponentenanalyse, die Faktorenanalyse sowie eine einfache Möglichkeit der grafischen Darstellung der Faktorenstruktur angeboten.

Die notwendigen Funktionen entnehmen wir dabei überwiegend aus dem `psych` Paket.

| Packet       | Funktion                | Verwendung                |
| :----------- | :---------------------- | :------------------------ |
| psych        | KMO()                   | Kaiser-Meyer-Olkin-Kriterium (MSA) |
| stats        | bartlett.test()         | Bartlett-Test |
| psych        | scree()                 | Scree-Test |
| psych        | principal()             | Hauptkomponentenanalyse |
| psych        | fa()                    | Faktoranalyse |
| psych        | fa_diagram()            | Grafik |

```{}
library(psych)
```
```{r, include=F}
library(psych)
```

### `KMO()` {-}

Das Kaiser-Meyer-Olkin-Kriterium berechnen wir mit der Funktion `KMO()`. Ausgegeben wird KMO (bzw. MSA) gesamt sowie einzeln für jedes Item.

Achtung! Ungewichtete Analyse.

**Syntax:** 

```{}
# Ohne Pipe

KMO(datensatz[c("Variable1", "variable2", "variable3")])

# Mit Pipe

datensatz %>% 
  select(variable1, variable2, variable3) %>% 
  KMO()

```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# KMO/MSA 

allbus2018 %>% 
  select(im19:im21, id01) %>% 
  KMO() 
  
```

### `Bartlett.test()` {-}

Den Bartlett Test führen wir mit der Funktion `bartlett.test` aus. Ausgegeben werden die Test Statistics, die Freiheitsgrade sowie der p-wert.

Achtung! Ungewichtete Analyse.

**Syntax:** 

```{}
# Ohne Pipe

bartlett.test(datensatz[c("Variable1", "variable2", "variable3")])

# Mit Pipe

datensatz %>% 
  select(variable1, variable2, variable3) %>% 
  bartlett.test()

```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Bartlett-Test 

allbus2018 %>% 
  select(im19:im21, id01) %>% 
  bartlett.test() 
  
```

### `Scree()` {-}

Einen Screeplot können wir mit der Funktion `scree()` abrufen. Im default wird dabei der Graph für Komponenten und Faktoren angezeigt und zur Lesehilfe eine horizontale Linie bei einem Eigenwert von 1.0 gezeichnet. 

Achtung! Ungewichtete Analyse.

**Syntax:** 

```{}
# Ohne Pipe

scree(datensatz[c("Variable1", "variable2", "variable3")])

# Mit Pipe

datensatz %>% 
  select(variable1, variable2, variable3) %>% 
  scree()

```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Scree-Plot

allbus2018 %>% 
  select(im19:im21, id01) %>% 
  scree() 
```

### `Principal()` {-}

Für eine Hauptkomponentenanalyse verwenden wir die Funktion `principal()`. Über die Argumente können verschiedene Spezifikationen wie beispielweise die Anzahl der zu extrahierenden Komponenten (`nfactors`) oder die Rotationsmethode (`rotate`) festgelegt werden. 

**Syntax:** 

```{}
# Ohne Pipe

principal(datensatz[c("Variable1", "variable2", "variable3")], 
          weight = datensatz$gewicht, nfactors = 1, rotate = "varimax",
          use = "pairwise", scores = T)

# Mit Pipe
# Nicht gut zu handhaben!
```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Datensatz erstellen

ds <- allbus2018 %>% 
  select(im19:im21, id01, wghtpew)

# Hauptkomponentenanalyse

pca <- principal(ds[1:4], weight = ds$wghtpew, nfactors = 2, rotate = "varimax",
          use = "pairwise")

pca

# Ladungen (Übersichtlicher)

print(pca$loadings, digits = 2, cutoff = .2)
```

### `Fa()` {-}

Eine explorative Faktorenanalyse führen wir über die Funktion `fa()` aus. Auch wie bei der vorherigen Funktionen können die Spezifikationen der Analyse über die Argumente festgelegt werden.

**Syntax:** 

```{}
# Ohne Pipe

fa(datensatz[c("Variable1", "variable2", "variable3")], 
   weight = datensatz$gewicht, nfactors = 1, rotate = "varimax", 
   use = "pairwise", scores = "regression")

# Mit Pipe
# Nicht gut zu handhaben!
```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Datensatz erstellen

ds <- allbus2018 %>% 
  select(im19:im21, id01, wghtpew)

# Hauptkomponentenanalyse

fa <- fa(ds[1:4], weight = ds$wghtpew, nfactors = 2, rotate = "varimax",
         use = "pairwise", scores = "regression")

fa

# Ladungen (Übersichtlicher)

print(fa$loadings, digits = 2, cutoff = .2)
```

### `Fa.diagram()` {-}

Eine einfache grafische Aufbereitung der durchgeführten Analysen (Hauptkomponenten- bzw. Faktorenanalysen) kann mit der Funktion `fa.diagram()` erstellt werden. Die folgenden Beispiele illustieren dies für die beiden vorherigen Analysen.

**Syntax:** 

```{}
# Ohne Pipe

fa.diagram(modell)

# Mit Pipe
# Nicht gut zu handhaben!
```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# PCA

fa.diagram(pca)

# FA

fa.diagram(fa)
```

## Konfirmatorische Faktorenanalyse

Wir wollen an dieser Stelle kurz auf Möglichkeiten konfirmatorischer Faktorenanalyse eingehen. Dies geschieht hier vor allem aus dem Grund, da über diesen kleinen Umweg eine gewichtete Realiabilitätsanalyse durchführbar ist. Eine andere Möglichkeit gewichtete Realiabilitätsanalysen zu berechnen ist uns derzeit nicht bekannt.

Zur Berechnung konfirmatorischen Faktorenanalyse verwenden wir die `cfa()` Funktion aus dem `lavaan`Paket, welches vor allem auch zur Strukturgleichungsmodellierung eignesetzt werden kann. Mit der `semPath()`Funktion (aus dem `semPlot` Paket) können wir die berechnete Faktorenanalyse grafisch aufbereiten.

| Packet       | Funktion                | Verwendung                |
| :----------- | :---------------------- | :------------------------ |
| lavaan       | cfa()                   | Konfirmatorische Faktorenanalyse |
| semPlot      | semPaths()              | Grafik |

```{}
library(lavaan)
library(semPlot)
```
```{r, include=F}
library(lavaan)
library(semPlot)
```

#### Modellspezifikation

Zur Berechnung der konfirmatorischen Faktorenanalyse müssen wir zunächst das Modell spezifizieren. Mit `faktorname`, `=~` und den folgenden Variablen legen wir die Faktorenstruktur fest. Für Details zur verwendeten Syntax kann sich auf den Hilfeseiten des `lavaan` Pakets weitergehend informiert werden.

```{r}
m1 <- "faktor =~ im19 + im20 + im21 + id01"
```

### `Cfa()` {-}

Mit der `cfa` Funktion berechnen wir unser Modell, welche wir unter `m1` spezifiziert haben. Wir speichern das Ergebnis als neues Objekt `cfa` ab und lassen uns die mit den Argumenten festgelegten Werte mit der `summary` Funktion ausgeben.

**Syntax:**

```{}
# ohne Pipe

cfa(model = modell, data = datensatz[c("Variable1", "variable2", "variable3")], sampling.weights = "gewicht",
    estimator = "MLR")
    
# Mit Pipe
# Nicht gut zu handhaben!
```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Datensatz erstellen

ds <- allbus2018 %>% 
  select(im19:im21, id01, wghtpew)

# Faktorenanalyse

cfa <- cfa(model = m1, data = ds, sampling.weights = "wghtpew", estimator = "MLR")

summary(cfa, fit.measures = T, standardized = T, rsquar = T)
```

### `semPaths()` {-}

Mit der `semPath` Funktion kann eine grafische Aufbereitung der Faktorenanalyse erstellt werden. Auch hier können über verschiedene Argumente der Funktion die Grafik den eigenen Wünschen angepasst werden.

**Syntax:**

```{}
# ohne Pipe

semPaths(object = cfa-Objekt, whatLabels = "std", layout = "tree", edge.color = "black")
    
# Mit Pipe
# Nicht gut zu handhaben!
```

**Beispielcode:**

```{r}
semPaths(cfa, whatLabels = "std", layout = "tree", edge.color = "black")
```

## Realiabilitätsanalyse

Mit der `reliability()` Funktion aus dem `semTools` Paket können wir nun im Anschluss an die berechnete konfirmatorische Faktorenanalyse die Realiabilitätsanalyse durchführen.

| Packet       | Funktion                | Verwendung                |
| :----------- | :---------------------- | :------------------------ |
| semTools       | reliability()         | Reliabilitätsmaße |

```{}
library(semTools)
```
```{r, include=F}
library(semTools)
```

### `reliability()` {-}

Zur Berechnung der Realiabilität setzen wir einfach die im Objekt `cfa` gespeicherten Ergebnisse der konfirmatorischen Faktorenanalyse in die `realiability()` Funktion ein.

**Syntax:**

```{}
# ohne Pipe

reliability(object = cfa-Objekt)
    
# Mit Pipe
# Nicht gut zu handhaben!
```

**Beispielcode:**

```{r}
reliability(cfa)
```

## Regressionsanalyse

Im abschließenden Kapitel zur multivarianten Datenanalyse behandeln wir noch Möglichkeiten der Regressionsanalysen, verschiedene Möglichkeiten zum Testen der Modellgüte sowie der grafischen Aufbereitung der Modelle.

| Packet       | Funktion                | Verwendung                |
| :----------- | :---------------------- | :------------------------ |
| stats        | lm()                    | lineare Regressionsmodelle |
| parameters   | model_parameters()      | Modellparameter ausgeben |
| stats        | anova()                 | F-Tests auf Gesamtsignifikanz |
| performance  | model_performance()     | Modellgüte |
| performance  | compare_performance()   | Vergleich der Modellgüte |
| texreg       | screenreg()             | tabellarischer Modellvergleich |
| sjplot       | plot_model()            | grafische Darstellungen von Regressionsmodellen |
| sjplot       | plot_models()           | grafischer Modellvergleich |
| sjplot       | check_model()           | 6 Grafiken zur Modellgüte |
| stats        | glm()                   | logistische Regressionsmodelle (u.A.) |

### `Lm()` {-}

Ein lineares Regressionsmodell können wir mit der `lm()` Funktion berechnen.

**Syntax:** 

```{}
# Ohne Pipe

lm(av ~ uv1 + uv2*uv3 + uv4 + uv1:uv4, datensatz, weights = gewicht)

# Mit Pipe
# Nicht gut zu handhaben!
```

Zur Veranschaulichung ist im Beispiel dazu die Datenaufbereitung aufgeführt, dessen Ergebnis im neuen Datensatz `ds` gespeichert wird. Anschließend wird das Nullmodell spezifiziert, mit dem unser Modell verglichen werden soll. Dann folgt die Spezifikation unserer Modelle, ohne (`model1`) und mit Interaktion (`model2.1 und model2.2`, unterschiedliche Schreibweise).

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Datensatz erstellen

ds <- allbus2018 %>% 
  select(im19, sex, age, educ, di08, wghtpew) %>% 
  # Z-Standardisierung Einkommen
   mutate(wMean = weighted_mean(di08, weights = wghtpew),
         wSD = weighted_sd(di08, weights = wghtpew),
         zEinkommen = (di08-wMean)/wSD) %>% 
  # Rekodierung Geschlecht und Bildung
  mutate(sex = rec(sex, rec = "1=1 [Mann]; 2=0 [Frau]"),
         bildung = rec(educ, rec = "1:2=1 [niedrig]; 3=2 [mittel]; 
                                    4:5=3 [hoch]; else=NA")) %>% 
  # Konvertierung in Faktor Geschlecht und Bildung
  to_label(sex, bildung) %>% 
  # Refrenzkategorie Bildung auf mittel
  ref_lvl(bildung, lvl = 2) %>% 
  # Löschung NA 
  drop_na()
  
# Nullmodell

nullmodel <- lm(im19 ~ 1, ds, weights = wghtpew)
summary(nullmodel)

# Modellierung erstes Modell

model1 <- lm(im19 ~ sex + age + bildung + zEinkommen, ds, weights = ds$wghtpew)
summary(model1)

# Prüfung auf Interaktioneffekt zwischen Geschlecht und zEinkommen

model2.1 <- lm(im19 ~ zEinkommen + sex + age + bildung + zEinkommen:sex, ds, 
               weights = ds$wghtpew)
summary(model2.1)

# ODER

model2.2 <- lm(im19 ~ zEinkommen*sex + age + bildung, ds, weights = ds$wghtpew)

summary(model2.2)
```

### `Model_parameters()` {-}

Mit der Funktion `model_parameters` können wir eine tabellarische Übersicht der Modellparameter erstellen. Mit der `plot` Funktion erstellen wir eine simple übersichtliche Grafik des Modells (Koeffizienten mit Konfidenzintervall).

```{r, include=F}
library("easystats")
```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Modellparameter in übersichtlicher Darstellung

m1Parameter <- model_parameters(model2.1)

m1Parameter

plot(m1Parameter)
```

### `Anova()` {-}

Um zu überprüfen, ob unsere Modelle eine Verbesserung der Anpassung an die Daten darstellen (im Vergleich zum Nullmodell oder unter einander) verwenden wir die `anvoa()` Funktion. 

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# F-Tests auf Gesamtsignifikanz (Anpassung an Daten)

anova(nullmodel, model1)

anova(model1, model2.1)
```

### `Model_performance()` {-}

Mit der `model_performance ()` Funktion lassen wir uns verschiedene Kennzahlen ausgeben, um die Modellgüte zu beurteilen.

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Modellgüte nach verschiedenen Kennzahlen 

model_performance(model2.1)

```

### `Compare_performance()` {-}

Die Kannzahlen der `model_performance()` Funktion könen wir uns mit der `compare_performance()` Funktion tabellarisch auch für mehrere Modell ausgeben lassen, sodass wir diese im direkten Vergleich betrachten können. Dieser berechnete Modellvergleich kann mit der `plot()` Funktion auch grafisch ausgegeben werden.

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Vergleich von Modellgüte

cperf <- compare_performance(model1, model2.1)

cperf

plot(cperf)
```

### `Screenreg()` {-}

Mit der `screenreg()` Funktion können wir uns mehrere vollständige Modelle mit verschiedenen Kennzahlen tabellarisch ausgeben lassen und direkt mit einander vergleichen.

```{}
library(texreg)
```
```{r, include=F}
library(texreg)
```

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Tabellarische Darstellung im Modellvergleich mit Kennzahlen der Modellgüte

screenreg(list(model1, model2.1), single.row = T)
```

### `Plot_model()` {-}

Die `plot_model()` Funktion bietet sowohl die Möglichkeit sich die Regressionkoeffizienten sowie die Konfidenzintervalle des Gesamtmodells grafisch ausgeben zu lassen als auch die Schätzwärte einzelner Prädiktoren. Die folgenden Beispiele illustieren dies anhand des berechneten `model2.1`.

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Regressionskoeffizienten

plot_model(model2.1)
```

```{r, echo=T, collapse=T, comment="#>"}
# Schätzwerte (predicted values)

plot_model(model2.1, type = "pred")
```

```{r, echo=T, collapse=T, comment="#>"}
# Gruppierung von Effekten

plot_model(model2.1, type = "pred", terms = c("zEinkommen","bildung"))
```

```{r, echo=T, collapse=T, comment="#>"}
# Interaktion

plot_model(model2.1, type = "int")
```

### `Plot_models()` {-}

Eine grafische Lösung des Modellvergleichs haben wir mit der `plot_models()` Funktion. Auch in dieser Darstellung werden Regressionskoeffizienten und Konfidenzintervalle ausgegeben.

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Vergleich Regressionskoeffizienten

plot_models(model1, model2.1)
```

### `Check_model()` {-}

Zur visuellen Überprüfung der Modellannahmen können wir uns mit `check_model()` sechs Grafiken ausgeben lassen (u. A. Homogenität der Varianz, Kollinearität).

**Beispielcode:**

```{r echo=T, message=FALSE, warning=FALSE, collapse=T, comment="#>"}
# Annahmenprüfung

check_model(model2.1)
```

### `Glm()` {-}

Für die Analyse logistischer Regressionsmodelle verwenden wir die `glm` Funktion. Diese erlaubt mit dem Argument `family=binomial` die Analyse von Regressionsmodellen mit einer dichotomen abhängigen Variable.

**Syntax:** 

```{}
# Ohne Pipe

glm(av ~ uv1 + uv2*uv3 + uv4 + uv1:uv4, family = binomial, datensatz, weights = gewicht)

# Mit Pipe
# Nicht gut zu handhaben!
```

Das Vorgehen im Beispiel entspricht dabei den Beispielen der Funktion `lm()` weiter oben. Lediglich die abhängige Variable wurde ausgetauscht - hier wird `pp26` als abhängige Variable verwendet. Diese Variable misst, ob die befragte Person sich schon einmal bei Versammlungen an öffentlichen Diskussionen beteiligt hat.

**Beispielcode:**

```{r, echo=T, collapse=T, comment="#>"}
# Datensatz erstellen

ds <- allbus2018 %>% 
  select(pp26, sex, age, educ, di08, wghtpew) %>% 
  # Rekodierung AV: Partizipation an öffent. Diskussion und Bildung
  mutate(partDisk = rec(pp26, rec = "1=1 [ja]; 0=0 [nein]; 
                                    else=NA")) %>% 
  # Z-Standardisierung Einkommen
   mutate(wMean = weighted_mean(di08, weights = wghtpew),
         wSD = weighted_sd(di08, weights = wghtpew),
         zEinkommen = (di08-wMean)/wSD) %>% 
  # Rekodierung Geschlecht und Bildung
  mutate(sex = rec(sex, rec = "1=1 [Mann]; 2=0 [Frau]"),
         bildung = rec(educ, rec = "1:2=1 [niedrig]; 3=2 [mittel]; 
                                    4:5=3 [hoch]; else=NA")) %>% 
  # Konvertierung in Faktor Geschlecht und Bildung
  to_label(sex, bildung) %>% 
  # Refrenzkategorie Bildung auf mittel
  ref_lvl(bildung, lvl = 2) %>% 
  # Löschung NA 
  drop_na()
  
# Nullmodell

nullmodel2 <- glm(pp26 ~ 1, family = binomial, ds, weights = wghtpew)
summary(nullmodel2)

# Modellierung erstes Modell

model3 <- glm(pp26 ~ sex + age + bildung + zEinkommen, family = binomial, ds, weights = ds$wghtpew)
summary(model3)

# Prüfung auf Interaktioneffekt zwischen Geschlecht und zEinkommen

model4.1 <- glm(pp26 ~ zEinkommen + sex + age + bildung + zEinkommen:sex, family = binomial, ds, 
               weights = ds$wghtpew)
summary(model4.1)

# ODER

model4.2 <- glm(pp26 ~ zEinkommen*sex + age + bildung, family = binomial, ds, weights = ds$wghtpew)

summary(model4.2)
```




