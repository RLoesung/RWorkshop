[["index.html", "R Workshop - Sozialwissenschaften Vorwort 0.1 Voraussetzungen 0.2 Warum R? 0.3 Was ist R? 0.4 Aller Einstieg ist schwer?! 0.5 Typographie 0.6 Weiterführende Literatur", " R Workshop - Sozialwissenschaften Yannick Diehl und Daniel Moosdorf 2022-05-11 Vorwort Dieser Workshop richtet sich insbesondere an Studierende der Sozialwissenschaften und möchte einen einfachen und verständlichen Einstieg in statistische Auswertungen mit R bieten. Ein besonderer Augenmerk liegt auf Anwender:innen die eine neue Heimat zur Lösung statistischer Aufgaben- und Problemstellungen suchen und folgend Kenntnisse im Umgang mit (u.a. kommerziellen) Statistik- und Analyse-Software besitzen (v.a. SPSS). Anwendungsziel der kommenden Analysetechniken sind insbesondere sozialwissenschaftliche Studien/Bevölkerungsumfragen mit wissenschaftlichen Erhebungsstandards, wenngleich auch “unstandartisierte” Datensätze mit den vorzustellenden Techniken verarbeitet werden können. Zudem soll den künftigen Anwender:innen eine umfassende Funktionsbibliothek an die Hand gegeben werden, welche eine komplexe Gewichtung von Studiendaten erlaubt. 0.1 Voraussetzungen Bitte installieren Sie hierfür die aktuelle Version von R unter: R Programm - Version 4.0.5 (17.05.2021) Darüber hinaus werden wir mit der integrierten Entwicklungsumgebung (IDE) RStudio arbeiten. Die aktuelle Version findet sich unter: RStudio Desktop Intergrierte Entwicklungsumgebungen wie RStudio vereinfachen den Arbeitprozess mit der Programmiersprache R ungemein, wenngleich auch schon im ersten Installationsschritt über das R Programm die gleichen Funktionsanwendungen ausführbar sind. So stellt RStudio vor allem eine Vereinfachung des Arbeitsprozesses dar, obgleich mit weitreichenden Implikationen bei der Nachvollziehbarkeit von Ablaufschritten und Anwendungsverfahren. 0.2 Warum R? R ist eine Programmiersprache, die speziell für statistische Berechnungen und Visualisierungen von Daten konzipiert ist. R ist eine der führenden Lösungen für die statistische Datenanalyse und kann auch für das Data Mining oder Predictive Analytics eingesetzt werden. Daten lassen sich mit der Sprache sehr flexibel auswerten und visualisieren. Sowohl wissenschaftliche Organisationen als auch große Unternehmen wie Oracle oder Microsoft verwenden R umfassend. R kann problemlos in alle Ebenen der Analyse und Präsentation von Daten integriert werden. Dank der Flexibilität von R ist der gleiche Code sowohl für kleinere Datenanalysen als auch für umfangreiches Data Mining im Big-Data-Umfeld geeignet. Die Plattformunabhängigkeit sorgt dafür, dass R in verschiedenste IT-Strukturen leicht integrierbar und universell nutzbar ist. Und zuletzt: Im Gegensatz zu anderen Lösungen für die Analyse und Visualisierung von Daten ist R Open Source. Es fallen keine Lizenzkosten an, auch nicht für den Großteil der verfügbaren Erweiterungspakete. 0.3 Was ist R? R wurde 1992 von Ross Ihaka und Robert Gentleman an der Universität Auckland entwickelt und wird als Open Source-Software unter der GNU General Public License durch die in Wien ansässige R Foundation for Statistical Computing verwaltet und verbreitet. R stammt direkt von der kommerziellen statistischen Programmiersprache S ab und während das Herz von R durch das R (Development) Core Team (aus dem auch die Stiftung hervorgegangen ist) weiterentwickelt wird, liegt die eigentliche Stärke von R in der Verfügbarkeit von Zusatzfunktionen, in Form sogenannter Packages (dt. Packete). So erweitern unabhängige Entwickler überall auf der Welt durch unzählige Packages mit unterschiedlichsten Ausrichtungen die Funktionsmöglichkeit von R, angefangen von der klassichen Regression bis zum maschinellen Lernen. Mehr als 12.000 dieser Funktionspakete, die geschätzt mehr als 220.000 Funktionen beinhalten, stehen über das Comprehensive R Archive Network (CRAN) und einige weitere Hubs zur kostenfreien Verfügung. Folglich gibt es praktisch kein statistisches Problem, dass noch nicht eine entsprechende Lösung in R gefunden hat und damit gebrauchsfertig heruntergeladen und nach eigenen Vorstellungen modifiziert werden kann. 0.4 Aller Einstieg ist schwer?! Wir werden uns primär mit R als Statistikumgebung und weniger als klassische Programmierumgebung beschäftigen, wenngleich kleinere Exkurse in die Fundamente dieser Sprache nicht vermieden werden können. Unser Anspruch bleibt dabei immer eine einfache, konsistente und übersichtliche Lösung zu geben, um dem freien und selbstbestimmten Lernen und Arbeiten aller Teilnehmenden Sorge zu tragen. Um diesem Anspruch gerecht werden zu können, werden wir uns vornehmlich in relativ “abgeschlossenen” Ökosystemen (Ecosystems) bewegen, also Sammlungen von Paketen, die aufeinander abgestimmt wurden. Das bekannteste Beispiel ist hierfür sicherlich das tidyverse, welches maßgebend von einem der großen R-Pioniere und RStudio chief scientist Hadley Wickham entwickelt wurde. Auf Grundlage des selbigen werden wir noch die Pakete von Daniel Lüdecke strengejacke und die beeindruckenden Modellaufbereitungen in easystats kennen lernen. So repräsentieren diese Pakete in vollem Umfang den “state-of-the-art” sozialwissenschaftlicher Datenanalysetechniken, obgleich der Lernprozess damit deutlich vereinfacht ist. Zudem werden alle genannten Pakete, vor allem das tidyverse, auch in nicht-universitären Kontexten weitreichend genutzt. 0.5 Typographie Die folgenden Kapitel bestehen zu einem großen Teil aus R Code und damit aus den entsprechenden chunks. Damit können sie leicht erkannt und für den eigenen Gebrauch in das persönliche R Script kopiert werden. Ein Beispiel: x &lt;- seq(from = 1, to = 100, by = 10) x Das Ergebnis lässt sich folgend in der Konsole ablesen. ## [1] 1 11 21 31 41 51 61 71 81 91 Damit ist x unser Input und ## [1] 1 11 21 31 41 51 61 71 81 91 unser Output nachdem wir x eine Zahlensequenz zwischen 1 und 100 in 10er Schritten zugewiesen haben. 0.6 Weiterführende Literatur Wir orientieren uns vor allem in den ersten beiden Kapiteln unseres Workshops an dem Kurs: Einführung in R von Andrew Ellis und Boris Mayer. Grundständige Literatur, die auch zu diesem Workshop passt, findet sich als freie Publikation von Garrett Grolemund und Hadley Wickham unter dem Titel R for Data Science. Zur Vertiefung bieten sich die Bücher Hands-On Programming with R von Garrett Grolemund und Advanced R von Hadley Wickham an. "],["rstudio.html", "1 RStudio 1.1 Benutzeroberfläche 1.2 Optionen 1.3 Konsole 1.4 Environment und History 1.5 Files 1.6 Packages 1.7 Help 1.8 Arbeiten mit RStudio", " 1 RStudio In einem ersten Schritt wollen wir uns RStudio genauer ansehen. Öffnen Sie nun bitte RStudio. 1.1 Benutzeroberfläche Sie sollten ungefähr die gleiche Benutzeroberfläche bzw. GUI (Graphical User Interface) vor sich sehen (standardmäßig weiß): 1.2 Optionen Wir empfehlen eindrücklich vor Beginn einer intensiven Nutzung mit RStudio die folgenden Punkte in den Optionen unter Preferencesbzw. Global Options zu deaktivieren. Restore .RData into workspace at startup (deaktivieren) Save workspace to .RData on exit (Never) Folgend müssen wir immer alle Daten und Variablen bei einem Neustart von RStudio neu laden. Belohnt werden wir hingegen durch einen frischen Workspace. Sofern Sie Interesse an einer Änderungen der grafischen Darstellung von RStudio haben (z.B. eine dunkle Farbgebung), sollten Sie sich unter dem Menüpunkt Appearance ausprobieren. 1.3 Konsole Die R Konsole ist praktisch das Herzstück der Benutzeroberfläche und ermöglicht geschriebenen Code direkt oder über das R Script interpretieren zu lassen. Das &gt; Zeichen ist die R Prompt (das Aufforderungszeichen). Die Konsole kann gerne auch als Übungsfeld für die ersten Eingaben genutzt werden, z.B. als Taschenrechner. 2+3 ## [1] 5 1.4 Environment und History Im Reiter Enironment finden wir die Funktion Global Environment (drop-down menu). In diesem Bereich werden alle Objekte, also Variablen und Datensätze, die wir zuvor angelegt haben, gespeichert. Auch selbstgeschriebene Funktionen werden hier hinterlegt. Unter dem Reiter History finden Sie alle Befehle, die Sie bisher ausgeführt haben. Mit einem Doppelklick werden diese automatisch in die Konsole kopiert. Damit können sie einfach modifiziert und/oder erneut ausgebenen werden. Tipp: Die History lässt sich auch direkt über die Testenbefehle cmd+ up auf macOS bzw. strg+ up bei Windows in der Konsole abrufen. 1.5 Files Unter dem Reiter Files können Sie auf Ihre Datenstruktur zugreifen und damit ein Arbeitsverzeichnis (working directory) festlegen (siehe Bild). Die Festlegung eines Arbeitsverzeichnis erleichtert in Folge das Einlesen von weiteren Datenobjekten (z.B. Datensätzen), sofern nicht in einem Project gearbeitet wird. Das Arbeitsverzeichnis muss in dem Ordner gesetzt werden, indem sich auch der Datensatz bzw. die einzulesenden Daten befinden. 1.6 Packages R stellt uns über base R schon eine ganze Reihe nützlicher Funktionen zur Verfügung. Diese bewegen sich jedoch auf sehr abstarktem Niveau und würden bei ausschließlicher Nutzung viele Analyseschritte sehr aufwendig machen. Folgend greifen wir auf die versprochenen Pakete bzw. Ökosysteme zurück, um unsere Funktionsbibliothek deutlich zu erweitern. Pakete lassen sich mit dem folgenden Befehl in der Konsole sehr leicht installieren. install.packages(&quot;tidyverse&quot;) Damit haben wir alle Pakete und Funktionen aus dem tidyverse installiert. Nun wollen wir noch strengejacke und easystats installieren. Die Pakete aus strengejacke können entweder einzeln über das CRAN installiert werden, oder im Bündel über Github. Wollen wir z.B. nur das Paket sjmisc aus strengejacke installieren verwenden wir den folgenden Befehl: install.packages(&quot;sjmisc&quot;) Sofern das ganze Bündel installiert werden soll, laden wir zunächst das Paket remotes, um Github als Downloadplattform anwählen zu können und dann strengejacke. install.packages(&quot;remotes&quot;) remotes::install_github(&quot;strengejacke/strengejacke&quot;) Damit wurde strengejacke erfolgreich installiert! Das Ökosystem easystats ist gegenwärtig noch in der Testphase und damit auch nur über Github zu laden. install.packages(&quot;remotes&quot;) remotes::install_github(&quot;easystats/easystats&quot;) Gratulation, damit haben wir die wichtigsten Pakete installiert! Nun müssen wir sie nur noch aktivieren. Dafür nutzen wir den Befehl library, um auf unsere Funktionsbibliothek zuzugreifen. library(tidyverse) library(strengejacke) library(&quot;easystats&quot;) Wichtig! Das Packetbündel easystats muss beim Aufruf in Anführungszeichen geschrieben werden. Als Alternative können wir Pakete auch über den Reiter Packages installieren und aktivieren (oben links im Fenster). Updates lassen sich über den Reiter Packages oder den folgenden Befehl machen: update.packages() bzw. update.packages(ask = F) 1.7 Help Selbst wenn man täglich mit R arbeitet, ist es (fast) unmöglich, sich alle Funktionen zu merken. Deshalb bietet R über den Reiter Help die Möglichkeit eine lexikale Darstellung aller Funktionen und Anwendungsmöglichkeiten zu bekommen. Leider sind viele der Einträge zu Beginn nicht ganz leicht verständlich. Nach einiger Zeit bieten sie aber eine zuverlässige Möglichkeit neue Funktionen zu erlernen und alte nachzuschlagen. Hat man eine Funktion im Kopf lässt sich diese leicht über das Suchfenster im Help Viewer suchen. Über die Konsole geht das natürlich auch. Der Befehl hier z.B. für den gewichteten Mittelwert: ?weighted_mean Hier muss nur die gesuchte Funktion hinter ein ? geschrieben werden. Will man herausfinden, welche Funktionen in einem Paket enthalten sind, ist der Reiter Packages zu öffnen. Über das Suchfenster das entsprechende Paket suchen und mit einem Klick öffnen. Anschließend wird man im Help Viewer über die möglichen Funktionen in einer Auswahl informiert. Viele Entwickler erstellen zudem eigene Websites für ihre Pakete. Hier einige Beispiele: Auf der Seite des tidyverse das gewünschte Paket aussuchen und dann über Reference eine Auswahlliste der Funktionen aufrufen. Beim Klick auf eine Funktion wird die dahinterliegende Vignette - Erklärung mit Beispielen - geöffnet. Die Pakete von strengejacke haben keine gebündelte Auswahl. Wir müssen uns also zuerst eines der Pakete aussuchen (sjmisc, sjlabelled, sjplot, sjstats) und dann nach diesem suchen. Bei strengejacke lassen sich alle Pakete über den folgenden Link öffnen: https://strengejacke.github.io/*Paketname*/, also z.B. https://strengejacke.github.io/sjmisc/ Bei den Paketen von easystats gilt das genauso. Erst ein Paket wählen (parameters, performance, effectsize, correlation, see) und dann öffnen über: https://easystats.github.io/*Paketname*/ Tipp: Um einen erster Eindruck über die Anwendungsmöglichkeiten und die Form der Pakete zu bekommen, lohnt sich zudem der Klick auf den Reiter Articles auf den Dokumentationsseiten der Pakete! Abschließend ist noch die FAQ-Seite Stackoverflow zu empfehlen, auf der schier zu jedem Problem schon einmal eine Frage gestellt und diese beantwortet wurde. Hierzu lohnt es sich das eigene Problem mit dem zusätzlichen Schlagwort Stackoverflow in eine Suchmaschine zu geben und die Einträge nach Lösungen zu durchsuchen. 1.8 Arbeiten mit RStudio Auf an die praktische Arbeit mit RStudio! 1.8.1 Projects Vor der eigentlichen Arbeit mit R und der Analyse von Daten ist es immer ratsam über die Erstellung eines Projekts nachzudenken. Über den Menüpunkt File + New Project + New Directory + New Project öffnet sich die entsprechende Auswahlmaske. Hier kann ein Projektname und der gewünschte Speicherort festgelegt werden. Im nächsten Schritt schieben wir die gewünschten Datensätze in den Projektordner, um einen ungehinderten Datenzugriff zu ermöglichen. Vorteile: Alle Files werden beim Start des Projekts, über den blauen Projektwürfel (.Rproj), wieder geöffnet. Es lassen sich beliebig viele Projekte gleichzeitig öffnen und zwischen diesen wechseln. Bei der Erstellung eines Projekts wird automatisch ein Arbeitsverzeichnis erstellt, auf das zurückgegriffen wird (Projektordner). Man muss sich also nicht mehr um das working directory bemühen und kann z.B. Daten- oder Skriptdateien direkt vom Projektordner aus aufrufen, ohne jedes Mal den vollständigen Pfad definieren zu müssen. 1.8.2 Konsole oder RScript? Es stehen dem Benutzer von RStudio wesentlich zwei Nutzungswege zur Verfügung: 1. Befehle direkt über die Konsole eintippen Die Eingabe über die Konsole ist dann empfehlenswert, wenn man schnell etwas ausprobieren möchte, oder ein Befehl wiederholt werden soll. Die Konsole wird auch bei unvollständiger Eingabe von Funktionen relevant. Im folgenden Beispiel wurde eine Klammer am Ende der Funktion vergessen. &gt; seq(1, 100, 5 + Nun muss entweder die fehlende Klammer zur Vervollständigung eingetippt, oder über Escder Befehl abgebrochen werden. Wird ein Befehl ungewollt ausgeführt, oder ist R abgestürzt? Hier kann ganz leicht über Session + Interrupt R bzw. das rote Stoppschild über der Konsole der Befehl abgebrochen, oder die ganze Sitzung über Session + Terminate R neu gestartet werden. 2. Befehle im Script speichern (vergleichbar mit Syntax aus SPSS) Zur Erstellung eines RScript öffnen wir über das Symbol mit dem weißen Blatt und grünem Kreuz (oben links) ein neues RScript (Tastenkürzel: cmd bzw. strg + up + N). Vorteile sind hier, wie auch in SPSS, die Möglichkeit zur übersichtlichen und nachvollziehbaren Arbeitsweise und das Speichern von Auswertungen. Wichtig! RScript-Datein werden beim Ausführen von oben nach unten gelesen. Wir können also Werte im Laufe eines Scripts immer wieder überschreiben und neu zuweisen. Wir probieren uns zu Beginn wieder an einer kurzen Rechnung aus. 2+3 Um die entsprechende Zeile auszuführen, klicken wir auf Run (Tastenkürzel: cmd bzw. strg + enter). ## [1] 5 Der Output erscheint wie gewohnt in der Konsole. Im nächsten Schritt definieren wir das Ergebnis unserer mathematischen Operation als Variable (Objekt), um es für folgende Anwendungen nutzen zu können. var1 &lt;- 2+3 Damit haben wir unsere gewünschte Variable (Objekt) mit der Bezeichnung var1 definiert. Wichtig ist für uns erstmal, dass wir unsere definierten Variablen im Environment sehen können. var1 wird folgend mit dem Wert 5 angezeigt. 1.8.3 Tab completion RStudio verfügt über eine weitere sehr hilfreiche Funktion: Tab completion. Während der Eingabe eines beliebigen Befehls erscheint über RStudio ein entsprechendes Menu mit Befehlsvorschlägen zur Vervollständigung. So erscheint z.B. bei der Eingabe von weighted_mean() eine ganze Reihe von Vorschlägen. Manuell wird auch über Tab das gleiche Menu aufgerufen. Wollen wir die erste Funktion übernehmen, drücken wir Enter zur Bestätigung. Zur Auswahl einer anderen Funktion einfach über die Pfeiltasten die richtige Funktion ansteuern und diese über Enter anwählen. Hat man eine Funktion eingegeben und drückt man innerhalb der Klammern Tab, erscheint eine Liste mit allen Argumenten dieser Funktion. Funktionsargumente definieren welche Daten einbezogen werden sollen und wie mit diesen umgegangen wird. x = steht z.B. für die eingehenden Daten und weights = für das anzuwendende Gewicht. Überschneiden sich zwei Funktionensbezeichungen zwischen zwei Paketen oder wissen wir, dass eine Funktion in einem Paket enthalten ist, können wir auch über den Paketnamen gefolgt von :: eine Funktionsliste erzeugen. 1.8.4 Nützliche Tastenbefehle (Shortcuts) Folgende Tastenbefehle erleichtern das Arbeiten mit R. Befehl Wirkung Wir haben schon folgende Befehle kennen gelernt: cmd bzw. strg + shift Vorherige Befehle in der Konsole anzeigen cmd bzw. strg + shift + N Neues Script erstellen cmd bzw. strg + Enter Eingabe ausführen cmd bzw. strg + S Speichert geöffnete RScript-Datei cmd bzw. strg + option + S Speichert alle geöffneten RScript-Datein Weitere nützliche Befehle: cmd bzw. strg + shift + Enter Gesamtes Script ausführen cmd bzw. strg + shift + R Kapitel im RScript definieren cmd bzw. strg + shift + C Kommentar im RScript control bzw. strg + L Konsole leeren cmd bzw. strg + shift + A Code restrukturieren Für folgende Kapitel: option bzw. alt + - Zuweisungspfeil (&lt;-) erzeugen cmd bzw. strg + shift + M %&lt;% erstellen Tipp: Um alle verfügbaren Tastenkürzel in RStudio sehen zu können, drücken Sie: option bzw. strg + shift + K. "],["programmiersprache-r.html", "2 Programmiersprache R 2.1 Variablen definieren 2.2 Funktionen aufrufen 2.3 Objekte und Datentypen 2.4 Pipe Operatoren", " 2 Programmiersprache R In diesem Kapitel wollen wir R als Programmierspache kennenlernen. 2.1 Variablen definieren In einem ersten Schritt wollen wir eine Rechnung (einen Wert) in einer Variable speichern. var1 &lt;- 2*4 Unsere Variable mit dem Namen var1 (immer links in der Zeile) wird über den Zuweisungspfeil &lt;- (Tastenkürzel: option + -) mit dem Ergebnis aus 2*4 (8) definiert. Zur Kontrolle können wir var1 mit den folgenden Befehlen aufrufen. var1 #&gt; [1] 8 Man kann auch gleich bei der Definition der Variablen die Zuweisung in Klammern schreiben und das Resultat wird gleichzeitig in der Konsole angezeigt. (var1 &lt;- 2*4) #&gt; [1] 8 Tipp: Sollten Sie aus anderen Programmiersprachen schon Kenntnisse mitbringen und = als Zuweisungsoperator kennen, empfehlen wir dennoch eindringlich mit &lt;- zu arbeiten. Funktionen in R arbeiten bei der Zuweisung von Argumenten mit dem Zuweisungsoperator =. Folglich ist die Verwendung von &lt;- nicht nur besser zu lesen, sie kann auch Fehler vorbeugen. 2.1.1 Variablennamen Eine Variable muss immer einen Namen haben. Sie darf aus Buchstaben, Zahlen und den Zeichen . und _ bestehen. Dennoch muss sie immer mit einem Buchstaben beginnen und darf keine Leerzeichen enthalten. Um lesbaren und verständlichen Code zu schreiben, gibt es ein paar Konventionen an die man sich halten sollte. Hier gibt es zwei gängige Möglichkeiten und eine ältere Form, um Variablen zu bennen. Die Wahl ist egal, solange man konsequent bei einer Schreibweise bleibt! 1. snake_case_variable Bei dieser Schreibform werden die einzelnen Worten in einer Variablenbezeichnung durch Unterstriche verbunden und alle Worte kleingeschrieben. 2. camelCaseVariable Hier wird nur das erste Wort kleingeschrieben und die folgenden mit dem ersten Buchstaben großgeschrieben. 3. variable.with.perdiods (alt) Die kleingeschriebenen Worte werden mit Punkten getrennt. # Gute Bezeichnungen efaKonstrukt1 efa_konstrukt_1 # Schlechte Bezeichnungen Efa.konstrukt_1 efaKonstrukt_1 # Unmöglich efa 1 2.2 Funktionen aufrufen “Everything that exists is an object. Everything that happens is a function call.” –John Chambers Objekte haben wir schon in ihrer einfachsten Form als Rechenergebnis in einer Variable kennen gelernt. Um kompliziertere Objekte verstehen zu können, wollen wir uns erst den Funktionen (function calls) in R zuwenden. Unsere Funktion sieht wie folgt aus (ein fiktionales Beispiel): functionName(arg1 = Daten, arg2 = option1, arg3) In einem ersten Schritt sehen wir uns an, welchen Namen die Funktion trägt. Unsere Funktion heißt functionName. Wir können leider nicht direkt aus dem Namen erschließen, welche Auswirkung unser function call haben wird. In so einem Fall würde ein Blick in Help (?functionName) sicher Abhilfe schaffen, wenngleich wir in unserem Beispiel leider keine Dokumentation nutzen können. So sehen wir uns in einem zweiten Schritt die Argumente unserer Funktion an. Wie wir sehen können, besitzt unsere Funktion drei Argumente: arg1, arg2 und arg3. Die Argumente werden mit spezifischen Werten über = bestückt. In unserem Beispiel benötigt das erste Argument Daten und das zweite Argument einen spezifischen Wert aus einer Auswahl an möglichen Werten - diese werden immer vom Entwickler der Funktion in der Dokumentation angegeben. Das dritte Argument wird als “default” abgerufen, also über eine Voreinstellung der Entwicklers geladen. Argumente die mit “default” arbeiten sind aber keinesfalls fest. Sie können immer auch durch andere Werte ersetzt werden. Argumente arbeiten immer dann mit “default,” wenn die Grundeinstellung des Arguments die häufigste Nutzungsform darstellt und man nicht bei jedem function call die Wertzuweisung von neuem schaffen möchte. Tipp: Wollen wir alle verfügbaren Argumente in einer Funktion sehen, drücken wir Tab. Wichtig! Eine Funktion kann beliebig viele Argumente besitzen. Um uns einer “großen” Funktion zu nähern, müssen wir zu Beginn einige “Grundfunktionen” kennenlernen. c() &gt; Combine: kreiert einen Vektor seq(from, to, by) &gt; Generiert eine Sequenz an Zahlen : &gt; Colon Operator: generiert eine reguläre Sequenz (Sequenz in Einerschritten) rep(x, times, each) &gt; Wiederholt x times: Sequenz wird n-mal wiederholt each: jedes Element wird n-mal wiederholt head(x, n = 6) &gt; Zeigt die n ersten Elemente von x an tail(x, n = 6) &gt; Zeigt die n letzten Elemente von x an print(x) &gt; Gibt Werte eines Objekts aus (vor allem bei großen Objekten wichtig) round(x, digits) &gt; Rundung von Zahlen z.B. # Daten erzeugen # Vektor erzeugen c(1, 2, 3, 4, 5) #&gt; [1] 1 2 3 4 5 # Sequenz erzeugen seq(from = 1, to = 10, by = 2) #&gt; [1] 1 3 5 7 9 # Reguläre Sequenz erzeugen 1:5 #&gt; [1] 1 2 3 4 5 # Wiederholt 2 ganze 3-mal in 5 Schleifen rep(x = 2, times = 5, each = 3) #&gt; [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 # Überblick über die erzeugten Daten # Vektor in var1 speichern var1 &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) # Ersten 6 Elemente in var1 head(x = var1, n = 6) #&gt; [1] 1 2 3 4 5 6 # Letzten 4 Elemente in var1 tail(x = var1, n = 4) #&gt; [1] 7 8 9 10 # Alle Elemente in var1 print(x = var1) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 # Daten transformieren var2 &lt;- c(1.222, 2.333, 3.444) # var2 wird auf eine Nachkommastelle gerundet round(x = var2, digits = 1) #&gt; [1] 1.2 2.3 3.4 Wir wollen uns die Variable var2 etwas genauer ansehen. var2 enthält durch das Aufrufen der Funktion c() eine Reihe von Zahlen (1.222 bis 3.444) mit drei Nachkommastellen. Diese Zahlen wollen wir mit der Funktion round() auf eine Nachkommastelle runden. Das Argument digits beschreibt damit die Rundungszahl nach dem Komma. digits = 1 löst eine Rundung der Nachkommastellen auf die erste Nachkommastelle aus. Der Wert im Argument digits kann damit theoretisch von 0 bis ∞ variieren. 2.2.1 Verschachtelung von Funktionen Zudem können wir beliebig viele Funktion ineinander verschachteln, d.h. wir können den Output einer Funktion einer anderen Funktion als Input übergeben. Wir bilden zuerst einen Vektor, runden die Zahlen und lassen uns dann nur die ersten drei Zahlen ausgeben. # Mehrere Funktionen hintereinander var1 &lt;- c(1.11, 1.22, 1.33, 1.44, 1.55) var1 &lt;- round(x = var1, digits = 1) head(x = var1, n = 3) #&gt; [1] 1.1 1.2 1.3 # jetzt in einer verschachtelten Funktion head(x = round(x = c(1.11, 1.22, 1.33, 1.44, 1.55), digits = 1), n = 3) #&gt; [1] 1.1 1.2 1.3 # kürzeste Form head(round(c(1.11, 1.22, 1.33, 1.44, 1.55), digits = 1), n = 3) #&gt; [1] 1.1 1.2 1.3 # Mit var1 als Dateninput head(round(var1, digits = 1), n = 3) #&gt; [1] 1.1 1.2 1.3 Die Funktionen werden immer in Reihenfolge von innen nach außen ausgeführt. In unserem Beispiel also erst c(), dann round() und dann head(). Jede Funktion gibt ihren Wert an die nächste Funktion weiter. Anmerkung: Die Funktion head() enthält zwei Argumente mit “default”-Werten: keepnums und addrownums. Beide bekommen automatisch (“default”) den Wert NULL und müssen damit nicht ausgeschrieben werden. Sie werden für unsere Anwendung auch nicht gebraucht und damit nicht angepasst. Vorteile von verschachtelten Funktionen: Es können unendlich viele Funktionen verschachtelt werden. Wir müssen Argumente nicht ausschreiben, solange sie eindeutig von der Funktion erkannt werden können. So gibt es in allen genutzten Funktionen mit x = nur eine Schnittstelle für die Dateneingabe. Weiterhin können wir so unseren Code in eine Kette von Befehlen verwandeln, die nur einen Output (ein Objekt) ausgibt. Die Objektstruktur wird damit übersichtlicher. Nachteil: Wenn wir mehrere Funktionen ineinander verschachteln, kann unser Code schnell unlesbar werden. Natürlich könnten wir die einzelnen Zwischenschritte speichern, wie im Beispiel weiter oben, aber dann definieren wir eine Menge Variablen, welche wir vielleicht gar nicht benötigen. Wir werden in Kapitel 2.4 einen neuen Operator kennen lernen, welcher eine sehr elegante Lösung für dieses Problem bietet. 2.3 Objekte und Datentypen In R kann alles als Objekt in Variablen gespeichert werden. Einzelne Werte / Mehrere Werte (z.B. ein Datensatz mit Rohdaten) Tabellen Statistische Modelle Ergebnisse statitischer Analysen Funktionen, etc. Anmerkung: Objekte sind nicht gleich Variablen, da Objekte nicht gespeichert werden müssen. Ein Objekt wird erst dann zur Variable, wenn es eine Bezeichnung über &lt;- erhält und damit gespeichert wird. Die Zahlenfolge aus c(1, 2, 3) stellt auch schon ein Objekt da. In R gibt es eine Vielzahl von verschiedenen Objekttypen. Die grundlegenden Objekttypen sind: 2.3.1 Vektoren (vector) Vektoren → ordinale/metrische Variablen numeric (Zahlen) character (Buchstaben) logical (Richtig oder Falsch) Beispiel # Numerischer Verktor (numeric vector) var1 &lt;- c(1, 2, 3, 4, 5) var1 #&gt; [1] 1 2 3 4 5 # Buchstaben Vektor (character vector) var2 &lt;- c(&quot;Peter&quot;, &quot;Yusuf&quot;, &quot;Sarah&quot;, &quot;Aayana&quot;) var2 #&gt; [1] &quot;Peter&quot; &quot;Yusuf&quot; &quot;Sarah&quot; &quot;Aayana&quot; # Logischer Vektor (logical vector) var3 &lt;- c(TRUE, FALSE, NA) var3 #&gt; [1] TRUE FALSE NA Tipp: TRUE bzw. FALSE können mit T bzw. F abgekürzt werden. Vektoren stellen die fundamentalen Datentypen dar. Alle weiteren Datentypen bauen auf diesen auf. Zudem müssen Vektoren aus denselben Elementen bestehen, d.h. wir können keine logical und character Elemente in einem Vektor mischen. Sie bilden damit die atomare Struktur in R. numeric vector: Die häufigste Datenform in R. Numerische Vektoren lassen sich zudem weiter unterteilen, in integer (ganze Zahlen) und double (reele Zahlen - Kommazahlen). Zahlen werden in R praktisch immer als double abgelegt (auch die ganzen Zahlen) und müssen somit nie für Berechungen gewandelt werden. character vector: Die Elemente dieses Typs bestehen aus Zeichen, welche von Anführungszeichen umgeben werden (entweder ’ oder ” ). Sie werden auch strings genannt. Anmerkung: Anführungszeichen dienen in R zur Kennzeichnung von nicht numerischen Werten. Wir müssen also alle natürlichen Worte in jedem Kontext in Anführungszeichen schreiben. logical vector: Die Elemente dieses Typs können nur 3 Werte annehmen:TRUE, FALSE oder NA. Logische Vektoren lassen sich auch numerisch übersetzen in TRUE = 1 und FALSE = 0, damit werden sie auch als integer abgelegt. Das wird vor allem bei der Datenselektion relevant. Anmerkung: NA steht für fehlende Werte. Vektoren haben folgend drei Eigenschaften: # Modus bzw. Struktur (mode) - Was ist es? typeof(var1) #&gt; [1] &quot;double&quot; # Länge - Wie viele Elemente? length(var1) #&gt; [1] 5 # Attribute (optional) - Zusätzliche Informationen (Metadaten) attributes(var1) # x wurden noch keine attribute zugeordnet #&gt; NULL # ------ Zusatz ------ # Objektbestimmung class(var1) #&gt; [1] &quot;numeric&quot; Nun wollen wir auf die einzelnen Elemente in den Vektoren zugreifen (indizieren). Wir können die einzelnen Elemente eines Vektor mit [] anwählen (subsetting). zahlenreihe &lt;- c(1, 2.5, 3, 4, 5.77, 6, 7) # Das erste Element zahlenreihe[1] #&gt; [1] 1 # das fünfte Element zahlenreihe[5] #&gt; [1] 5.77 # Das letzte Element zahlenreihe[length(zahlenreihe)] #&gt; [1] 7 # Mit - (Minus) können wir gezielt Elemente ausschließen zahlenreihe[-4] #&gt; [1] 1.00 2.50 3.00 5.77 6.00 7.00 # Wir können auch Sequenzen auswählen zahlenreihe[2:5] #&gt; [1] 2.50 3.00 4.00 5.77 # Wir können auch gezielt mehrere Elemente ausschließen oder auswählen zahlenreihe[-c(1, 4)] #&gt; [1] 2.50 3.00 5.77 6.00 7.00 zahlenreihe[c(1, 2, 5)] #&gt; [1] 1.00 2.50 5.77 # Das Gleiche funktioniert auch mit einem character vector buchstabenreihe &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;) buchstabenreihe[1] #&gt; [1] &quot;A&quot; 2.3.2 Faktoren (factor) Faktoren → nominale/ordinale Variablen nominale Variable Kategorien des Faktors = levels (kann Zahlen oder Buchstaben enthalten) Bisher haben wir numeric, character und logical Vektoren kennengelernt. Ein weiterer Objekttyp wird benötigt, um kategoriale Daten oder Gruppierungsvariablen darzustellen. Dieser Objekttyp wird factor genannt. Ein Faktor ist ein Vektor mit ganze Zahlen (integer), welcher eine Beschriftung für die einzelnen Fakttorstufen (levels) besitzt. Die Beschriftungen sind letztlich Attribute (attributes), die Informationen über die Faktorstufen geben. Ein Beispiel: # Geschlecht als character vector sex &lt;- c(&quot;Mann&quot;, &quot;Frau&quot;, &quot;Mann&quot;, &quot;Frau&quot;, &quot;Frau&quot;, &quot;Div&quot;) sex #&gt; [1] &quot;Mann&quot; &quot;Frau&quot; &quot;Mann&quot; &quot;Frau&quot; &quot;Frau&quot; &quot;Div&quot; # Modus (mode) typeof(sex) #&gt; [1] &quot;character&quot; # Attribute attributes(sex) #&gt; NULL Nun haben wir einen character vector mit Informationen über Geschlechter. In einem nächsten Schritt wollen wir diesen Vektor als Faktor definieren. # Geschlecht als Faktor sexf &lt;- factor(sex, levels = c(&quot;Mann&quot;, &quot;Frau&quot;, &quot;Div&quot;)) sexf #&gt; [1] Mann Frau Mann Frau Frau Div #&gt; Levels: Mann Frau Div # Geschlecht hat nun den Datentyp integer typeof(sexf) #&gt; [1] &quot;integer&quot; # und die Klasse &quot;factor&quot; class(sexf) #&gt; [1] &quot;factor&quot; # jetzt sind auch die Attribute definiert attributes(sexf) #&gt; $levels #&gt; [1] &quot;Mann&quot; &quot;Frau&quot; &quot;Div&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; Wir haben bei der Definition die levels explizit angegeben. Das hätten wir aber nicht machen müssen. R ordnet standardmäßig alle Faktorstufen alphabetisch zu. # Geschlecht als Faktor sexf2 &lt;- factor(sex) sexf2 #&gt; [1] Mann Frau Mann Frau Frau Div #&gt; Levels: Div Frau Mann # Datentyp typeof(sexf2) #&gt; [1] &quot;integer&quot; # Klasse class(sexf2) #&gt; [1] &quot;factor&quot; # Attribute attributes(sexf2) #&gt; $levels #&gt; [1] &quot;Div&quot; &quot;Frau&quot; &quot;Mann&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; Wir werden Faktoren später häufig bei der Modellierung benötigen z.B. bei Regressionsmodellen mit Dummyvariablen. Die erste Stufe eines Faktors wird von R automatisch als Referenzkategorie bestimmt, wenn wir den Faktor als Prädiktorvariable in ein Modell einbringen. Manchmal wollen wir jedoch eine andere Stufe als Referenzkategorie. In diesem Fall kann man die Reihenfolge der Faktorstufen ändern. Über relevel() kann direkt die Refrenzkategorie bestimmt werden. # Unsere Refrenzkategorie ist gegenwärtig &quot;Mann&quot; levels(sexf) #&gt; [1] &quot;Mann&quot; &quot;Frau&quot; &quot;Div&quot; # Wir ändern die Refrenkategorie folgend auf &quot;Frau&quot; sexf &lt;- relevel(sexf, ref = &quot;Frau&quot;) levels(sexf) #&gt; [1] &quot;Frau&quot; &quot;Mann&quot; &quot;Div&quot; Mit der Funktion factor() lassen sich alle Faktorstufen frei ordnen, solange wir im Befehl alle Faktorstufen benutzen. Die erste Stufe wird folglich zur Refrenzkategorie. # Unsere Refrenzkategorie ist gegenwärtig &quot;Frau&quot; levels(sexf) #&gt; [1] &quot;Frau&quot; &quot;Mann&quot; &quot;Div&quot; # Wir ändern die Refrenkategorie durch die neue Auflistung unserer level auf &quot;Mann&quot; sexf &lt;- factor(sexf, levels = c(&quot;Mann&quot;, &quot;Frau&quot;, &quot;Div&quot;)) levels(sexf) #&gt; [1] &quot;Mann&quot; &quot;Frau&quot; &quot;Div&quot; Durch die Festlegung einer Variable als Faktor wird diese automatisch dummykodiert und kann umstandslos in ein Modell einbezogen werden. Wir müssen nur die Refrenzkategorie im Blick behalten. 2.3.3 Datensatz (data frame) Datensatz (mehrere Zeilen und Spalten) Spalten (Vektoren und Faktoren) Zeilen (Fälle, z. B. Versuchspersonen) Nun kommen wir zu dem für uns wichtigsten Objekt in R, dem Datensatz. Ein Datensatz besteht aus Zeilen (rows) und Spalten (columns) gleicher Länge und entspricht einem Datensatz in SPSS. Die Spalten eines Datensatz sind lediglich Vektoren. Sie können damit numeric, character und logical sein, oder als factor auftreten. Numerische Variablen in einem Datensatz sollten demzufolge numerische Vektoren und kategoriale Variablen/Gruppierungsvariablen sollten Faktoren sein. Durch die Mischung von Datentypen innerhalb des Objekts “Datensatz” sprechen wir auch von einer rekursiven Struktur. Datensätze werden traditionell über die Funktion data.frame() definiert. Da wir das tidyverse nutzen, greifen wir auf eine weiterentwickelte Form zurück - tibbles oder tbl. tibbles werden über die Funktion tibble() definiert und erleichtern so die Arbeit mit dem Datensatz. Anmerkung: Der Vorteil liegt beim Einlesen von Datensätzen, da weniger Rücksicht auf die Datenstruktur genommen werden muss. Durch tibbles wird viel durch R automatisiert. Erstellung eines Datensatz. # Vektoren sex &lt;- factor(c(&quot;Mann&quot;, &quot;Frau&quot;, &quot;Mann&quot;, &quot;Mann&quot;, &quot;Frau&quot;, &quot;Mann&quot;)) alter &lt;- c(22, 45, 67, 87, 16, 56) # Datensatz datensatz &lt;- tibble(sex, alter) datensatz #&gt; # A tibble: 6 × 2 #&gt; sex alter #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Mann 22 #&gt; 2 Frau 45 #&gt; 3 Mann 67 #&gt; 4 Mann 87 #&gt; 5 Frau 16 #&gt; 6 Mann 56 Unser datensatz ist damit ein Datensatz mit zwei Variablen (sex und alter) und sechs Fällen (rows). Dieser wird uns entsprechend im Environment angezeigt. Ein Datensatz hat die Attribute names(), colnames() und rownames() - [names() und colnames() bedeuten dasselbe]. attributes(datensatz) #&gt; $class #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; #&gt; #&gt; $row.names #&gt; [1] 1 2 3 4 5 6 #&gt; #&gt; $names #&gt; [1] &quot;sex&quot; &quot;alter&quot; Wir können zudem sowohl die Länge des Spaltenvektors (Anzahl der Spalten) über ncol abfragen, wie auch die Länge des Zeilenvektors (Anzahl der Fälle) über nrow. ncol(datensatz) #&gt; [1] 2 nrow(datensatz) #&gt; [1] 6 2.3.3.1 Datensatz indizieren (subsetting) Ein Datensatz ist eine 2-dimensionale Struktur aus Spalten und Fällen, die entsprechend indiziert werden kann. Einzelne Spalten können über $ ausgewählt werden. Einzelne oder mehrere Elemente, ob Spalten oder Zeilen, können über [] ausgewählt werden. # Spaltenname zur Auswahl einer spezifischen Variable über $ datensatz$sex #&gt; [1] Mann Frau Mann Mann Frau Mann #&gt; Levels: Frau Mann # Spaltenname zur Auswahl einer spezifischen Variable über [] datensatz[&quot;sex&quot;] #&gt; # A tibble: 6 × 1 #&gt; sex #&gt; &lt;fct&gt; #&gt; 1 Mann #&gt; 2 Frau #&gt; 3 Mann #&gt; 4 Mann #&gt; 5 Frau #&gt; 6 Mann # Nach Position auswählen datensatz[2] #&gt; # A tibble: 6 × 1 #&gt; alter #&gt; &lt;dbl&gt; #&gt; 1 22 #&gt; 2 45 #&gt; 3 67 #&gt; 4 87 #&gt; 5 16 #&gt; 6 56 Wir können aber auch mehrer Variablen und sogar Zeilen (Fälle) auswählen. Sobald wir die Werte in [] durch ein Komma trennen, gibt der erste Wert die Zeilen und der zweite die Spalten an. Ohne Komma nur die Spalten. # Erste Spalte und erste Zeile datensatz[1, 1] #&gt; # A tibble: 1 × 1 #&gt; sex #&gt; &lt;fct&gt; #&gt; 1 Mann # Erster Fall über alle Spalten (Variablen) datensatz[1, ] #&gt; # A tibble: 1 × 2 #&gt; sex alter #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Mann 22 # Alle Zeilen in der ersten Spalte datensatz[, 1] #&gt; # A tibble: 6 × 1 #&gt; sex #&gt; &lt;fct&gt; #&gt; 1 Mann #&gt; 2 Frau #&gt; 3 Mann #&gt; 4 Mann #&gt; 5 Frau #&gt; 6 Mann # Wir können auch Sequenzen benutzen # Ersten drei Fälle über alle Spalten datensatz[1:3, ] #&gt; # A tibble: 3 × 2 #&gt; sex alter #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Mann 22 #&gt; 2 Frau 45 #&gt; 3 Mann 67 # Da die Spalten Vektoren sind, können wir diese genauso indizieren # Erster Fall im Vektor zu Geschlecht datensatz$sex[1] #&gt; [1] Mann #&gt; Levels: Frau Mann # Letzten drei Fälle in der Variable alter datensatz$alter[4:length(datensatz$alter)] #&gt; [1] 87 16 56 # Die Spalten sex und alter datensatz[c(&quot;sex&quot;, &quot;alter&quot;)] #&gt; # A tibble: 6 × 2 #&gt; sex alter #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Mann 22 #&gt; 2 Frau 45 #&gt; 3 Mann 67 #&gt; 4 Mann 87 #&gt; 5 Frau 16 #&gt; 6 Mann 56 2.3.4 Listen (list) Listen → in SPSS nicht vorhanden Kombination mehrerer Objekte Listen können beliebige Objekte enthalten, auch Objekte verschiedenen Typs. Im Unterschied zu Datensätzen können auch Objekte unterschiedlicher Länge gespeichert werden. Ein weiterer Datentyp ist list. Während Datensätze schon aus verschiedenen Vektoren bestehen können, lassen sich diese in Listen auch in verschiedenen Längen ablegen. Die meisten Objekte die wir im Verlauf unserer R Anwendung kennenlernen werden, sind damit Listen (z.B. die Ergebnisse eines Regressionsmodells werden als Liste gespeichert). Wir müssen aber nur mit ihnen umgehen können und sie verstehen. Wir werden sie praktisch nie selbst erstellen müssen. In einem ersten Schritt wollen wir dennoch mit der Funktion list() eine Liste definieren. So können wir schrittweise verstehen, welche Eigenschaften Listen besitzen. list1 &lt;- list(1:3, &quot;a&quot;, c(1.22, 2, 3.44, 4, 5), c(TRUE, FALSE, FALSE)) list1 #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] &quot;a&quot; #&gt; #&gt; [[3]] #&gt; [1] 1.22 2.00 3.44 4.00 5.00 #&gt; #&gt; [[4]] #&gt; [1] TRUE FALSE FALSE Wir haben mit der Variable list1 eine Liste erstellt, die als Elemente einen numeric Vektor mit einer Zahlenreihe, einen character Vektor mit der Länge 1 (L1), einen numericVektor mit Kommazahlen und einen logical Vektor speichert. Listen können wie Vektoren indiziert werden. # Erstes Element in der Liste (erster Vektor) list1[1] #&gt; [[1]] #&gt; [1] 1 2 3 # Zweites Element (zweiter Vektor) list1[2] #&gt; [[1]] #&gt; [1] &quot;a&quot; # Drittes Element (dritter Vektor) list1[3] #&gt; [[1]] #&gt; [1] 1.22 2.00 3.44 4.00 5.00 Häufig sind die Elemente in einer Liste als Variablen benannt und können entsprechend wie in einem Datensatz über $ abgerufen werden. list2 &lt;- list(var1 = c(1, 2, 3), var2 = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), var3 = c(TRUE, FALSE), var4 = seq(from = 1, to = 100, by = 5)) # Ganze Liste abrufen list2 #&gt; $var1 #&gt; [1] 1 2 3 #&gt; #&gt; $var2 #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; #&gt; #&gt; $var3 #&gt; [1] TRUE FALSE #&gt; #&gt; $var4 #&gt; [1] 1 6 11 16 21 26 31 36 41 46 51 56 61 66 71 76 81 86 91 96 # Aufruf der ersten Variable mit ihrem Namen var1 list2$var1 #&gt; [1] 1 2 3 # Aufruf der zweiten Variable mit ihrem Namen var2 list2$var2 #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; # Objektbestimmung typeof(list2) #&gt; [1] &quot;list&quot; Im Environment gibt sich folgende Datenstruktur. Wichtig! Elemente in Listen können unendlich “gestapelt” werden und folgend mit einer Verschränkung des [] Operator “entpackt” werden. list3 &lt;- list(list1 = list1, list2 = list(var1 = c(1, 2, 3, 4, 5), var2 = &quot;a&quot;), var1 = 1:100) # Liste1 aus Liste3 entpacken list3$list1 #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] &quot;a&quot; #&gt; #&gt; [[3]] #&gt; [1] 1.22 2.00 3.44 4.00 5.00 #&gt; #&gt; [[4]] #&gt; [1] TRUE FALSE FALSE # var1 aus liste1 in liste3 entpacken list3$list1[1] #&gt; [[1]] #&gt; [1] 1 2 3 # var2 aus liste2 in liste3 entpacken list3$list2$var2 #&gt; [1] &quot;a&quot; # Erster Wert aus var1 in list1 über list3 entpacken list3$list1[[1]][1] #&gt; [1] 1 2.3.5 Weitere Datentypen R kennt noch zwei weitere Datentypen (Matrizen und Arrays), die wir in diesem Kurs ausklammern werden. Sofern interesse besteht, verweisen wir auf das Buch von Hadley Wickham: Advanced R. 2.4 Pipe Operatoren In Kapitel 2.2.1 konnten wir schon sehen, dass es schnell unübersichtlich werden kann, wenn wir Funktionen ineinander verschachteln. Vor allem bei der Datenverarbeitung entsteht sehr schnell unübersichtlicher Code. Hierfür gibt es in R eine “ganz einfache” Lösung - Pipes. So lassen sich Sequenzen von Funktionen sehr elegant abbilden. Eine Pipe zeigt sich immer durch den %&gt;% Operator an. Um auf diesen zugreifen zu können, müssen wir eig. das Paket magrittr laden. Da aber die Packete des tidyverse den Operator automatisch laden, müssen wir zumindest in seiner einfachsten Form keinen zusätzlichen Aufwand betreiben. Nun wollen wir aber mit zwei weiteren Formen des Pipe-Operators arbeiten (%$% und %T&gt;%), die uns nur über das Laden von magrittr zur Verfügung gestellt werden. install.packages(&quot;magrittr&quot;) library(magrittr) %&gt;% Operator Tipp: Um schnell auf den Pipe Operator zugreifen zu können, bietet sich das Tastenkürzel cmd bzw. strg + up + M an. Um einen ersten Einstieg zu schaffen, greifen auf unser Beispiel aus Kapitel 2.2.1 zurück. Hier haben wir den Vektor c(1.11, 1.22, 1.33, 1.44, 1.55), welcher in var1 gespeichert wurde, gerundet. # Vektor speichern in var1 var1 &lt;- c(1.11, 1.22, 1.33, 1.44, 1.55) # var1 runden round(var1, digits = 1) #&gt; [1] 1.1 1.2 1.3 1.4 1.6 In diesem Stadium ist unser Code noch sehr übersichtlich. Wir können aber auch schon jetzt eine Pipe zu Demonstrationszwecken bilden. # Vektor speichern in var1 var1 &lt;- c(1.11, 1.22, 1.33, 1.44, 1.55) # var1 runden var1 %&gt;% round(digits = 1) #&gt; [1] 1.1 1.2 1.3 1.4 1.6 Der Effekt ist für unser Beispiel klein, aber die Idee ist klar. Wir schreiben mit der Pipe also Funktionen nicht mehr als f(x) sondern als x %&gt;% f() bzw. x %&gt;% f. Wir reihen also unsere Funktionen aneinander, wir verschachteln sie nicht mehr. Im nächsten Schritt wollen wir unseren gerundeten Vektor in eine weitere Funktion übergeben, dann wird auch der Effekt dieses Vorgehens ersichtlich. Wir rufen zusätzlich mit head() die ersten drei Elemente unseres Vektors auf. # Vektor speichern in var1 var1 &lt;- c(1.11, 1.22, 1.33, 1.44, 1.55) # var1 runden und die ersten drei Elemente abrufen head(round(var1, digits = 1), n = 3) #&gt; [1] 1.1 1.2 1.3 # var1 runden und die ersten drei Elemente abrufen - Pipe var1 %&gt;% round(digits = 1) %&gt;% head(n = 3) #&gt; [1] 1.1 1.2 1.3 Wie wir sehen können, wird der Vektor var1 durch die Funktionen “weitergegeben.” Tatsächlich gibt jede Funktion ihren Output, also ihr Ergebnis, an die nächste weiter. Im ersten Beispiel passiert das von “innen nach außen.” Damit wird es schnell unübersichtlich, zumal anstrengend zu schreiben. In der Pipe hingegen, erzeugen wir eine lineare Übergabe von Funktion zu Funktion. Der Ablauf der Pipe in Kürze: Der Vektor aus var1 wird also an die Funktion round() weitergegeben und in dieser auf eine Nachkommastelle gerundet. Damit haben wir an diesem Punkt den Output: c(1.1, 1.2, 1.3, 1.4, 1.6). Im nächsten Schritt wird dieser Output an head() übergeben. In head() rufen wir nur die ersten drei Elemente ab, also c(1.1, 1.2, 1.3). Vorteile: Unser Code ist lesbarer Wir müssen keine unnötigen Variablen definieren Wir können diesen Prozess auch mit dem Platzhalter-Operator . veranschaulichen. Dieser steht immer für den Output aus der letzten Funktion. # Vektor speichern in var1 var1 &lt;- c(1.11, 1.22, 1.33, 1.44, 1.55) # var1 runden und die ersten drei Elemente abrufen - Pipe var1 %&gt;% round(x = ., digits = 1) %&gt;% head(x = ., n = 3) #&gt; [1] 1.1 1.2 1.3 Ziemlich schick, nicht wahr? Der Platzhalter lässt sich aber auch an jeder anderen Stelle in der Funktion als Wertcontainer einsetzen. # Vektor speichern in var1 var1 &lt;- c(1.11, 1.22, 1.33, 1.44, 1.55) # var1 runden und die ersten drei Elemente abrufen - Pipe 1 %&gt;% round(var1, digits = .) %&gt;% head(x = ., n = 3) #&gt; [1] 1.1 1.2 1.3 Wichtig! Wollen wir ohne einen Platzhalter arbeiten, muss das erste Argument der nachfolgenden Funktion den Output der vorherigen aufnehmen können - i.d.R. x = Daten (Datensatz oder Variablen). In den meisten Fällen ist auch das Objekt, welches übergeben wird, gleichzeitig das erste Argument der nächsten Funktion (vor allem für die tidyverse-Funktionen), so dass wir diesen Platzhalter selten brauchen werden. Wir haben alle Funktionen in diesem Kurs nach diesem Kriterium ausgewählt, um eine möglichst reibungslose Einarbeitung zu ermöglichen. Anmerkung: Der Verkettung von Funktionen ist damit praktisch kein Limit gesetzt, außer ein paar Regeln an die man sich halten sollte. Pipes sollten nicht genutzt werden, wenn die Pipe länger als 10 Schritte wäre, mehrere Inputs oder Outputs benötigt werden, eine komplexe Objektstruktur das Ziel ist. %$% Operator Für Funktionen, die auf Variablenebene arbeiten und keinen Datensatz als Dateninput erlauben, gibt es den %$% Operator. Wichtig! Wir brauchen diesen Operator aber nur für ganz wenige Funktionen. Die meisten Funktionen die auf Variablenebene arbeiten, besitzen gleichzeitig auch als erstes Argument eine Datensatz-Schnittstelle - x = Datensatz. Sie greifen dann über das zweite Argument auf die Variablen in diesem Datensatz zu. Der %$% Operator ermöglicht letztlich, dass wir gezielt einzelne Variablen aus dem Datensatz in der nächsten Funktion anwählen können, auch wenn es keine Datensatz-Schnittstelle gibt. In unserem Beispiel benötigt die Funktion ts.plot, als Grafik für Zeitachsenmessungen, eine Variable als Input - x = Variable. Es darf also kein Datensatz eingespeist werden. Folglich brauchen wir den %$% Operator, um auf Variablenebene operieren zu können. # Vektoren in Datensatz speichern var1 &lt;- c(1, 1, 2, 2, 2, 3, 3, 3, 3) var2 &lt;- c(8, 9, 1, 1, 2, 3, 4, 5, 4) ds1 &lt;- tibble(var1, var2) # Mit dem %$% Operator ds1 %$% ts.plot(var1) %T&gt;% Operator Dieser Operator ermöglicht es eine Pipe auch bei Funktionen ohne “inhaltlichen” Output weiterzuführen. Grafiken haben letztlich keinen Output außer der Grafikausgabe und würden so eine Verkettung von Funktionen beenden. Wollen wir aber zu unserer Grafik noch einen “inhaltlichen” Output, brauchen wir den %T&gt;% Operator. Dieser wird hinter den letzten Output geschrieben, auf den wir uns beziehen wollen. Unser Wert wird damit auch an die übernächste Funktion “weitergegeben.” Es wird also immer auf den linken Wert neben dem %T&gt;% Operator zugegriffen und dieser an alle folgenden Funktionen “weitergegeben.” var1 &lt;- c(1.11, 1.22, 1.33, 1.44, 1.55) var1 %&gt;% round(digits = 2) %T&gt;% plot() %&gt;% head(n = 3) #&gt; [1] 1.11 1.22 1.33 So können wir uns einen Grafikoutput, wie auch die ersten drei Elemente von unserem gerundeten Vektor ausgeben lassen. Hervorangend! Jetzt können wir mit der Bearbeitung unseres Datensatzes beginnen. "],["datenverarbeitung.html", "3 Datenverarbeitung 3.1 Vorbereitung 3.2 Datensatz importieren 3.3 Erster Blick auf den Datensatz 3.4 Datensatz restrukturieren 3.5 Daten konvertieren 3.6 Daten beschriften 3.7 Daten manipulieren", " 3 Datenverarbeitung In diesem Kapitel werden wir in einem ersten Schritt das Einlesen von Datensätzen in den geläufigen Datenstrurkturen kennenlernen, um in einem zweiten Schritt die Daten nach unseren Vorstellungen zu modifizieren. Tipp: Zur Erstellung eigener Datensätze empfehlen wir das Kapitel Datensätze selber erstellen von Andrew Ellis und Boris Mayer. Wie Eingangs erwähnt, arbeiten wir in diesem Kurs mit den Ökosystemen tidyverse und strengejacke, um Daten umfänglich modifizieren zu können. Natürlich gibt es auch andere Möglichkeiten der Datenbearbeitung. Wir sind aber davon überzeugt, dass die “tidyverse-Methode,” an die sich auch strengejacke anschließt, eine sehr konsistente und eingängige Form des Arbeitens ermöglicht. Wie wir später noch sehen werden, erfordern viele Arten von statistischen Analysen und insbesondere Grafik-Funktionen einen Datensatz im long-Format. So muss mitunter erstaunlich viel Zeit für die Organisation von Daten für die weitere Analyse aufgewendet werden (diese Art von Arbeit wird oft als “data wrangling” bezeichnet). Sofern Sie einen Datensatz im wide-Format in ein long-Format transformieren wollen, empfehlen wir das Kapitel: Reshaping: tidyr von Andrew Ellis und Boris Mayer. 3.1 Vorbereitung Wir wollen mit dem Allbus-Datensatz (Allgemeine Bevölkerungsumfrage der Sozialwissenschaften) von 2018 arbeiten. Dieser lässt sich über GESIS unter: Allbus 2018 herunterladen. Der Allbus 2018 liegt gleich im long-Format vor. Anmerkung: Der Allbus 2018 ist eine standardisierte Bevölkerungsbefragung mit überproportionaler Repräsentanz von Befragten aus den neuen Bundesländern. Um diesem Umstand gerecht zu werden, müssen die Daten des Allbus gewichtet werden. Eine ideale Voraussetzung für diesen Kurs. Wir wollen unserem Anspruch einer zielgerichteten und forschungspraktischen Anwendung von R auch während der Bearbeitung des Allbus 2018, als Datengrundlage, gerecht werden. So greifen wir auf vergangene Forschungspublikationen zurück. Diese erlauben uns eine Orientierungslinie für kommende Beispiele zu ziehen. Folgend erstellen wir ein Projekt in RStudio (siehe 1.8.1). Sobald der Projektordner erstellt wurde, schieben wir unseren Datensatz in den Projektordner. Durch die Festlegung unseres Arbeitsverzeichnises im Projektordner, kann R direkt auf den Datensatz zugreifen. Der Reiter Files sollte entsprechend so aussehen: Abschließend erstellen wir ein RScript (siehe 1.8.2) und laden unsere Pakete: tidyverse, strengejacke und easystats (siehe 1.6). Voila! Nun können wir den Datensatz einlesen. 3.2 Datensatz importieren Durch das Packet sjlabelled aus dem Packet strengejacke können wir drei verschiedene Dateiformate einlesen. .sav &gt; SPSS .dta &gt; Stata .sas &gt; SAS Da wir den Allbus 2018 in .sav vorliegen haben, benutzen wir die folgende Funktion. # SPSS allbus2018 &lt;- read_spss(&quot;ALLB2018.sav&quot;) Wichtig! Mit der Funktion read_spss() über das Paket sjlabelled werden alle fehlenden Werte zu NA konvertiert. Sofern Sie mit fehlenden Werten arbeiten wollen, empfehlen wir gegenwärtig noch das Paket haven über die Funktion read_sav() und dem Argument user_na = TRUE zu nutzen. Hier ist aber zu beachten, dass alle Vektoren unter der Klasse labelled_spss gespeichert werden. Das kann zu Problemen mit Funktionen aus externen Paketen führen. Eine Lösung wäre vorher die betreffenden Vektoren händisch in atomare Strukturen zu konvertieren (z.B. durch unlabel() aus sjlabelled). Zudem müssen dann alle fehlenden Werte händisch als NA makiert werden (set_na() aus sjlabelled). Dazu aber später mehr! Sollten Ihre Daten in .dta oder .sas vorliegen, können Sie die folgenden Befehle nutzen. # Stata allbus2018 &lt;- read_stata(&quot;Datensatz.dta&quot;) # SAS allbus2018 &lt;- read_sas(&quot;Datensatz.sas&quot;) Anmerkung: Sollten Sie andere Dateiformate nutzen wollen, bieten sich zudem die Pakete haven, readxl und readr an. Die Funktion read_spss besitzt vier für uns relevante Argumente. Einen Überblick über die möglichen Argumente findet sich unter: ?read_spss. convert.factors = TRUE &gt; Alle Variablen die in SPSS als nominal oder ordinale Datentypen erfasst wurden, werden zu Faktoren konvertiert. Kann in manchen Analysen zu Problemen führen. So empfehlen wir das Argument auf FALSE zu setzen und die Konvertierungen, falls nötig, händisch vorzunehmen. atomic.to.fac = TRUE &gt; Alle Variablen mit beschrifteten Ausprägungsmerkmalen werden zu Faktoren konvertiert. Für uns ist dieses Argument offensichtlich unbrauchbar, da wir viele Items vom Likert-Typ im Allbus 2018 vorfinden und diese als pseudo-metrisch behandeln wollen. drop.labels = TRUE &gt; Alle Ausprägungsmerkmale ohne Fälle werden gelöscht. Eine nützliche Funktion, sofern wir nicht mit fehlenden Werten arbeiten möchten. Durch read_spss() über das Packet sjlabelled wurden ohnehin alle vormalig fehlenden Werte zu NA konvertiert. So können wir die überflüssigen Ausprägungsmerkmale einfach löschen. verbose = TRUE &gt; Es wird beim Verarbeiten der Daten ein Fortschrittsbalken eingeblendet. Nur bei großen Datensätzen relevant. tag.na = TRUE &gt; Alle fehlenden Werte werden als tagged_na markiert. Damit werden sie in allen Berechnungen zwar als NA einbezogen, der große Vorteil dieses Vorgehens liegt aber im Erhalt der ursprünglichen Kodierung jener fehlenden Werte. Wir können also wie aus SPSS bekannt, jederzeit auf diese mit der Funktion replace_na() zugreifen und sie als reguläre Werte in unsere Berechungen aufnehmen. Leider funktioniert dieses Argument gegenwärtig nur mit positiven Kodierungsmerkmalen (z.B. 98, 99), aber nicht mit negativen Ausprägungsformen (-7, -8). Wir hoffen auf eine baldige Anpassung und stehen mit dem Entwickler im Kontakt. Damit empfehlen wir das Argument dop.labels mit TRUE bzw. T zu aktivieren und convert.factors mit FALSE bzw. F zu deaktivieren, um die Kontrolle über die Daten zu behalten. allbus2018 &lt;- read_spss(&quot;ALLB2018.sav&quot;, drop.labels = T, convert.factors = F) # Noch schnell den Allbus zum tibble transformieren allbus2018 &lt;- tibble(allbus2018) Hervorragend! Damit haben wir erfolgreich unsere Daten in R importiert. Um bearbeitete Datensätze zu speichern, bietet sich der folgende Befehl an. write_spss(allbus2018, path = &quot;allbus2018&quot;) Die Datei wird automatisch in unserem Projektordner abgelegt. Wir können aber auch über das Argument path einen neuen Speicherort definieren. 3.3 Erster Blick auf den Datensatz Nachdem wir unseren Datensatz eingelesen haben, wollen wir uns zu Beginn einen Überblick über die vorhandenen Daten verschaffen. Mit view() können wir den ganzen Datensatz als zusätzliches Fenster öffnen. view(allbus2018) Über den Befehl view_df() wird uns eine HTML-Version unseres Datensatzes im Viewer angezeigt. view_df(allbus2018) Der große Vorteil der zweiten Abbildung liegt offensichtlich in der reduzierten Darstellung. So können wir über die Spalte ID ablesen, welchen Wert unsere Variablen im Spaltenvektor des Datensatzes innehaben. Wir können entsprechend Variablen über diesen indizieren. Zudem wird uns die Variablenbezeichnung über Name, die Variablenbeschriftung über Label und die Ausprägungsmerkmale bzw. Spannweite über Values, sowie die Merkmalsbeschriftung über Value Labels ausgegeben. Weiterhin können wir über unsere zuvor erlernten “Grundfunktionen” einen Ausschnitt des Datensatzes generieren. # Ersten 3 Fälle head(allbus2018, n = 3) # Letzten 5 Fälle tail(allbus2018, n = 5) #Ganzer Datensatz print(allbus2018) Die Anwendung unserer Grundfunktionen hat gegenwärtig noch den großen Nachteil, dass R versucht alle Variablen unseres Datensatzes abzubilden. Um das in den Griff zu bekommen, wollen wir uns in den folgenden Kapiteln mit der Datensatztransformation und dann Datenmanipulation beschäftigen. 3.4 Datensatz restrukturieren Anmerkung: Ab jetzt werden wir mit dem Allbus 2018 arbeiten. Um die folgenden Befehle nachvollziehen zu können, sollte Sie den Datensatz entsprechend eingelesen haben. Gemäß unseres forschungspraktischen Anspruchs stammen die kommenden Variablen aus einer Untersuchung politischen Wissens (Moosdorf 2020) in Bearbeitung des Allbus 2018. Kurze Erläuterung des Forschungsinhalts R verspricht eine enorme Flexibilität im Umgang mit Daten. Unmittelbar spürbar wird dieser Umstand in der Reorganisation von Datensätzen in neuen Objekten (gezielt aufgebaute eigene Datensätze). So wollen wir in einem ersten Schritt lernen, wie wir Datensätze grob restrukturieren und anschließend die Daten in einem neuen Datensatz speichern können. Unser Ziel ist es also einen eigenen, auf unsere Bedürfnisse zugeschnittenen, Datensatz zu erzeugen. Hierfür straten wir mit den folgenden Funktionen: Packet Funktion Verwendung dplyr select() Selektieren von Variablen dplyr filter() Filtern nach Fällen mit spezifischer Ausprägung dplyr arrange() Sortiert Datensatz nach bestimmter Variable Das dplyr Package stellt Funktionen für alle diese Aufgaben zur Verfügung (und noch viele mehr, wir betrachten hier nur eine kleine Auswahl). dplyr besteht sozusagen aus Verben (Funktionen) für all diese Operationen, und diese Funktionen können - je nach Bedarf - auf sehr elegante Weise zusammengesetzt werden. Wir sehen uns nun der Reihe nach die verschiedenen Funktionen und deren Verwendung an. Wir verwenden immer den %&gt;% Operator. Der Input Datensatz ist dabei immer als erstes Argument der Funktion zu verstehen. Select() Mit der Funktion select() lassen sich Variablen aus einem Datensatz gezielt auswählen. Syntax: # Ohne Pipe select(datensatz, variable1, variable2:variable3, -variable4) # Mit Pipe datensatz %&gt;% select(variable1, variable2:variable3, -variable4) Mit dem Befehl select() wurden aus dem Datensatz datensatz die Variablen variable1, variable2 bis variable3 ausgewählt. variable4 wurde weggelassen. Beispielcode: # Nur Einstellung zu Leistungsprinzip (im19) im neuen Datensatz ds speichern ds &lt;- allbus2018 %&gt;% select(im19) ds #&gt; # A tibble: 3,477 × 1 #&gt; im19 #&gt; &lt;dbl&gt; #&gt; 1 4 #&gt; 2 4 #&gt; 3 2 #&gt; 4 4 #&gt; 5 4 #&gt; 6 2 #&gt; 7 4 #&gt; 8 4 #&gt; 9 3 #&gt; 10 4 #&gt; # … with 3,467 more rows # Einstellungen zum Leistungsprinzip (im19) und Befürwortung von Ungleichheit (im20) # in ds speichern ds &lt;- allbus2018 %&gt;% select(im19, im20) ds #&gt; # A tibble: 3,477 × 2 #&gt; im19 im20 #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 2 #&gt; 2 4 4 #&gt; 3 2 3 #&gt; 4 4 2 #&gt; 5 4 4 #&gt; 6 2 2 #&gt; 7 4 4 #&gt; 8 4 3 #&gt; 9 3 2 #&gt; 10 4 3 #&gt; # … with 3,467 more rows # Befürwortung von Ungleichheit (im20) aus ds löschen ds &lt;- ds %&gt;% select(-im20) ds #&gt; # A tibble: 3,477 × 1 #&gt; im19 #&gt; &lt;dbl&gt; #&gt; 1 4 #&gt; 2 4 #&gt; 3 2 #&gt; 4 4 #&gt; 5 4 #&gt; 6 2 #&gt; 7 4 #&gt; 8 4 #&gt; 9 3 #&gt; 10 4 #&gt; # … with 3,467 more rows # Auswahl von Einstellung zum Leistungsprinzip (im19) # über Befürwortung von Ungleichheit (im20) # bis Einstellung zu sozialer Ungleichheit auf Makroebene (im21) und Mikroebene (id01) # in ds speichern ds &lt;- allbus2018 %&gt;% select(im19:im21, id01) ds #&gt; # A tibble: 3,477 × 4 #&gt; im19 im20 im21 id01 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 2 3 3 #&gt; 2 4 4 4 2 #&gt; 3 2 3 3 3 #&gt; 4 4 2 2 3 #&gt; 5 4 4 4 2 #&gt; 6 2 2 3 3 #&gt; 7 4 4 3 3 #&gt; 8 4 3 3 2 #&gt; 9 3 2 2 3 #&gt; 10 4 3 4 3 #&gt; # … with 3,467 more rows Wir können über select() auch die Reihenfolge unseres Spaltenvektors gezielt bestimmen. # Reheinfolge des Datensatz ds anpassen ds &lt;- allbus2018 %&gt;% select(id01, im19, im20, im21) ds #&gt; # A tibble: 3,477 × 4 #&gt; id01 im19 im20 im21 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 3 4 2 3 #&gt; 2 2 4 4 4 #&gt; 3 3 2 3 3 #&gt; 4 3 4 2 2 #&gt; 5 2 4 4 4 #&gt; 6 3 2 2 3 #&gt; 7 3 4 4 3 #&gt; 8 2 4 3 3 #&gt; 9 3 3 2 2 #&gt; 10 3 4 3 4 #&gt; # … with 3,467 more rows Anmerkung: Viele Funktionen des tidyverse, auch select(), besitzen zusätzlich Hilfsfunktionen und erweiterte Funktionsvarianten, um gezielt mehrere Variablen nach bestimmten Kriterien einschließen zu können. In Anbetracht der umfänglichen Möglichkeiten dieses Vorgehens, können wir leider in diesem Kurs nicht darauf eingehen. Sofern Sie bedarf für Ihre eigenen Arbeiten sehen, empfehlen wir in der Packetdokumentation nachzusehen unter: selection helpers und scoped verbs. Sofern Sie einzelne Variablen im Datensatz verschieben möchten, empfehlen wir die Funktion move_columns() aus dem Paket sjmisc. Filter() Mit der Funktion filter() können wir eine Auswahl von Fällen treffen, die alle eine bestimmte Ausprägung einer Variable besitzen. Tipp: Wir kennen diesen Befehl aus SPSS als select if. Um unsere Daten ausgiebig filtern zu können, müssen wir uns kurz mit den logischen Operatoren in R beschäftigen. &lt; Kleiner &lt;= Kleiner gleich &gt; Grösser &gt;= Grösser gleich == Gleich (testet auf Äquivalenz) != Ungleich x | y x ODER y x &amp; y x UND y xor(x, y) Exklusives ODER (entweder in x oder y, aber nicht in beiden) Die logischen Operatoren in R sind recht selbsterklärend und sollten bei eigener Anwendung recht schnell verstanden sein. Zusätzlich brauchen wir noch einen infix operator. %in% Merkmale in einem Vektor Syntax: # Ohne Pipe filter(datensatz, variable1 == 1) # Mit Pipe datensatz %&gt;% filter(variable1 == 1) Mit dem Befehl filter() wurden nur die Fälle des Datensatzes datensatz mit der Ausprägung 1 der Variable variable1 übernommen. Beispielcode: # Auswahl unserer bekannten Variablen gefiltert nach Personen mit NUR der # deutschen Staatsbürgerschaft ds &lt;- allbus2018 %&gt;% select(im19:im21, id01, german) %&gt;% filter(german == 1) ds #&gt; # A tibble: 3,218 × 5 #&gt; im19 im20 im21 id01 german #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 2 3 3 1 #&gt; 2 4 4 4 2 1 #&gt; 3 2 3 3 3 1 #&gt; 4 4 2 2 3 1 #&gt; 5 4 4 4 2 1 #&gt; 6 2 2 3 3 1 #&gt; 7 4 4 3 3 1 #&gt; 8 4 3 3 2 1 #&gt; 9 3 2 2 3 1 #&gt; 10 4 3 4 3 1 #&gt; # … with 3,208 more rows # Auswahl unserer bekannten Variablen gefiltert nach Personen mit der # deutschen Staatsbürgerschaft (auch mit weiteren) ds &lt;- allbus2018 %&gt;% select(im19:im21, id01, german) %&gt;% filter(german %in% 1:2) ds #&gt; # A tibble: 3,268 × 5 #&gt; im19 im20 im21 id01 german #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 2 3 3 1 #&gt; 2 4 4 4 2 1 #&gt; 3 2 3 3 3 1 #&gt; 4 4 2 2 3 1 #&gt; 5 4 4 4 2 1 #&gt; 6 2 2 3 3 1 #&gt; 7 4 4 3 3 1 #&gt; 8 4 3 3 2 1 #&gt; 9 3 2 2 3 1 #&gt; 10 4 3 4 3 1 #&gt; # … with 3,258 more rows # Auswahl unserer bekannten Variablen gefiltert nach Personen mit der # deutschen Staatsbürgerschaft (auch mit weiteren) und weiblichem Geschlecht ds &lt;- allbus2018 %&gt;% select(im19:im21, id01, german, sex) %&gt;% filter(german %in% c(1,2) &amp; sex == 2) ds #&gt; # A tibble: 1,610 × 6 #&gt; im19 im20 im21 id01 german sex #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 4 4 2 1 2 #&gt; 2 4 4 4 2 1 2 #&gt; 3 4 4 3 3 1 2 #&gt; 4 3 2 2 3 1 2 #&gt; 5 4 3 4 3 1 2 #&gt; 6 2 NA 4 2 1 2 #&gt; 7 4 2 3 2 1 2 #&gt; 8 2 3 4 2 1 2 #&gt; 9 2 2 4 NA 1 2 #&gt; 10 2 3 3 2 1 2 #&gt; # … with 1,600 more rows Arrange() Mit arrange() können wir Beobachtungen sortieren, entweder in aufsteigender oder in absteigender Reihenfolge. Syntax: # Aufsteigend # Ohne Pipe arrange(datensatz, variable1) # Mit Pipe datensatz %&gt;% arrange(variable1) # Absteigend # Ohne Pipe arrange(datensatz, desc(variable1)) # Mit Pipe datensatz %&gt;% arrange(desc(variable1)) Beispielcode: # Sortieren nach Alter aufsteigend ds &lt;- allbus2018 %&gt;% select(age, im19:im21, id01, german, sex) %&gt;% arrange(age) ds #&gt; # A tibble: 3,477 × 7 #&gt; age im19 im20 im21 id01 german sex #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 18 3 1 2 2 1 1 #&gt; 2 18 3 3 3 3 1 2 #&gt; 3 18 3 3 4 3 1 2 #&gt; 4 18 3 2 3 3 1 1 #&gt; 5 18 4 2 4 2 1 1 #&gt; 6 18 2 3 3 3 1 2 #&gt; 7 18 2 1 2 2 1 1 #&gt; 8 18 2 2 3 3 1 1 #&gt; 9 18 2 2 3 3 1 1 #&gt; 10 18 2 2 2 3 2 1 #&gt; # … with 3,467 more rows # Sortieren nach Alter absteigend ds &lt;- allbus2018 %&gt;% select(age, im19:im21, id01, german, sex) %&gt;% arrange(desc(age)) ds #&gt; # A tibble: 3,477 × 7 #&gt; age im19 im20 im21 id01 german sex #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 95 2 2 2 3 1 1 #&gt; 2 94 2 2 3 4 1 1 #&gt; 3 94 2 2 3 1 1 1 #&gt; 4 92 3 3 4 2 1 2 #&gt; 5 92 2 1 2 3 1 2 #&gt; 6 92 2 2 2 3 1 2 #&gt; 7 92 1 4 4 2 1 1 #&gt; 8 92 NA 2 2 2 1 2 #&gt; 9 92 2 2 3 3 1 1 #&gt; 10 92 2 2 4 3 1 1 #&gt; # … with 3,467 more rows 3.5 Daten konvertieren So wollen wir uns den Funktionen zuwenden, die Datentypen verändern. Anmerkung: Wir benutzen die Pakete sjmisc und sjlabelled zur Konvertierung von Datentypen, weil die Anwendung der base R Funktionen alle Beschriftungen (siehe 3.3) unseres Datensatzes entfernen würde. Zudem sind die base R Funktionen nicht für die Nutzung in einer Pipe optimiert. Packet Funktion Verwendung sjlabelled to_factor() Konvertiert Variable in Faktor mit numerischen levels sjlabelled to_label() Konvertiert Variable in Faktor mit beschrifteten levels sjlabelled to_numeric() Konvertiert Variable in numerischen Vektor sjlabelled to_character() Konvertiert Variable in character Vektor sjmisc numeric_to_factor() Konvertiert Variablen mit n Ausprägungsmerkmalen zu Faktor sjlabelled unlabel() Konvertiert labelled class in atomare Struktur sjmisc ref_lvl() Setzt Referenzkategorie To_factor() Konvertiert einen Vektor in einen Faktor mit numerischen levels - äquivalent zur Funktion factor(). Sinnvoll bei Variablen mit mehr als zwei Ausprägungsmerkmalen. Syntax: # Ohne Pipe to_factor(datensatz$variable1, datensatz$variable2) # Mit Pipe datensatz %&gt;% to_factor(variable1, variable2) Beispielcode: # Geschlecht unbearbeitet class(allbus2018$sex) #&gt; [1] &quot;numeric&quot; # Geschlecht in Faktor mit numerischen levels konvertieren ds &lt;- allbus2018 %&gt;% select(sex) %&gt;% to_factor(sex) attributes(ds$sex) #&gt; $levels #&gt; [1] &quot;1&quot; &quot;2&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; #&gt; #&gt; $labels #&gt; MANN FRAU #&gt; 1 2 #&gt; #&gt; $label #&gt; [1] &quot;GESCHLECHT, BEFRAGTE(R)&quot; To_label() Konvertiert einen Vektor in einen Faktor mit beschrifteten levels. Sinvoll bei binären Ausprägungsmerkmalen. Syntax: # Ohne Pipe to_label(datensatz$variable1, datensatz$variable2) # Mit Pipe datensatz %&gt;% to_label(variable1, variable2) Beispielcode: # Geschlecht in Faktor mit beschrifteten levels konvertieren ds &lt;- allbus2018 %&gt;% select(sex) %&gt;% to_label(sex) attributes(ds$sex) #&gt; $levels #&gt; [1] &quot;MANN&quot; &quot;FRAU&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; #&gt; #&gt; $label #&gt; [1] &quot;GESCHLECHT, BEFRAGTE(R)&quot; To_numeric() Konvertiert einen Faktor oder character Vektor in einen numerischen Vektor. Syntax: # Ohne Pipe to_numeric(datensatz$variable1, datensatz$variable2) # Mit Pipe datensatz %&gt;% to_numeric(variable1, variable2) Beispielcode: # Geschlecht in Faktor ds &lt;- allbus2018 %&gt;% select(sex) %&gt;% to_factor(sex) # Geschlecht wieder in numerischen Vektor konvertieren ds &lt;- ds %&gt;% select(sex) %&gt;% to_numeric(sex) class(ds$sex) #&gt; [1] &quot;numeric&quot; To_character() Konvertiert einen numerischen Vektor oder Faktor in einen character Vektor. Syntax: # Ohne Pipe to_character(datensatz$variable1, datensatz$variable2) # Mit Pipe datensatz %&gt;% to_character(variable1, variable2) Beispielcode: # Geschlecht in character Vektor konvertieren ds &lt;- allbus2018 %&gt;% select(sex) %&gt;% to_character(sex) class(ds$sex) #&gt; [1] &quot;character&quot; # Folge: Alle numerischen Ausprägungsmerkmale wurden in ihre Beschriftung umgewandelt str(ds$sex) #&gt; chr [1:3477] &quot;MANN&quot; &quot;FRAU&quot; &quot;MANN&quot; &quot;MANN&quot; &quot;FRAU&quot; &quot;MANN&quot; &quot;FRAU&quot; &quot;MANN&quot; ... #&gt; - attr(*, &quot;label&quot;)= chr &quot;GESCHLECHT, BEFRAGTE(R)&quot; Numeric_to_factor() Diese Funktion ermöglicht es uns alle Variablen eines Datensatzes anzuwählen und diese zu einem Faktor zu konvertieren. Wir müssen lediglich eine Maximalgrenze (n) als gewünschten Grenzwert zur Umwandlung angeben. Hat eine Variable weniger oder gleich viele Ausprägungsmerkmale wird sie konvertiert. Beispielcode: # Datensatz als Ausgangspunkt ds &lt;- allbus2018 %&gt;% select(im19:im21, id01) class(ds$im19) #&gt; [1] &quot;numeric&quot; # Alle Variablen haben nur bis zu vier Ausprägungsmerkmale # Wir können sie entsprechend zu Faktoren konvertieren # ACHTUNG: Diese Funktion ändert den Datentyp unseres Datensatzes! # Wir geben also zusätzliche die Funktion tibble() an ds &lt;- ds %&gt;% numeric_to_factor(n = 4) %&gt;% tibble() class(ds$im19) #&gt; [1] &quot;factor&quot; Wichtig! Die Funktion numeric_to_factor() hat die gleiche Wirkung wie die Funktion to_label(). Wir sparen uns lediglich den Aufwand jede Variable einzeln anzuwählen. Unlabel() Mit dieser Funktion können wir Variablen konvertieren, die als labelled class gespeichert wurden. Durch das Einlesen unseres Datensatzes über read_spss() werden wir diesen Befehl praktisch nie brauchen. Sollte wir den Datensatz aber über haven mit der Funktion read_sav() laden, ist es sinnvoll alle Variablen nach der Bearbeitung in eine atomare Struktur umzuwandeln - damit lassen sich spätere Probleme mit zusätzlichen Paketen vorbeugen. Beispielcode: # Datensatz laden und vorbereiten library(haven) #&gt; #&gt; Attache Paket: &#39;haven&#39; #&gt; Die folgenden Objekte sind maskiert von &#39;package:sjlabelled&#39;: #&gt; #&gt; as_factor, read_sas, read_spss, read_stata, write_sas, zap_labels allbus2018_haven &lt;- read_sav(&quot;ALLB2018.sav&quot;) ds &lt;- allbus2018_haven %&gt;% select(age, im19:im21, id01, german, sex) # Beispiel class(ds$age) #&gt; [1] &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; &quot;double&quot; # Wir konvertieren alle Variablen # ACHTUNG: Diese Funktion ändert den Datentyp unseres Datensatzes! # Wir geben also zusätzliche die Funktion tibble() an ds &lt;- ds %&gt;% unlabel() %&gt;% tibble() class(ds$age) #&gt; [1] &quot;numeric&quot; Ref_lvl() Die Verwendung der Funktion rev_lvl() aus sjmisc hat den großen Vorteil, dass unser Faktor im Gegensatz zur Funktion relevel() rekodiert wird und damit alle Beschriftungen auch bei numerischen levels richtig zugewiesen werden können. Syntax: # Ohne Pipe rev_lvl(datensatz, variable1, lvl = 3) # Mit Pipe datensatz %&gt;% ref_lvl(variable1, lvl = 3) Wir ändern mit der Funktion ref_lvl() die Referenzkategorie von variable1 auf das Ausprägungsmerkmal 3. Beispielcode: # Geschlecht als Faktor ds &lt;- allbus2018 %&gt;% select(sex) %&gt;% to_factor(sex) # Unsere Refrenzkategorie ist gegenwärtig &quot;Mann&quot; attributes(ds$sex) #&gt; $levels #&gt; [1] &quot;1&quot; &quot;2&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; #&gt; #&gt; $labels #&gt; MANN FRAU #&gt; 1 2 #&gt; #&gt; $label #&gt; [1] &quot;GESCHLECHT, BEFRAGTE(R)&quot; # Wir ändern die Refrenkategorie folgend auf &quot;Frau&quot; ds &lt;- ds %&gt;% ref_lvl(sex, lvl = 2) attributes(ds$sex) #&gt; $levels #&gt; [1] &quot;1&quot; &quot;2&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; #&gt; #&gt; $label #&gt; [1] &quot;GESCHLECHT, BEFRAGTE(R)&quot; #&gt; #&gt; $labels #&gt; FRAU MANN #&gt; 1 2 3.6 Daten beschriften Grundständig kennt R keine beschrifteten Daten. Erst durch den zunehmenden Einfluss sozialwisschenschaftlicher Anwendungsbedürfnisse und der bevorzugten Datenformate (.sav, .dta, .sas) halten Datenbeschriftungen auch in die R-Umgebung Einzug. Packet Funktion Verwendung sjlabelled get_label() Ruft Variablenbeschriftung ab sjlabelled get_labels() Ruft Beschriftung von Ausprägungsmerkmalen ab sjlabelled remove_label() Entfernt Variablenbeschriftung sjlabelled remove_labels() Entfernt Beschriftung von Ausprägungsmerkmalen sjlabelled remove_all_labels() Entfernt alle Beschriftungen sjlabelled var_labels() Variable neubeschriften sjlabelled val_labels() Ausprägungsmerkmale neubeschriften sjlabelled drop_labels() Alle “unbesetzten” Ausprägungsmerkmale löschen *Die Funktion drop_labels() ist äquivalent zum Argument drop.labels = T in der Funktion read_spss(). Sofern Sie ihre Daten mit read_sav() eingelesen haben, können Sie diesen Befehl nach der Bearbeitung ihres Datensatzes zur Löschung überflüssiger Merkmalsausprägungen nutzen. Get_label() Mit der Funktion get_label() können wir Variablenbeschriftungen abrufen. Syntax: # Ohne Pipe get_label(datensatz, variable1) # Mit Pipe datensatz %&gt;% get_label(variable1) Beispielcode: # Variablenbeschriftung Leistungsprinzip (im19) # und Befürwortung von Ungleichheit (im20) allbus2018 %&gt;% get_label(im19, im20) #&gt; im19 #&gt; &quot;EINKOMMENSDIFFERENZ ERHOEHT MOTIVATION&quot; #&gt; im20 #&gt; &quot;RANGUNTERSCHIEDE SIND AKZEPTABEL&quot; Get_labels() Die Funktion get_labels() erlaubt uns das Abrufen der Beschriftung von Merkmalsausprägungen. Syntax: # Ohne Pipe get_labels(datensatz, variable1) # Nicht mit Pipe möglich! Beispielcode: # Beschriftung der Ausprägungsmerkmale - Leistungsprinzip (im19) get_labels(allbus2018$im19) #&gt; [1] &quot;STIMME VOLL ZU&quot; &quot;STIMME EHER ZU&quot; &quot;STIMME EHER NICHT ZU&quot; #&gt; [4] &quot;STIMME GAR NICHT ZU&quot; Remove_label() Über die Funktion remove_label() lassen sich gezielt Variablenbeschriftungen von einzelnen Variablen oder allen Variablen im Datensatz entfernen. Syntax: # Einzelne Variable # Ohne Pipe remove_label(datensatz, variable1) # Mit Pipe datensatz %&gt;% remove_label(variable1) # --------- # Ganzer Datensatz # Ohne Pipe remove_label(datensatz) # Mit Pipe datensatz %&gt;% remove_label() Beispielcode: # Löschung der Variablenbeschriftung - Geschlecht ds &lt;- allbus2018 %&gt;% select(sex) %&gt;% remove_label(sex) # Variablenbeschriftung wurde gelöscht ds %&gt;% get_label(sex) #&gt; sex #&gt; &quot;&quot; # Löschung aller Variablenbeschriftungen im Datensatz ds &lt;- allbus2018 %&gt;% select(im19, im20) %&gt;% remove_label() # Variablenbeschriftungen wurden gelöscht ds %&gt;% get_label(im19, im20) #&gt; im19 im20 #&gt; &quot;&quot; &quot;&quot; Remove_labels() Die Funktion remove_labels() erlaubt es uns gezielt Beschriftungen der Ausprägungsmerkmale von einzelnen Variablen oder allen Variablen im Datensatz zu löschen. Syntax: # Ohne Pipe remove_labels(datensatz, variable1) # Mit Pipe datensatz %&gt;% remove_labels(variable1) # --------- # Ganzer Datensatz # Ohne Pipe remove_labels(datensatz) # Mit Pipe datensatz %&gt;% remove_labels() Beispielcode: # Löschung der Variablenbeschriftung - Geschlecht ds &lt;- allbus2018 %&gt;% select(im19) %&gt;% remove_labels(im19, labels = c(1, 2, 3, 4)) # Variablenbeschriftung wurde gelöscht get_labels(ds$im19) #&gt; NULL # Löschung aller Variablenbeschriftungen im Datensatz ds &lt;- allbus2018 %&gt;% select(im19, im20) %&gt;% remove_labels(labels = 0:99) # Variablenbeschriftungen wurden gelöscht get_labels(ds$im19) #&gt; NULL get_labels(ds$im20) #&gt; NULL Remove_all_labels() Wir können mit der Funktion remove_all_labels() alle (Variablenbeschriftungen und Beschriftungen von Merkmalsausprägungen) löschen. Syntax: # Ohne Pipe remove_all_labels(datensatz, variable1) # Mit Pipe datensatz %&gt;% remove_all_labels(variable1) Beispielcode: # Löschung aller Beschriftungen in einem Datensatz ds &lt;- allbus2018 %&gt;% select(im19, im20) %&gt;% remove_all_labels() # Variablenbeschriftungen wurden gelöscht ds %&gt;% get_label(im19, im20) #&gt; im19 im20 #&gt; &quot;&quot; &quot;&quot; # Beschriftung von Ausprägungsmerkmalen wurden gelöscht get_labels(ds$im19) #&gt; NULL get_labels(ds$im20) #&gt; NULL Var_labels() Mit der Funktion var_labels() können wir von einer oder mehreren Variablen die Variablenbeschriftung neu definieren. Syntax: # Ohne Pipe var_labels(datensatz, variable1 = &quot;Variablenbeschriftung&quot;) # Mit Pipe datensatz %&gt;% var_labels(variable1 = &quot;Variablenbeschriftung&quot;) Beispielcode: # Variablenbeschriftung neu definieren ds &lt;- ds %&gt;% var_labels(im19 = &quot;Leistungsprinzip&quot;, im20 = &quot;Befürwortung von Ungleichheit&quot;) # Variablenbeschriftungen abrufen ds %&gt;% get_label(im19, im20) #&gt; im19 im20 #&gt; &quot;Leistungsprinzip&quot; &quot;Befürwortung von Ungleichheit&quot; Val_labels() Die Funktion val_labels() erlaubt es uns Ausprägungsmerkmale für eine oder mehrere Variablen neu zu definieren. Syntax: # Ohne Pipe var_labels(datensatz, variable1 = c(&quot;1&quot;, &quot;2&quot;)) # Mit Pipe datensatz %&gt;% var_labels(variable1 = c(&quot;1&quot;, &quot;2&quot;), variable2 = c(&quot;Hallo&quot;, &quot;Tschüss&quot;)) Beispielcode: # Merkmalsausprägungen neu definieren ds &lt;- ds %&gt;% val_labels(im19 = c(&quot;Erste Stufe&quot;, &quot;Zweite Stufe&quot;, &quot;Dritte Stufe&quot;, &quot;Vierte Stufe&quot;), im20 = c(&quot;Erste Stufe&quot;, &quot;Zweite Stufe&quot;, &quot;Dritte Stufe&quot;, &quot;Vierte Stufe&quot;)) get_labels(ds$im19) #&gt; [1] &quot;Erste Stufe&quot; &quot;Zweite Stufe&quot; &quot;Dritte Stufe&quot; &quot;Vierte Stufe&quot; get_labels(ds$im20) #&gt; [1] &quot;Erste Stufe&quot; &quot;Zweite Stufe&quot; &quot;Dritte Stufe&quot; &quot;Vierte Stufe&quot; ds %&gt;% select(im19, im20) %&gt;% view_df() Data frame: . ID Name Label Values Value Labels 1 im19 Leistungsprinzip 1234 Erste StufeZweite StufeDritte StufeVierte Stufe 2 im20 Befürwortung von Ungleichheit 1234 Erste StufeZweite StufeDritte StufeVierte Stufe 3.7 Daten manipulieren Zur Manipulation/Bearbeitung unseres Datensatzes werden wir maßgeblich mit dem dplyr-Paket aus dem tidyverse und dem Paket sjmisc aus strengejacke arbeiten. Die folgende Auswahl kann nur einen Überblick über die “wichtigsten” Funktionen dieser Pakete geben. Sofern Sie weitere Tranformationswünsche haben, sollten Sie unbedingt die Entwicklerseiten dieser Pakete aufsuchen und nach geeigneten Funktionen suchen (siehe 1.6). Packet Funktion Verwendung dplyr rename() Umbenennen von Variablen dplyr mutate() Erstellen und verändern von vorhandenen Variablen dplyr group_by() Erstellt Gruppen (Teilmengen) dplyr summarise() Daten zusammenfassen dplyr distinct() Auswahl einzigartiger Werte dplyr case_when() Vektorisierter if-Befehl sjmisc rec() Rekodierung von Variablen sjmisc std() Z-Standardisierung von Variablen sjmisc center() Zentrierung von Variablen am Mittelwert sjmisc split_var() Aufspaltung von Variablen in n Gruppen gleicher Größe sjmisc group_var() Aufspaltung von Variablen in Gruppen gleicher Spannweite sjmisc row_count() Zählung von Zeilenwerten sjmisc row_sums() Summe der Zeilenwerte sjmisc row_means() Mittelwert der Zeilenwerte sjlabelled set_na() Transformiert Ausprägungsmerkmale zu fehlenden Werten tidyr drop_na() Alle fehlenden Werte werden gelöscht Rename() Die Funktion rename() erlaubt uns eine Neubeschriftung der Variablennamen vorzunehmen. Wichtig! Die nicht umbenannten Variablen verbleiben auch weiterhin im Datensatz. Syntax: # Ohne Pipe rename(datensatz, rename(variableA = variable1)) # Mit Pipe datensatz %&gt;% rename(variableA = variable1) Mit dem Befehl rename() haben wir in unserem Datensatz ds die Variable variable1 in variableA umbenannt. Der neue Name muss folgend immer auf der linken Seite der Gleichung stehen. Beispielcode: # Neubeschriftung der Variablen Geschlecht (sex) und Alter (age) ds &lt;- allbus2018 %&gt;% select(sex, age) %&gt;% rename(Geschlecht = sex, Alter = age) ds #&gt; # A tibble: 3,477 × 2 #&gt; Geschlecht Alter #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 62 #&gt; 2 2 64 #&gt; 3 1 22 #&gt; 4 1 59 #&gt; 5 2 30 #&gt; 6 1 41 #&gt; 7 2 43 #&gt; 8 1 39 #&gt; 9 2 40 #&gt; 10 2 69 #&gt; # … with 3,467 more rows Mutate() Über die Funktion mutate() können wir neue Variablen aus schon bestehenden Variablen bilden. Vor allem erlaubt uns dieser Befehl mathematische Operationen an Variablen vorzunehmen. Wir kennen diese Befehl in SPSS als compute. Syntax: # Ohne Pipe mutate(datensatz, variable1 = Berechnung) # Mit Pipe datensatz %&gt;% mutate(variable1 = Berechnung) Die Funktion mutate() erstellt eine neue Variable mit dem Namen variable1, in der wir das Ergebnis aus Berechnung speichern. Beispielcode: # Berechung des Alters der Befragten aus ihrem Geburtsjahr in neuer Variable (Alter) ds &lt;- allbus2018 %&gt;% select(yborn, age) %&gt;% mutate(Alter = 2018-yborn) ds #&gt; # A tibble: 3,477 × 3 #&gt; yborn age Alter #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1956 62 62 #&gt; 2 1953 64 65 #&gt; 3 1995 22 23 #&gt; 4 1959 59 59 #&gt; 5 1987 30 31 #&gt; 6 1976 41 42 #&gt; 7 1975 43 43 #&gt; 8 1979 39 39 #&gt; 9 1977 40 41 #&gt; 10 1949 69 69 #&gt; # … with 3,467 more rows # Fast ;D # Um das korrekte Alter zu ermitteln, müssten wir natürlich noch den Geburtsmonat einbeziehen! Sofern Sie nur die neu gebildeten Variablen in ihrem Datensatz behalten möchten, bietet sich der Befehl transmute() als Erweiterung von mutate() an. Group_by() Gesetzt den Fall, dass wir bestimmte Operationen nicht auf den ganzen Datensatz anwenden wollen, sondern nur auf Teilgruppen, ist die Funktion group_by() die ideale Lösung für uns. Über group_by() wird unser Datensatz anhand einer Gruppierungsvariable (mit nominalen Ausprägungsmerkmalen) geteilt. Anschließende Funktionen werden auf jeden Teil angewendet, bevor sich der Datensatz nach Abschluss unserer Operationen über wieder zusammensetzt (split-apply-combine). group_by() wird deshalb meistens in Kombination mit anderen Funktionen verwendet. Um nach einer abgeschlossenen Operation die Gruppierung wieder zusammen zu setzen, nutzen wir ungroup(). So können wir wieder mit einem ungruppierten Datensatz weiterarbeiten. Unsere Ergebnisse können wir über mutate() einer neuen Variable zuweisen und es damit auf alle Fälle in unserem Datensatz übertragen. Syntax: # Ohne Pipe group_by(datensatz, variable1) # Mit Pipe datensatz %&gt;% group_by(variable1) Wir spalten also über die Funktion group_by() unseren Datensatz in Gruppen nach den Ausprägungsmerkmalen der variable1. Beispielcode: # Altersdurchschnitt nach Ost und West ds &lt;- allbus2018 %&gt;% select(age, eastwest, wghtpew) %&gt;% group_by(eastwest) %&gt;% # Wir werden in Kapitel 4 alles über gewichtete Objekte lernen (z.B. weighted_mean())! mutate(alterOstWest = weighted_mean(age, weights = wghtpew)) %&gt;% ungroup() ds %&gt;% select(eastwest, alterOstWest) #&gt; # A tibble: 3,477 × 2 #&gt; eastwest alterOstWest #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 50.7 #&gt; 2 2 53.9 #&gt; 3 1 50.7 #&gt; 4 2 53.9 #&gt; 5 2 53.9 #&gt; 6 1 50.7 #&gt; 7 1 50.7 #&gt; 8 1 50.7 #&gt; 9 1 50.7 #&gt; 10 2 53.9 #&gt; # … with 3,467 more rows Unter Verwendung von group_by() haben wir den Datensatz in zwei separate Teile geteilt und dann den Gruppenmittelwert für Ost- und Westdeutschland errechnet. Da wir unser Ergebnis allen Fällen zuweisen wollten, haben wir eine neue Variable über mutate() gebildet. Anschließend haben wir die Teile wieder über ungroup() “zusammengesetzt” (d.h. es ist wieder ein Datensatz) und so das Ergebnis allen Fällen zugewiesen. Als Resultat besitzen alle Fälle den Altersdurchschnitt in ihrem Bundesgebiet als neue Variable alterOstWest. Summarise() Die Funktion summarise() ermöglicht es uns Variablen zusammen zu fassen und deskriptive Kennzahlen zu berechnen. Im Gegensatz zu mutate() gibt summarise() aber nicht den Wert für jede Beobachtung als Output aus, sondern einen Wert für jede Gruppe. summarise() wird oft zusammen mit group_by() verwendet. Syntax: # Ohne Pipe summarise(datensatz, variable1 = funktion(variable)) # Mit Pipe datensatz %&gt;% summarise(variable1 = funktion(variable)) Mit der Funktion summarise() wurde in variable1 das Ergebnis aus function(variable) gespeichert. Hierbei wurde ein neuer Datensatz mit nur der Variable variable1 gebildet, die als einzigen Wert den Gruppenwert aus function(variable) besitzt. Beispielcode: # Altersdurchschnitt nach Ost und West ds &lt;- allbus2018 %&gt;% select(age, eastwest, wghtpew) %&gt;% group_by(eastwest) %&gt;% summarise(alterOstWest = weighted_mean(age, weights = wghtpew)) %&gt;% ungroup() ds %&gt;% select(eastwest, alterOstWest) #&gt; # A tibble: 2 × 2 #&gt; eastwest alterOstWest #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 50.7 #&gt; 2 2 53.9 Distinct() Die Funktion distinct() erlaubt uns einzigartige Werte in einem Vektor zu ermitteln. Syntax: # Ohne Pipe distinct(datensatz, variable1) # Mit Pipe datensatz %&gt;% distinct(variable1) Beispielcode: # Geburtsjahre ds &lt;- allbus2018 %&gt;% select(yborn) %&gt;% distinct(yborn) %&gt;% arrange(yborn) ds #&gt; # A tibble: 78 × 1 #&gt; yborn #&gt; &lt;dbl&gt; #&gt; 1 1923 #&gt; 2 1924 #&gt; 3 1925 #&gt; 4 1926 #&gt; 5 1927 #&gt; 6 1928 #&gt; 7 1929 #&gt; 8 1930 #&gt; 9 1931 #&gt; 10 1932 #&gt; # … with 68 more rows Case_when() Über die Funktion case_when() lassen sich Kombinationen von Ausprägungsmerkmalen in neuen Variablen speichern - (Stw. Kombinationsindex). Der Befehl if-Befehl aus SPSS kommt diesem sehr nahe. Syntax: # Ohne Pipe case_when(datensatz$variable1 == 1 &amp; datensatz$variable2 == 2 ~ 1, datensatz$variable1 == 2 $ datensatz$variable2 == 1 ~ 2) # Mit Pipe datensatz %&gt;% mutate(variableA = case_when(variable1 == 1 &amp; variable2 == 2 ~ 1, variable1 == 2 $ variable2 == 1 ~ 2) Die Funktion case_when() erzeugt aus den Ausprägungsmerkmalen 1 und 2 der Variablen variable1 und variable2 eine neue Ausprägung 1. Das gleiche passiert auch in den nachfolgenden Operationen mit verschiedenen Wertpaaren der variable1 und variable2. Anmerkung: Die Funktion case_when() kann innerhalb einer Pipe praktisch nicht ohne eine “Speicherfunktion” auskommen. Entsprechend haben wir hier mutate() vorangestellt. Beispielcode: # Postmaterialismusindex nach Inglehart: Materialisten/Postmaterialisten ds &lt;- allbus2018 %&gt;% select(va01:va04, ingle) %&gt;% mutate( inglehartIndex = case_when( # Materialisten va01 == 1 &amp; va03 == 2 ~ 4, va01 == 2 &amp; va03 == 1 ~ 4, # Postmaterialisten va02 == 1 &amp; va04 == 2 ~ 1, va02 == 2 &amp; va04 == 1 ~ 1 ) ) # Vergleich mit dem beigelegten Inglehartindex aus dem Allbus # Wir müssten natürlich noch die Mischtypen berechnen! ds %&gt;% select(inglehartIndex, ingle) %&gt;% filter(inglehartIndex %in% c(1, 4)) #&gt; # A tibble: 1,129 × 2 #&gt; inglehartIndex ingle #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 4 #&gt; 2 4 4 #&gt; 3 1 1 #&gt; 4 1 1 #&gt; 5 1 1 #&gt; 6 1 1 #&gt; 7 1 1 #&gt; 8 1 1 #&gt; 9 4 4 #&gt; 10 1 1 #&gt; # … with 1,119 more rows Rec() Nun folgt die wohl wichtigste Funktion in unserem Werkzeugkasten. So vereint die Funktion rec() eine Vielzahl von uns bekannten Funktionen z.B. to_numeric() und to_factor(), var_labels() und val_labels() und schafft darüber hinaus die Möglichkeit zur gezielten Rekodierung von Variablen. Diese Funktion entspricht dem Befehl recode aus SPSS. Syntax: # Ohne Pipe rec(datensatz, variable1, rec = &quot;1=1 [niedrig]; 2,4=2 [mittel]; 4:max=3 [hoch], else=copy, 99=NA&quot;, var.label = &quot;Variablenbeschriftung&quot;, to.factor = TRUE) # Mit Pipe datensatz %$% rec(variable1, rec = &quot;1=1 [niedrig]; 2,3=2 [mittel]; 4:max=3 [hoch], else=copy, 99=NA&quot;, var.label = &quot;Variablenbeschriftung&quot;, to.factor = TRUE) variable1 aus dem Datensatz datensatz wurde rekodiert und in einen Faktor konvertiert. So wurden alle Werte entsprechend neu zugewiesen und mit neuen Beschriftungen versehen. Zudem wurde die Variablenbeschriftung angepasst. Beispielcode: # Rekodierung von Bildungsabschlüssen ds &lt;- allbus2018 %&gt;% select(educ) %&gt;% mutate(bildung = rec(educ, rec = &quot;1,2=1 [gering]; 3,7=2 [mittel]; 4,5=3 [hoch]&quot;, var.label = &quot;Bildung kategorisiert&quot;, to.factor = T)) class(ds$educ) #&gt; [1] &quot;numeric&quot; attributes(ds$bildung) #&gt; $levels #&gt; [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; #&gt; #&gt; $labels #&gt; gering mittel hoch #&gt; 1 2 3 #&gt; #&gt; $label #&gt; [1] &quot;Bildung kategorisiert&quot; view_df(ds) Data frame: ds ID Name Label Values Value Labels 1 educ ALLGEMEINER SCHULABSCHLUSS 1234567 OHNE ABSCHLUSSVOLKS-,HAUPTSCHULEMITTLERE REIFEFACHHOCHSCHULREIFEHOCHSCHULREIFEANDERER ABSCHLUSSNOCH SCHUELER 2 bildung Bildung kategorisiert 123 geringmittelhoch Std() Mit der Funktion std() können wir Variablen z-transformieren (Standardisierung und Zentrierung). Syntax: # Ohne Pipe std(datensatz, variable1) # Mit Pipe datensatz %&gt;% std(variable1) Im Default wird dabei eine neue Variable mit dem Suffix “_z” erstellt. Im Beispiel würde im Datensatz datensatz eine neue Variable mit dem Namen variable1_z gebildet werden. Beispielcode: # z-Standardisierung des Leistungsprinzip (im19) ds &lt;- allbus2018 %&gt;% std(im19) ds %&gt;% select(im19, im19_z) #&gt; # A tibble: 3,477 × 2 #&gt; im19 im19_z #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 1.58 #&gt; 2 4 1.58 #&gt; 3 2 -0.537 #&gt; 4 4 1.58 #&gt; 5 4 1.58 #&gt; 6 2 -0.537 #&gt; 7 4 1.58 #&gt; 8 4 1.58 #&gt; 9 3 0.522 #&gt; 10 4 1.58 #&gt; # … with 3,467 more rows Center() Zur Zentrierung (um den Mittelwert) einer Variable kann der Befehl center() genutzt werden. Syntax: # Ohne Pipe center(datensatz, variable1) # Mit Pipe datensatz %&gt;% center(datensatz, variable1) Im Default wird bei der Zentrierung eine neue Variable mit dem Suffix “_c” erstellt. Im Beispiel würde im Datensatz datensatz eine neue Variable mit dem Namen variable1_c gebildet werden. Beispielcode: # Zentrierung des Leistungsprinzip (im19) am Mittelwert ds &lt;- allbus2018 %&gt;% center(im19) ds %&gt;% select(im19, im19_c) #&gt; # A tibble: 3,477 × 2 #&gt; im19 im19_c #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 1.49 #&gt; 2 4 1.49 #&gt; 3 2 -0.507 #&gt; 4 4 1.49 #&gt; 5 4 1.49 #&gt; 6 2 -0.507 #&gt; 7 4 1.49 #&gt; 8 4 1.49 #&gt; 9 3 0.493 #&gt; 10 4 1.49 #&gt; # … with 3,467 more rows Split_var() Mit dem Befehl split_var() können nummerische Variablen in gleich große Gruppen (Befragtenanzahl) aufgeteilt werden. Die Anzahl der Gruppen wird dabei im Befehl mit n= festgelegt. Syntax: # Ohne Pipe split_var(datensatz, variable1, n = 5) # Mit Pipe datensatz %&gt;% split_var(variable1, n = 5) Bei der Gruppierung mit diesem Befehl wird eine neue Variable mit dem Suffix “_g” erstellt. Im Beispiel würde im Datensatz datensatz eine neue Variable mit dem Namen variable1_g gebildet werden. Beispielcode: # Alter in 5 gleichgroße Gruppen unterteilen ds &lt;- allbus2018 %&gt;% select(age) %&gt;% mutate(ageGrp = split_var(age, n = 5)) # Den Befehl frq() werden wir in Kapitel 4 umfassend besprechen! ds %&gt;% frq(ageGrp, weights = allbus2018$wghtpew) #&gt; ALTER: BEFRAGTE(R) (ageGrp) &lt;categorical&gt; #&gt; # total N=3471 valid N=3471 mean=2.99 sd=1.42 #&gt; #&gt; Value | N | Raw % | Valid % | Cum. % #&gt; -------------------------------------- #&gt; 1 | 698 | 20.11 | 20.11 | 20.11 #&gt; 2 | 717 | 20.66 | 20.66 | 40.77 #&gt; 3 | 665 | 19.16 | 19.16 | 59.93 #&gt; 4 | 696 | 20.05 | 20.05 | 79.98 #&gt; 5 | 695 | 20.02 | 20.02 | 100.00 #&gt; &lt;NA&gt; | 0 | 0.00 | &lt;NA&gt; | &lt;NA&gt; Group_var() Entgehgen dem vorherigen Befehl split_var(), ist hier der Fokus die Gruppen nach dem Wertebereich einzuteilen. Mit dem group_var() Befehl wird eine nummerische Variable in einer neuen Variable zu Gruppen mit gleichem Wertebereich gruppiert. Mit size= wird der Wertebreich der einzelnen Gruppen festgelegt. Syntax: # Ohne Pipe group_var(datensatz, variable1, size = 5) # Mit Pipe datensatz %&gt;% group_var(variable1, size = 5) Bei der Gruppierung mit diesem Befehl wird eine neue Variable mit dem Suffix “_gr” erstellt. Im Beispiel würde im Datensatz datensatz eine neue Variable mit dem Namen variable1_gr gebildet werden. Beispielcode: # 10 Jahre Altersspannen # Achtung! Intervalle orientieren sich &quot;default&quot; an der oberen Wertgrenze des Intervalls ds &lt;- allbus2018 %&gt;% select(age) %&gt;% mutate(ageGrp = group_var(age, size = 10)) # Eine direkte Beschriftung ist leider nicht möglich. # Zum Abgleich der Intervallgrenzen ist group_labels() aber sehr hilfreich! # Group_labels() generiert in gleicher Form die gewüschten Intervalle, besitz aber als Ausprägungsmerkmale die Beschriftung. group_labels(ds$age, size = 10) #&gt; [1] &quot;10-19&quot; &quot;20-29&quot; &quot;30-39&quot; &quot;40-49&quot; &quot;50-59&quot; &quot;60-69&quot; &quot;70-79&quot; &quot;80-89&quot; &quot;90-99&quot; #&gt; attr(,&quot;label&quot;) #&gt; [1] &quot;ALTER: BEFRAGTE(R)&quot; # Beschriftung der Intervalle ds &lt;- ds %&gt;% val_labels(ageGrp = c(&quot;10-19&quot;, &quot;20-29&quot;, &quot;30-39&quot;, &quot;40-49&quot;, &quot;50-59&quot;, &quot;60-69&quot;, &quot;70-79&quot;, &quot;80-89&quot;, &quot;90-99&quot;)) attributes(ds$ageGrp) #&gt; $label #&gt; [1] &quot;ALTER: BEFRAGTE(R)&quot; #&gt; #&gt; $labels #&gt; 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99 #&gt; 1 2 3 4 5 6 7 8 9 Row_count() Befehl count in SPSS. Noch suchen: count für mehrere Werte! Syntax: # Ohne Pipe row_count(datensatz, count = 1) # Mit Pipe datensatz %&gt;% row_count(count = 1) Beispielcode: # Mitgliedsstatus in Vereinen zählen - aktives Mitglied (3) ds &lt;- allbus2018 %&gt;% select(sm04:sm14) %&gt;% row_count(count = 3) ds %&gt;% frq(rowcount, weights = allbus2018$wghtpew) #&gt; rowcount &lt;integer&gt; #&gt; # total N=3476 valid N=3476 mean=0.61 sd=0.88 #&gt; #&gt; Value | N | Raw % | Valid % | Cum. % #&gt; --------------------------------------- #&gt; 0 | 2006 | 57.71 | 57.71 | 57.71 #&gt; 1 | 987 | 28.39 | 28.39 | 86.10 #&gt; 2 | 353 | 10.16 | 10.16 | 96.26 #&gt; 3 | 98 | 2.82 | 2.82 | 99.08 #&gt; 4 | 23 | 0.66 | 0.66 | 99.74 #&gt; 5 | 7 | 0.20 | 0.20 | 99.94 #&gt; 7 | 1 | 0.03 | 0.03 | 99.97 #&gt; 8 | 1 | 0.03 | 0.03 | 100.00 #&gt; &lt;NA&gt; | 0 | 0.00 | &lt;NA&gt; | &lt;NA&gt; Row_sums() Summenindex # Ohne Pipe row_sums(datensatz, n = Inf) # Mit Pipe datensatz %&gt;% row_sums(n = Inf) Beispielcode: # Mitgliedsstatus in Vereinen zählen ds &lt;- allbus2018 %&gt;% select(sm04:sm07) %&gt;% row_sums(n = Inf) ds %&gt;% frq(rowsums, weights = allbus2018$wghtpew) #&gt; rowsums &lt;numeric&gt; #&gt; # total N=3474 valid N=3474 mean=5.23 sd=1.54 #&gt; #&gt; Value | N | Raw % | Valid % | Cum. % #&gt; --------------------------------------- #&gt; 4 | 1739 | 50.06 | 50.06 | 50.06 #&gt; 5 | 342 | 9.84 | 9.84 | 59.90 #&gt; 6 | 837 | 24.09 | 24.09 | 84.00 #&gt; 7 | 206 | 5.93 | 5.93 | 89.93 #&gt; 8 | 225 | 6.48 | 6.48 | 96.40 #&gt; 9 | 49 | 1.41 | 1.41 | 97.81 #&gt; 10 | 56 | 1.61 | 1.61 | 99.42 #&gt; 11 | 14 | 0.40 | 0.40 | 99.83 #&gt; 12 | 5 | 0.14 | 0.14 | 99.97 #&gt; 14 | 1 | 0.03 | 0.03 | 100.00 #&gt; &lt;NA&gt; | 0 | 0.00 | &lt;NA&gt; | &lt;NA&gt; Row_means() Mittelwertindex # Ohne Pipe row_means(datensatz, n = 1) # Mit Pipe datensatz %&gt;% row_means(n = 1) Beispielcode: # Mittelwertindex: Leistungsprinzip (im19) und Befürwortung von Ungleichheit (im20) ds &lt;- allbus2018 %&gt;% select(im19, im20) %&gt;% row_means(n = 1) ds %&gt;% frq(rowmeans, weights = allbus2018$wghtpew) #&gt; rowmeans &lt;numeric&gt; #&gt; # total N=3436 valid N=3436 mean=2.52 sd=0.80 #&gt; #&gt; Value | N | Raw % | Valid % | Cum. % #&gt; -------------------------------------- #&gt; 1.00 | 222 | 6.46 | 6.46 | 6.46 #&gt; 1.50 | 320 | 9.31 | 9.31 | 15.77 #&gt; 2.00 | 830 | 24.16 | 24.16 | 39.93 #&gt; 2.50 | 711 | 20.69 | 20.69 | 60.62 #&gt; 3.00 | 752 | 21.89 | 21.89 | 82.51 #&gt; 3.50 | 303 | 8.82 | 8.82 | 91.33 #&gt; 4.00 | 298 | 8.67 | 8.67 | 100.00 #&gt; &lt;NA&gt; | 0 | 0.00 | &lt;NA&gt; | &lt;NA&gt; Set_na() Mit der Funktion set_na() wollen wir lernen, wie wir einzelne oder mehrere Ausprägungsmerkmale in NA konvertieren können. Syntax: # Ohne Pipe set_na(datensatz, variable1, na = c(1, 3)) # Mit Pipe datensatz %&gt;% set_na(variable1, na = c(1, 3)) Mit haben mit der Funktion set_na() in variable1 die Ausprägungsmerkmale 1 und 3 als NA definiert. Beispielcode: # Definition der Altersspanne 61 bis 99 als NA ds &lt;- allbus2018 %&gt;% select(age) %&gt;% set_na(age, na = 61:99) view_df(ds) Data frame: ds ID Name Label Values Value Labels 1 age ALTER: BEFRAGTE(R) range: 18-60 Drop_na() Syntax: # Einzelne Variable # Ohne Pipe drop_na(datensatz, variable1) # Mit Pipe datensatz %&gt;% drop_na(variable1) # -------- # Ganzer Datensatz # Ohne Pipe drop_na(variable1) # Mit Pipe datensatz %&gt;% drop_na() Beispielcode: # Fehlende Werte in Leistungsprinzip (im19) löschen ds &lt;- allbus2018 %&gt;% drop_na(im19) # Alle fehelnden Werte im Datensatz löschen ds &lt;- allbus2018 %&gt;% drop_na() Referenz: Moosdorf, D. (2020): Kritik an sozialer Ungleichheit – Macht politisches Wissen den Unterschied?. In Tausendpfund, M. &amp; B. Westle (Hrsg.), Politisches Wissen in Deutschland: Empirische Analysen mit dem ALLBUS 2018 (S. 165–197). Wiesbaden: Springer VS. https://doi.org/10.1007/978-3-658-30492-8_6. "],["uni--und-bivariate-datenanalyse.html", "4 Uni- und Bivariate Datenanalyse 4.1 Gewichtung 4.2 Univariate Statistiken 4.3 Bivariate Statistiken 4.4 Mittelwertvergleiche (unabhängig) 4.5 Grafiken", " 4 Uni- und Bivariate Datenanalyse In diesem Kapitel behandeln wir die gängigsten Verfahren zur uni- und bivariaten Datenanalyse und wie diese in den verwendeten Ökosystemen umgesetzt sind. Damit kann sich ein Überblick über die Datenstruktur verschafft und erste Zusammenhänge überprüft werden. Zur Veranschaulichung dieser Analyseschritte werden am Ende dieses Kapitels erste vereinfachte Möglichkeiten angeboten, diese grafisch aufzubereiten. 4.1 Gewichtung Sozialwissenschaftlich arbeiten wir vielfach mit Umfragedaten, mit denen Aussagen über eine größere Grundgesamtheit gemacht werden sollen (wie bspw. der in den Beispielen verwendete Allbus-Datensatz). Diese Daten beinhalten aber oft Verzerrungen (gewollt (Oversample) oder ungewollt (Non-Response)), welche ihre Repräsentativität einschränken. Um diesem Problem zu begegnen, ist es erforderlich die Daten zu gewichten. Bei der Auswahl der Codes, welche wir für die einzelnen Analyseschritte für dieses e-Book zusammengestellt haben, haben wir daher durchgehend darauf geachtet, dass die Verfahren gewichtet möglich sind. Hinweis an bisherigen SPSS-Nutzer:innen: Die Gewichtung erfolgt in R für jede Analyse einzeln (und nicht einmal für die ganze Analyse-Session wie in SPSS). Bei jedem Analyseschritt muss daher angegeben werden, ob gewichtet werden soll. Die Gewichtung erfolgt bei den einzelnen Funktionen i.d.R. mit dem Argument weights=. Bei jeder Funktion ist dies aber noch einmal ausgewiesen. 4.2 Univariate Statistiken Für univariate Statistiken haben wir die gängigsten Verfahren zusammengestellt (Häufigkeitsverteilungnen sowie Lage- und Streuungsmaße). Packet Funktion Verwendung sjmisc frq() Häufigkeitstabelle sjmisc descr() Despriptive Statistiken ausgeben sjstats weighted_mean() Mittelwert berechnen sjstats weighted_median() Median berechnen sjstats weighted_sd() Standardabweichung berechnen sjstats weighted_se() Standardfehler berechnen weights wtd.quantile() Quantile berechnen Frq() Mit der Funktion frq() können Häufigkeitstabellen ausgegeben werden, welche die Informationen: Value, Valuelabel, N, RaW %, Valid % und CUm. % umfassen. (Sie entsprechen damit dem SPSS-oUtput). Syntax: # Ohne Pipe frq(datensatz$variable1, weights = datensatz$gewicht) # Mit Pipe datensatz %&gt;% frq(variable1, weights = gewicht) Beispielcode: # Häufigkeitstabelle Leistungsprinzip (im19) allbus2018 %&gt;% frq(im19, weights = wghtpew) #&gt; EINKOMMENSDIFFERENZ ERHOEHT MOTIVATION (im19) &lt;numeric&gt; #&gt; # total N=3370 valid N=3370 mean=2.49 sd=0.93 #&gt; #&gt; Value | Label | N | Raw % | Valid % | Cum. % #&gt; -------------------------------------------------------------- #&gt; 1 | STIMME VOLL ZU | 532 | 15.79 | 15.79 | 15.79 #&gt; 2 | STIMME EHER ZU | 1186 | 35.19 | 35.19 | 50.98 #&gt; 3 | STIMME EHER NICHT ZU | 1132 | 33.59 | 33.59 | 84.57 #&gt; 4 | STIMME GAR NICHT ZU | 520 | 15.43 | 15.43 | 100.00 #&gt; &lt;NA&gt; | &lt;NA&gt; | 0 | 0.00 | &lt;NA&gt; | &lt;NA&gt; Descr() Mit descr() werden die wesentlichen deskriptiven Statistiken ausgegeben: prozentuale Angabe fehlender Werten, Mittelwert, Standardabweichung, Standardfehler, Wertebereich, Interquartilsabstand, Scheife. Syntax: # Ohne Pipe descr(datensatz$variable1, weights = datensatz$gewicht) # Mit Pipe datensatz %&gt;% descr(variable1, weights = gewicht) Mit dem Argument show = \"short\" wird die Ausgabe verkürzt und nur noch: prozentuale Angabe fehlender Werten, Mittelwert, Standardabweichung ausgegeben. Beispielcode: # Deskriptive Statistiken Leistungsprinzip (im19) allbus2018 %&gt;% descr(im19, weights = wghtpew) #&gt; #&gt; ## Basic descriptive statistics #&gt; #&gt; var type label n NA.prc mean sd se #&gt; im19 numeric EINKOMMENSDIFFERENZ ERHOEHT MOTIVATION 3370 2.99 2.49 0.93 0.02 #&gt; range iqr skew #&gt; 3 (1-4) 1 0.01 allbus2018 %&gt;% descr(im19, weights = wghtpew, show = &quot;short&quot;) #&gt; #&gt; ## Basic descriptive statistics #&gt; #&gt; var n NA.prc mean sd #&gt; im19 3370 2.99 2.49 0.93 Weighted_mean() weighted_mean() wird verwendet um lediglich den Mittelwert zu berechnen. Dies hat den Vorteil, dass das Ergebnis direkt als neue Variable abgespreichert werden kann (siehe dazu den Beispielcode unten). ACHTUNG: In der Pipe-Schreibeweise muss hier der %$%-Operator verwendet werden. Syntax: # Ohne Pipe weighted_mean(datensatz$variable1, weights = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% weighted_mean(variable1, weights = gewicht) Beispielcode: # Mittelwert Leistungsprinzip (im19) allbus2018 %$% weighted_mean(im19, weights = wghtpew) #&gt; [1] 2.48678 # Mittelwert Leistungsprinzip (im19) als neue Variable ds &lt;- allbus2018 %&gt;% transmute(mittelLeistung = weighted_mean(im19, weights = wghtpew)) ds #&gt; # A tibble: 3,477 × 1 #&gt; mittelLeistung #&gt; &lt;dbl&gt; #&gt; 1 2.49 #&gt; 2 2.49 #&gt; 3 2.49 #&gt; 4 2.49 #&gt; 5 2.49 #&gt; 6 2.49 #&gt; 7 2.49 #&gt; 8 2.49 #&gt; 9 2.49 #&gt; 10 2.49 #&gt; # … with 3,467 more rows Weighted_median() Analog zur vorherigen Funktion wird mit weighted_median() nur der Median berechnet. ACHTUNG: In der Pipe-Schreibeweise muss hier der %$%-Operator verwendet werden. Syntax: # Ohne Pipe weighted_median(datensatz$variable1, weights = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% weighted_median(variable1, weights = gewicht) Beispielcode: # Median Leistungsprinzip (im19) allbus2018 %$% weighted_median(im19, weights = wghtpew) #&gt; [1] 2 # Median Leistungsprinzip (im19) als neue Variable ds &lt;- allbus2018 %&gt;% mutate(medianLeistung = weighted_median(im19, weights = wghtpew)) %&gt;% distinct(medianLeistung) ds #&gt; # A tibble: 1 × 1 #&gt; medianLeistung #&gt; &lt;dbl&gt; #&gt; 1 2 Weighted_sd() Mit weighted_sd kann die Standardabweichung berechnet werden. ACHTUNG: In der Pipe-Schreibeweise muss hier der %$%-Operator verwendet werden. Syntax: # Ohne Pipe weighted_sd(datensatz$variable1, weights = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% weighted_sd(variable1, weights = gewicht) Beispielcode: # Mittelwert und Standardabweichung Leistungprinzip nach Ost-West (Fälle) ds &lt;- allbus2018 %&gt;% select(eastwest, im19, wghtpew) %&gt;% group_by(eastwest) %&gt;% mutate(leistungMittelOstWest = weighted_mean(im19, weights = wghtpew), leistungSDOstWest = weighted_sd(im19, weights = wghtpew)) %&gt;% ungroup() ds %&gt;% select(eastwest, leistungMittelOstWest, leistungSDOstWest) #&gt; # A tibble: 3,477 × 3 #&gt; eastwest leistungMittelOstWest leistungSDOstWest #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2.46 0.923 #&gt; 2 2 2.60 0.985 #&gt; 3 1 2.46 0.923 #&gt; 4 2 2.60 0.985 #&gt; 5 2 2.60 0.985 #&gt; 6 1 2.46 0.923 #&gt; 7 1 2.46 0.923 #&gt; 8 1 2.46 0.923 #&gt; 9 1 2.46 0.923 #&gt; 10 2 2.60 0.985 #&gt; # … with 3,467 more rows Weighted_se() weighted_se() wird verwendet, um nur den Standardfehler zu berechnen. ACHTUNG: In der Pipe-Schreibeweise muss hier der %$%-Operator verwendet werden. Syntax: # Ohne Pipe weighted_se(datensatz$variable1, weights = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% weighted_se(variable1, weights = gewicht) Beispielcode: # Mittelwert, Standardabweichung und Standardfehler # Leistungprinzip nach Ost-West (Gruppen) ds &lt;- allbus2018 %&gt;% select(eastwest, im19, wghtpew) %&gt;% group_by(eastwest) %&gt;% summarise(leistungMittelOstWest = weighted_mean(im19, weights = wghtpew), leistungSDOstWest = weighted_sd(im19, weights = wghtpew), leistungSEOstWest = weighted_se(im19, weights = wghtpew)) %&gt;% ungroup() ds #&gt; # A tibble: 2 × 4 #&gt; eastwest leistungMittelOstWest leistungSDOstWest leistungSEOstWest #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2.46 0.923 0.0192 #&gt; 2 2 2.60 0.985 0.0302 # Mittelwert, Standardabweichung, Standardfehler und .95 Konfidenzintervall # Leistungprinzip nach Ost-West (Gruppen) ds &lt;- allbus2018 %&gt;% group_by(eastwest) %&gt;% summarise(leistungMittelOstWest = weighted_mean(im19, weights = wghtpew), leistungSDOstWest = weighted_sd(im19, weights = wghtpew), leistungSEOstWest = weighted_se(im19, weights = wghtpew), CI.95.down = leistungMittelOstWest-1.96*(leistungSDOstWest/sqrt(n())), CI.95.up = leistungMittelOstWest+1.96*(leistungSDOstWest/sqrt(n()))) %&gt;% ungroup() ds #&gt; # A tibble: 2 × 6 #&gt; eastwest leistungMittelOstWest leistungSDOstWest leistungSEOstWest CI.95.down #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2.46 0.923 0.0192 2.43 #&gt; 2 2 2.60 0.985 0.0302 2.55 #&gt; # … with 1 more variable: CI.95.up &lt;dbl&gt; wtd.quantile() Für die Berchnung der Quantile müssen wir auf das Paket weights zurückgreifen. Bitte installieren und laden. Wir verwenden davon die Funktion wtd.quantile. ACHTUNG: In der Pipe-Schreibeweise muss hier der %$%-Operator verwendet werden. library(weights) Syntax: # Ohne Pipe wtd.quantile(datensatz$variable1, weights = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% wtd.quantile(variable1, weights = gewicht) Beispielcode: # Quantile Alter allbus2018 %$% wtd.quantile(age, weights = wghtpew) #&gt; 0% 25% 50% 75% 100% #&gt; 18 36 52 65 95 4.3 Bivariate Statistiken Für bivariate Statistiken schauen wir uns zunächst mit der Funktion crosstab() die gemeinsame Verteilung zweier Variablen in einer Kreuztabelle an. Die Zusammenhangsmaße können wir überwiegend mit crosstable_statistics() abrufen. Für den Chi-Quadart-Test und den Korrelataionskoeffizienten nach Pearson verwenden wir spezifisch dafür geschriebene Funktionen. Packet Funktion Verwendung dscr crosstab() Kreuztabellen sjstats weighted_chisqtest() Chi-Quadrat-Test sjstats crosstable_statistics() Zusammenhangsmaße sjmisc weighted_correlation() Pearson`s r Crosstab() Für die Berechung einer Kreuztabelle verwenden wir das Paket descr, welches installiert und geladen werden muss. library(descr) # Achtung! Überschreibt sjmisc::descr # Paket sjmisc deaktivieren und nochmal aktivieren detach(&quot;package:sjmisc&quot;, unload = TRUE) library(sjmisc) Syntax: Mit der Funktion crosstab aus dem descr-Paket berechnen wir die Kreuztabelle. Mit der ersten Variable definieren wir die Zeilen und mit der Zweiten die Spalten. Im default ohne weitere Spezifikation erhalten wir eine Kreuztabelle mit den absoluten Häufigkeiten und eine Mosaik-Plot der Verteilung. Für andere Angaben müssen entsprechende Argumente benannt werden. Siehe dazu die folgenden Beispiele oder die Hilfeseite der Funktion mit ?crosstab. ACHTUNG: In der Pipe-Schreibeweise muss hier der %$%-Operator verwendet werden. # Ohne Pipe crosstab(datensatz$variable1, datensatz$variable2, weights = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% crosstab(variable1, variable2, weight = gewicht) Beispielcode: # Kreuztabelle Geschlecht (sex) und Bildung (educ) - # Absolute Häufigkeit # ohne Grafik allbus2018 %$% crosstab(sex, educ, weight = wghtpew, plot = F) #&gt; Cell Contents #&gt; |-------------------------| #&gt; | Count | #&gt; |-------------------------| #&gt; #&gt; ================================================================================= #&gt; ALLGEMEINER SCHULABSCHLUSS #&gt; GESCHLECHT, BEFRAGTE(R) 1 2 3 4 5 6 7 Total #&gt; --------------------------------------------------------------------------------- #&gt; 1 31 445 519 185 570 12 13 1775 #&gt; --------------------------------------------------------------------------------- #&gt; 2 23 408 575 140 531 10 11 1698 #&gt; --------------------------------------------------------------------------------- #&gt; Total 54 853 1094 325 1101 22 24 3473 #&gt; ================================================================================= # Kreuztabelle Geschlecht (sex) und Bildung (educ) - # relative Häufigkeit nach Spalten # ohne Grafik allbus2018 %$% crosstab(sex, educ, weight = wghtpew, prop.c = T, plot = F) #&gt; Cell Contents #&gt; |-------------------------| #&gt; | Count | #&gt; | Column Percent | #&gt; |-------------------------| #&gt; #&gt; ======================================================================================== #&gt; ALLGEMEINER SCHULABSCHLUSS #&gt; GESCHLECHT, BEFRAGTE(R) 1 2 3 4 5 6 7 Total #&gt; ---------------------------------------------------------------------------------------- #&gt; 1 31 445 519 185 570 12 13 1775 #&gt; 57.4% 52.2% 47.4% 56.9% 51.8% 54.5% 54.2% #&gt; ---------------------------------------------------------------------------------------- #&gt; 2 23 408 575 140 531 10 11 1698 #&gt; 42.6% 47.8% 52.6% 43.1% 48.2% 45.5% 45.8% #&gt; ---------------------------------------------------------------------------------------- #&gt; Total 54 853 1094 325 1101 22 24 3473 #&gt; 1.6% 24.6% 31.5% 9.4% 31.7% 0.6% 0.7% #&gt; ======================================================================================== # Kreuztabelle Geschlecht (sex) und Bildung (educ) - # relative Häufigkeit nach Zeilen # ohne Grafik allbus2018 %$% crosstab(sex, educ, weight = wghtpew, prop.r = T, plot = F) #&gt; Cell Contents #&gt; |-------------------------| #&gt; | Count | #&gt; | Row Percent | #&gt; |-------------------------| #&gt; #&gt; ===================================================================================== #&gt; ALLGEMEINER SCHULABSCHLUSS #&gt; GESCHLECHT, BEFRAGTE(R) 1 2 3 4 5 6 7 Total #&gt; ------------------------------------------------------------------------------------- #&gt; 1 31 445 519 185 570 12 13 1775 #&gt; 1.7% 25.1% 29.2% 10.4% 32.1% 0.7% 0.7% 51.1% #&gt; ------------------------------------------------------------------------------------- #&gt; 2 23 408 575 140 531 10 11 1698 #&gt; 1.4% 24.0% 33.9% 8.2% 31.3% 0.6% 0.6% 48.9% #&gt; ------------------------------------------------------------------------------------- #&gt; Total 54 853 1094 325 1101 22 24 3473 #&gt; ===================================================================================== # Kreuztabelle Geschlecht (sex) und Bildung (educ) - # relative Häufigkeit nach Gesamthäufigkeit # ohne Grafik allbus2018 %$% crosstab(sex, educ, weight = wghtpew, prop.t = T, plot = F) #&gt; Cell Contents #&gt; |-------------------------| #&gt; | Count | #&gt; | Total Percent | #&gt; |-------------------------| #&gt; #&gt; ==================================================================================== #&gt; ALLGEMEINER SCHULABSCHLUSS #&gt; GESCHLECHT, BEFRAGTE(R) 1 2 3 4 5 6 7 Total #&gt; ------------------------------------------------------------------------------------ #&gt; 1 31 445 519 185 570 12 13 1775 #&gt; 0.9% 12.8% 14.9% 5.3% 16.4% 0.3% 0.4% #&gt; ------------------------------------------------------------------------------------ #&gt; 2 23 408 575 140 531 10 11 1698 #&gt; 0.7% 11.7% 16.6% 4.0% 15.3% 0.3% 0.3% #&gt; ------------------------------------------------------------------------------------ #&gt; Total 54 853 1094 325 1101 22 24 3473 #&gt; ==================================================================================== # Kreuztabelle Geschlecht (sex) und Bildung (educ) - # relative Häufigkeit mit Chi-Quadrat nach Zellen # ohne Grafik allbus2018 %$% crosstab(sex, educ, weight = wghtpew, prop.chisq = T, plot = F) #&gt; Cell Contents #&gt; |-------------------------| #&gt; | Count | #&gt; | Chi-square contribution | #&gt; |-------------------------| #&gt; #&gt; ======================================================================================== #&gt; ALLGEMEINER SCHULABSCHLUSS #&gt; GESCHLECHT, BEFRAGTE(R) 1 2 3 4 5 6 7 Total #&gt; ---------------------------------------------------------------------------------------- #&gt; 1 31 445 519 185 570 12 13 1775 #&gt; 0.419 0.188 2.880 2.150 0.095 0.051 0.044 #&gt; ---------------------------------------------------------------------------------------- #&gt; 2 23 408 575 140 531 10 11 1698 #&gt; 0.438 0.196 3.010 2.247 0.099 0.053 0.046 #&gt; ---------------------------------------------------------------------------------------- #&gt; Total 54 853 1094 325 1101 22 24 3473 #&gt; ======================================================================================== # Kreuztabelle Geschlecht (sex) und Bildung (educ) - # relative Häufigkeit nach Spalten # mit Chi-Quadrat-Test # mit Grafik allbus2018 %$% crosstab(sex, educ, weight = wghtpew, prop.c = T, chisq = T, plot = F) #&gt; Cell Contents #&gt; |-------------------------| #&gt; | Count | #&gt; | Column Percent | #&gt; |-------------------------| #&gt; #&gt; ======================================================================================== #&gt; ALLGEMEINER SCHULABSCHLUSS #&gt; GESCHLECHT, BEFRAGTE(R) 1 2 3 4 5 6 7 Total #&gt; ---------------------------------------------------------------------------------------- #&gt; 1 31 445 519 185 570 12 13 1775 #&gt; 57.4% 52.2% 47.4% 56.9% 51.8% 54.5% 54.2% #&gt; ---------------------------------------------------------------------------------------- #&gt; 2 23 408 575 140 531 10 11 1698 #&gt; 42.6% 47.8% 52.6% 43.1% 48.2% 45.5% 45.8% #&gt; ---------------------------------------------------------------------------------------- #&gt; Total 54 853 1094 325 1101 22 24 3473 #&gt; 1.6% 24.6% 31.5% 9.4% 31.7% 0.6% 0.7% #&gt; ======================================================================================== #&gt; #&gt; Statistics for All Table Factors #&gt; #&gt; Pearson&#39;s Chi-squared test #&gt; ------------------------------------------------------------ #&gt; Chi^2 = 11.91607 d.f. = 6 p = 0.0639 #&gt; #&gt; Minimum expected frequency: 10.75612 # Grafik Weighted_chisqtest() Der Chi-Quadrat-Test kann mit der crosstab-Funktion direkt unterhalb der Kreuztabelle berechnet oder direkt mit der weighted_chisqtest()-Funktion. Syntax: # Ohne Pipe weighted_chisqtest(datensatz$variable1, datensatz$variable2, weights = datensatz$gewicht) # Mit Pipe datensatz %&gt;% weighted_chisqtest(variable1, variable2, weights = gewicht) Beispielcode: # Chi-Quadrat-Test Geschlecht (sex) und Bildung (educ) allbus2018 %&gt;% weighted_chisqtest(sex, educ, weights = wghtpew) #&gt; #&gt; # Measure of Association for Contingency Tables #&gt; #&gt; Chi-squared: 11.9161 #&gt; Cramer&#39;s V: 0.0586 #&gt; df: 6 #&gt; p-value: 0.064 #&gt; Observations: 3473 Crosstable_statistiscs() Die Funktion crosstable_statistics() können gängige Zusammenhangsmaße berechnet werden. Syntax: # Ohne Pipe crosstable_statistics(datensatz$vaiable1, datensatz$variable2, weights = datensatz$gewicht, statistics = c(&quot;phi&quot;, &quot;cramer&quot;, &quot;spearman&quot;, &quot;kendall&quot;, &quot;fisher&quot;)) # Mit Pipe allbus2018 %&gt;% crosstable_statistics(variable1, variable2, weights = gewicht, statistics = c(&quot;phi&quot;, &quot;cramer&quot;, &quot;spearman&quot;, &quot;kendall&quot;, &quot;fisher&quot;)) Beispielcode: # Phi Geschlecht (sex) und Ost West (eastwest) allbus2018 %&gt;% crosstable_statistics(sex, eastwest, weights = wghtpew, statistics = &quot;phi&quot;) #&gt; #&gt; # Measure of Association for Contingency Tables #&gt; #&gt; Chi-squared: 0.0769 #&gt; Phi: 0.0055 #&gt; df: 1 #&gt; p-value: 0.781 #&gt; Observations: 3477 # Cramers V Geschlecht (sex) und Bildung (educ) allbus2018 %&gt;% crosstable_statistics(sex, educ, weights = wghtpew, statistics = &quot;cramer&quot;) #&gt; #&gt; # Measure of Association for Contingency Tables #&gt; #&gt; Chi-squared: 11.9161 #&gt; Cramer&#39;s V: 0.0586 #&gt; df: 6 #&gt; p-value: 0.064 #&gt; Observations: 3473 # Spearman`s rho Leistungsprinzip (im19) und Befürwortung von Ungleichheit (im20) allbus2018 %&gt;% crosstable_statistics(im19, im20, weights = wghtpew, statistics = &quot;spearman&quot;) #&gt; #&gt; # Measure of Association for Contingency Tables #&gt; #&gt; S: 2913791351.3356 #&gt; Spearman&#39;s rho: 0.5148 #&gt; df: 9 #&gt; p-value: &lt; .001*** #&gt; Observations: 3298 Weighted_correlation() Mit weighted_correlation berechnen wir den Korrelationskoeffizienten nach Pearson. Ausgeben wird der Wert des Korrelationskoeffizienten, die Werte für ein Konfidenzintervall von 95% in eckigen Klammern und der p-Wert, Syntax: # Ohne Pipe weighted_correlation(datensatz$variable1, datensatz$variable2, weights = datensatz$gewicht) # Mit Pipe datensatz %&gt;% weighted_correlation(variable1, variable2, weights = gewicht) Beispielcode: # Pearson`s r Leistungsprinzip (im19) und Befürwortung von Ungleichheit (im20) allbus2018 %&gt;% weighted_correlation(im19, im20, weights = wghtpew) #&gt; #&gt; Weighted Pearson&#39;s Correlation Coefficient #&gt; #&gt; estimate [95% CI]: 0.515 [0.493 0.536] #&gt; p-value: 0.000 4.4 Mittelwertvergleiche (unabhängig) Für Mittelwertvergleiche können mit folgenden Funktionen t-Tests, einfaktorielle ANOVAs und der Mann-Whitney-Test bzw. Kruskall-Wallis-Test berechnet werden. Packet Funktion Verwendung sjstats weighted_ttest() T-Test sjstats grpmean() Einfaktorielle ANOVA sjstats weighted_mannwhitney() Mann-Whitney-Test / Kruskall-Wallis-Test Weighted_ttest() Den t-Test berechnen wir mit der Funktion weighted_ttest(). Als Testergebnis werden der t-Wert, die Freiheitsgrade (df) und der P-Wert ausgegeben. Darunter wird der Mittelwert für beide Gruppen, die Mittelwertdifferenz sowie das 95%-Konfidenzintervall der Mittelwertdifferenz (in eckigen Klammern) ausgegeben. Syntax: # Ohne Pipe weighted_ttest(variable1 ~ gruppenvariable + gewicht, datensatz) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # T-Test zu Leistungsprinzip (im19) zwischen Geschlecht (sex) weighted_ttest(im19 ~ sex + wghtpew, allbus2018) #&gt; #&gt; Two-Sample t-test (two.sided) #&gt; #&gt; # comparison of im19 by sex #&gt; # t=-6.06 df=3338 p-value=0.000 #&gt; #&gt; mean in group [1] MANN: 2.393 #&gt; mean in group [2] FRAU: 2.587 #&gt; difference of mean : -0.195 [-0.257 -0.132] Grpmean() Für einen Mittelwertvergleich über mehr als zwei Gruppen können wir mit der grpmean-Funktion eine einfaktorielle ANOVA berechnen. Ausgeben werden für jede Gruppe der Mittelwert, das N, die Standardabweichung, der Standardfehler sowie der p-Wert für den Mittelwertunterschied zum Mittelwert des gesamten Samples. Für die ANOVA werden der R-Quadrat-Wert, der korregierte R-Quadart-Wert, der F-Wert und der p-Wert ausgegeben. Syntax: # Ohne Pipe grpmean(datensatz$variable1, datensatz$gruppenvariable, weights = datensatz$gewicht) # Mit Pipe datensatz %&gt;% grpmean(variable1, gruppenvariable, gewicht) Beispielcode: # Einfaktorielle Anova Leistungsprinzip (im19) zwischen Bildungsniveau (educ) # P-Wert in Relation zu absolutem Mittelwert allbus2018 %&gt;% grpmean(im19, educ, weights = wghtpew) #&gt; #&gt; # Grouped Means for EINKOMMENSDIFFERENZ ERHOEHT MOTIVATION by ALLGEMEINER SCHULABSCHLUSS #&gt; #&gt; Category | Mean | N | SD | SE | p #&gt; ------------------------------------------------------- #&gt; OHNE ABSCHLUSS | 2.29 | 45 | 0.90 | 0.14 | 0.451 #&gt; VOLKS-,HAUPTSCHULE | 2.20 | 817 | 0.92 | 0.03 | &lt; .001 #&gt; MITTLERE REIFE | 2.51 | 1058 | 0.94 | 0.03 | 0.080 #&gt; FACHHOCHSCHULREIFE | 2.49 | 323 | 0.87 | 0.05 | 0.269 #&gt; HOCHSCHULREIFE | 2.70 | 1081 | 0.91 | 0.03 | &lt; .001 #&gt; ANDERER ABSCHLUSS | 2.24 | 20 | 1.01 | 0.24 | 0.451 #&gt; NOCH SCHUELER | 2.38 | 22 | 0.76 | 0.17 | 0.885 #&gt; Total | 2.49 | 3370 | 0.93 | 0.02 | #&gt; #&gt; Anova: R2=0.041; adj.R2=0.039; F=23.736; p=0.000 # Einfaktorielle Anova Leistungsprinzip (im19) zwischen Bildungsniveau (educ) # nach Geschlecht (sex) # P-Wert in Relation zu absolutem Mittelwert allbus2018 %&gt;% group_by(sex) %&gt;% grpmean(im19, educ, weights = wghtpew) #&gt; #&gt; Grouped by: #&gt; GESCHLECHT, BEFRAGTE(R): MANN #&gt; #&gt; # Grouped Means for EINKOMMENSDIFFERENZ ERHOEHT MOTIVATION by ALLGEMEINER SCHULABSCHLUSS #&gt; #&gt; Category | Mean | N | SD | SE | p #&gt; ------------------------------------------------------ #&gt; OHNE ABSCHLUSS | 2.31 | 28 | 0.94 | 0.18 | 0.869 #&gt; VOLKS-,HAUPTSCHULE | 2.15 | 435 | 0.89 | 0.04 | 0.103 #&gt; MITTLERE REIFE | 2.45 | 506 | 0.93 | 0.04 | 0.076 #&gt; FACHHOCHSCHULREIFE | 2.42 | 183 | 0.83 | 0.06 | 0.146 #&gt; HOCHSCHULREIFE | 2.54 | 564 | 0.90 | 0.04 | 0.001 #&gt; ANDERER ABSCHLUSS | 1.79 | 11 | 0.64 | 0.20 | 0.076 #&gt; NOCH SCHUELER | 2.35 | 12 | 0.82 | 0.25 | 0.869 #&gt; Total | 2.39 | 1733 | 0.91 | 0.02 | #&gt; #&gt; Anova: R2=0.030; adj.R2=0.026; F=8.815; p=0.000 #&gt; #&gt; #&gt; Grouped by: #&gt; GESCHLECHT, BEFRAGTE(R): FRAU #&gt; #&gt; # Grouped Means for EINKOMMENSDIFFERENZ ERHOEHT MOTIVATION by ALLGEMEINER SCHULABSCHLUSS #&gt; #&gt; Category | Mean | N | SD | SE | p #&gt; ------------------------------------------------------- #&gt; OHNE ABSCHLUSS | 2.24 | 17 | 0.85 | 0.22 | 0.323 #&gt; VOLKS-,HAUPTSCHULE | 2.25 | 383 | 0.94 | 0.05 | 0.001 #&gt; MITTLERE REIFE | 2.57 | 552 | 0.94 | 0.04 | 0.713 #&gt; FACHHOCHSCHULREIFE | 2.58 | 139 | 0.92 | 0.08 | 0.713 #&gt; HOCHSCHULREIFE | 2.87 | 517 | 0.89 | 0.04 | &lt; .001 #&gt; ANDERER ABSCHLUSS | 2.87 | 8 | 1.12 | 0.40 | 0.418 #&gt; NOCH SCHUELER | 2.41 | 10 | 0.73 | 0.24 | 0.713 #&gt; Total | 2.59 | 1637 | 0.95 | 0.02 | #&gt; #&gt; Anova: R2=0.060; adj.R2=0.056; F=17.300; p=0.000 Weighted_mannwhitney() Zur Berechnung des Mann-Whitney-Tests bzw. des Kruskall-Wallis-Tests verwenden wir die Funktion weighted_mannwhitney(). Syntax: # Ohne Pipe weighted_mannwhitney(variable1 ~ gruppenvariable + gewicht, datensatz) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Mann-Whitney-Test Leistungsprinzip (im19) nach Geschlecht (sex) weighted_mannwhitney(im19 ~ sex + wghtpew, allbus2018) #&gt; #&gt; # Weighted Mann-Whitney-U test #&gt; #&gt; comparison of im19 by sex #&gt; Chisq=5.88 df=3371 p-value=0.000 # Kruskall-Wallis-Test Leistungsprinzip (im19) nach Geschlecht (sex) weighted_mannwhitney(im19 ~ educ + wghtpew, allbus2018) #&gt; #&gt; # Weighted Kruskal-Wallis test #&gt; #&gt; comparison of im19 by educ #&gt; Chisq=6.00 df=130 p-value=0.000 4.5 Grafiken Zur grafischen Aufbereitung einiger der vorhergehenden univariaten und bivariaten Analysen bietet das Paket sjplot verschiedene Möglichkeiten an, mit wenigen Zielen Code Grafiken zu erstellen. Diese können exportiert und direkt in Ergebnisberichte verwendet werden. Packet Funktion Verwendung sjplot plot_frq() Grafiken zu univariaten Häufigkeitsverteilungen sjplot plot_likert() Grafiken zu univariaten Häufigkeitsverteilungen bei Likert-Items sjplot plot_stackfrq() Grafiken als univariate Balkenschichtungsdiagramme sjplot plot_grpfrq() Grafiken zu univariaten Häufigkeitsverteilungen nach Gruppen sjplot plot_xtab() Grafiken als Kreuztabellendiagramme Plot_frq() Mit der Funktion plot_frq() können verschiedene Grafiken zu univariaten Häufigkeitsverteilungen erstellt werden. Im default wird dabei ein einfaches Balkendiagramm erstellt, welches die absolute Anzahl der Befragten pro Kategorie sowie deren prozentualen Anteil an der Gesamtverteilung abbildet. Mit verschiedenen Argumenten (Übersicht mit ?plot_frq abrufbar) kann die Grafik entsprechend den eigenen Wünschen angepasst werden. In den Beispiele sind hierfür verschiedene Möglichkeiten aufgeführt. ACHTUNG: In der Pipe-Schreibeweise muss hier der %$%-Operator verwendet werden. Syntax: # Ohne Pipe plot_frq(datensatz$variable1, weight.by = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% plot_frq(variable1, weight.by = gewicht) Beispielcode: # Grafik zur Häufigkeitsverteilung Bildung (educ) allbus2018 %$% plot_frq(educ, weight.by = wghtpew, coord.flip = T, hjust = &quot;left&quot;, type = &quot;dot&quot;, show.ci = T, expand.grid = T, vjust = &quot;bottom&quot;, sort.frq = &quot;desc&quot;) # Grafik zur Häufigkeitsverteilung Alter (age) # mit Normalverteilungskurve, Mittelwert und Standardabweichung allbus2018 %$% plot_frq(age, weight.by = wghtpew, type = &quot;h&quot;, show.mean = TRUE, show.mean.val = TRUE, normal.curve = TRUE, show.sd = TRUE, normal.curve.color = &quot;black&quot;, geom.size = .3, xlim = c(15, 100)) # Grafik zur Häufigkeitsverteilung Alter (age) allbus2018 %$% plot_frq(age, weight.by = wghtpew, type = &quot;violin&quot;, show.values = F) Plot_likert() Um Häufigkeitsverteilungen verschiedener Likert-Items im Vergleich zu darzustellen bietet das sjplot-Paket mit der plot_likert Funktion eine sehr praktische Lösung an. Wie bei der vorherigen Funktion können über diverse Argumente die Grafik entsprechend den eigenen Vorstellungen angepasst werden. Auch hier bieten die aufgeführten Beispiele erste Orientierungen, welche Möglichkeiten bestehen. Syntax: # Ohne Pipe plot_likert(datensatz$variable1, weight.by = datensatz$gewicht) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Grafik zur Verteilung von Ausprägungsmerkmalen bei Likert-Items plot_likert(allbus2018[c(&quot;im19&quot;, &quot;im20&quot;, &quot;im21&quot;, &quot;id01&quot;)], grid.range = c(.8, .8), wrap.legend.labels = 11, wrap.labels = 12, values = &quot;sum.inside&quot;, show.prc.sign = T, weight.by = allbus2018$wghtpew) # Grafik zur Verteilung von Ausprägungsmerkmalen bei Likert-Items nach Komponenten plot_likert(allbus2018[c(&quot;im19&quot;, &quot;im20&quot;, &quot;im21&quot;, &quot;id01&quot;)], c(1,1,2,2), grid.range = c(1.1, 1.1), values = &quot;sum.outside&quot;, show.prc.sign = T, weight.by = allbus2018$wghtpew, legend.pos = &quot;none&quot;) Plot_stackfrq() Mit der plot_stackfrq() Funktion können Balkenschichtungsdiagramme erstellt werden. Syntax: # Ohne Pipe plot_stackfrq(datensatz$variable1, weight.by = datensatz$gewicht) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Verteilung von Ausprägungsmerkmalen in einem Balkenschichtungsdiagramm # Farbauswahl mit RColorBrewer::display.brewer.all() plot_stackfrq(allbus2018[c(&quot;im19&quot;, &quot;im20&quot;, &quot;im21&quot;, &quot;id01&quot;)], weight.by = allbus2018$wghtpew, expand.grid = T, geom.colors = &quot;Greens&quot;, wrap.labels = 12, wrap.legend.labels = 11) Plot_grpfrq() Um die Häufigkeitsverteilung für verschiedene Gruppen im Vergleich abzubilden, verwenden wir die Funktion plot_grpfrq(). Diese Funktion bietet mit dem Argument show.summary auch an, die Chi-Quadart Statistiken in die Grafik zu integrieren. Auch für diese Funktion bieten die aufgeführten Beispiele einen ersten Überblick über die verschieden Möglichkeiten. Syntax: # Ohne Pipe plot_frq(datensatz$variable1, datensatz$gruppenvariable, weight.by = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% plot_frq(variable1, gruppenvariable, weight.by = gewicht) Beispielcode: # Verteilung Alter (age) nach Geschlecht (sex) und Statistiken allbus2018 %$% plot_grpfrq(age, sex, weight.by = wghtpew, show.values = F, type = &quot;line&quot;, show.summary = T, summary.pos = 1) # Verteilung Leistungsprinzip (im19) nach Schichtzugehörigkeit (id02) allbus2018 %$% plot_grpfrq(im19, id02, weight.by = wghtpew, show.values = F, type = &quot;boxplot&quot;) # Verteilung Leistungsprinzip (im19) nach Geschlecht (sex) und Statistiken allbus2018 %$% plot_grpfrq(im19, sex, weight.by = wghtpew, type = &quot;bar&quot;, show.summary = T, summary.pos = &quot;1&quot;, ylim = c(0, 850)) # Verteilung Leistungsprinzip (im19) nach Geschlecht (sex) und Ost West (eastwest) # und Statistiken allbus2018 %$% plot_grpfrq(im19, sex, intr.var = eastwest, weight.by = wghtpew, type = &quot;violin&quot;, show.summary = T, summary.pos = &quot;1&quot;) Plot_xtab() Mit der Funktion plot_xtab() können Kreuztabellen grafisch dargestellt werden. Auch diese Funktion bietet verschiedene Möglichkeiten über Argumente die Grafik den eigenen Bedürfnissen anzupassen. Syntax: # Ohne Pipe plot_xtab(datensatz$variable1, datensatz$variable2, weight.by = datensatz$gewicht) # Mit Pipe # Achtung! %$% Operator datensatz %$% plot_xtab(variable1, variable2, weight.by = gewicht) Beispielcode: # Verteilung soziale Ungleichheit aus Makroperspektive (im21) nach Ost West (eastwest) # und Statistiken allbus2018 %$% plot_xtab(im21, eastwest, weight.by = wghtpew, type = &quot;line&quot;, show.total = F, show.n = F, show.summary = T, summary.pos = &quot;1&quot;) Grid.arrange() Wenn wir mehrere Plots erstellen, welche zusammen berichtet werden sollen, bietet es sich mitunter an, sie mit der Funktion grid.arrange() in einer Grafik vor dem Exportieren zusammen zu fassen. Die Funktion grid.arrange() entnehmen wir aus dem Paket gridExtra. Zur Anordnung der gewünschten Plots erstellen wir zunächst die einzelnen Plots als neues Objekt. Anschließend definieren wir mit der Funktion grid.arrange() wie diese zueinander angeordnet werden sollen. library(gridExtra) Syntax: # Ohne Pipe grid.arrange(arrangeGrob(abbildung1, abbildung2)) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Verteilung Alter (age) nach Geschlecht (sex) zwischen Ost West (eastwest) p1 &lt;- allbus2018 %&gt;% filter(eastwest == 1) %$% plot_grpfrq(age, sex, weight.by = wghtpew, type = &quot;violin&quot;, show.summary = T, summary.pos = &quot;1&quot;, title = &quot;ALTER nach GESCHLECHT - WEST&quot;, geom.colors = &quot;Blues&quot;) p2 &lt;- allbus2018 %&gt;% filter(eastwest == 2) %$% plot_grpfrq(age, sex, weight.by = wghtpew, type = &quot;violin&quot;, show.summary = T, summary.pos = &quot;1&quot;, title = &quot;ALTER nach GESCHLECHT - OST&quot;, geom.colors = &quot;Greens&quot;) # -------- pp1 &lt;- grid.arrange(arrangeGrob(p1, p2, nrow = 1)) pp1 #&gt; TableGrob (1 x 1) &quot;arrange&quot;: 1 grobs #&gt; z cells name grob #&gt; 1 1 (1-1,1-1) arrange gtable[arrange] Ggsave() Wenn wir mit der grafischen Aufbereitung unserer Ergebnisse zufrieden sind, können wir diese mit der Funktion ggsave() exportieren. Syntax: # Ohne Pipe ggsave(&quot;Grafik.png&quot;, plot = last_plot(), dpi = 300) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: ggsave(&quot;grid.plot.png&quot;, plot = pp1, dpi = 300) #&gt; Saving 7 x 5 in image "],["multivariate-datenanalyse.html", "5 Multivariate Datenanalyse 5.1 Korrelationsmatrix 5.2 Explorative Faktoranalyse und Hauptkomponentenanalyse 5.3 Konfirmatorische Faktorenanalyse 5.4 Realiabilitätsanalyse 5.5 Regressionsanalyse", " 5 Multivariate Datenanalyse In diesem Kapitel werden unsere Ansätze vorgestellt, um multivariate Datenanalysen in R durchzuführen. Dabei müssen wir an verschiedenen Stellen auf andere Pakete zurück greifen, um die Analysen durchzuführen. Zwar beinhalten auch die bisher verwendeten Pakete tw. multivariate Analysemöglichkeiten, doch häufig ohne die Möglichkeit die Analysen auch zu gewichten. Das Kaptiel umfasst die Korrelationsanalyse, Faktorenanalysen und Regressionsanalysen. 5.1 Korrelationsmatrix Packet Funktion Verwendung weights wtd.cor() Korrelationsmatrix corrplot corrplot() Grafiken zu Korrelationsanalysen Wtd.cor() Zur Berechnung der Korrelationsmatrix verwenden wir die wtd.cor() Funktion aus dem weights Paket. In getrennter tabellarischen Darstellung werden die Korrelationskoeffizienten, die Standardfehler, die t-Werte sowie die p-Werte ausgegeben. library(weights) Syntax: # Ohne Pipe wtd.cor(datensatz[c(&quot;Variable1&quot;, &quot;variable2&quot;, &quot;variable3&quot;)], weight = datensatz$gewicht) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Datensatz erstellen ds &lt;- allbus2018 %&gt;% select(im19:im21, id01, wghtpew) #Berechnung der Korrelationsmatrix corMatrix &lt;- wtd.cor(ds[1:4], weight = ds$wghtpew) corMatrix #&gt; $correlation #&gt; im19 im20 im21 id01 #&gt; im19 1.00000000 0.51469202 0.3452849 0.03606102 #&gt; im20 0.51469202 1.00000000 0.5031235 -0.02409378 #&gt; im21 0.34528492 0.50312350 1.0000000 -0.16428931 #&gt; id01 0.03606102 -0.02409378 -0.1642893 1.00000000 #&gt; #&gt; $std.err #&gt; im19 im20 im21 id01 #&gt; im19 7.895494e-17 1.492272e-02 1.624389e-02 1.737802e-02 #&gt; im20 1.492272e-02 1.144824e-15 1.495593e-02 1.739744e-02 #&gt; im21 1.624389e-02 1.495593e-02 9.207409e-16 1.702737e-02 #&gt; id01 1.737802e-02 1.739744e-02 1.702737e-02 4.070850e-17 #&gt; #&gt; $t.value #&gt; im19 im20 im21 id01 #&gt; im19 1.266545e+16 3.449049e+01 2.125629e+01 2.075094e+00 #&gt; im20 3.449049e+01 8.734970e+14 3.364041e+01 -1.384903e+00 #&gt; im21 2.125629e+01 3.364041e+01 1.086082e+15 -9.648546e+00 #&gt; id01 2.075094e+00 -1.384903e+00 -9.648546e+00 2.456490e+16 #&gt; #&gt; $p.value #&gt; im19 im20 im21 id01 #&gt; im19 0.000000e+00 6.726140e-223 3.831939e-94 3.805500e-02 #&gt; im20 6.726140e-223 0.000000e+00 6.568035e-214 1.661756e-01 #&gt; im21 3.831939e-94 6.568035e-214 0.000000e+00 9.526801e-22 #&gt; id01 3.805500e-02 1.661756e-01 9.526801e-22 0.000000e+00 Corrplot() Für die grafische Aufbereitung der Korrelationsmatrix bietet das Paket corrplot mit der Funktion corrplot eine einfache, aber anschauliche Möglichkeit. Auch für diese Funktion stehen eine Reihe verschiedener Argumente zur Verfügung, mit denen die Grafik angepasst werden kann. library(corrplot) Syntax: # Ohne Pipe corrplot(korrelationsmatrix, method=number) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Grafik der Korrelationsmatrix erstellen # Achtung! Die Funktionen corrplot() und corrplot.mixed laufen noch nicht 100% stabil corrplot(corMatrix$correlation, p.mat = corMatrix$p.value, method = &quot;circle&quot;, tl.col = &quot;black&quot;, addCoef.col = &quot;black&quot;, cl.cex = .7, number.cex = .7, insig = &quot;pch&quot;) 5.2 Explorative Faktoranalyse und Hauptkomponentenanalyse Für die explorative Faktorenanalyse werdeb im folgenden zwei gängige Tests zur Prüfung der Voraussetzung (KMO, Bartlett), eine grafische Veranschaulichung zur Bestimmung der Anzahl der Faktoren (Screeplot), die Hauptkomponentenanalyse, die Faktorenanalyse sowie eine einfache Möglichkeit der grafischen Darstellung der Faktorenstruktur angeboten. Die notwendigen Funktionen entnehmen wir dabei überwiegend aus dem psych Paket. Packet Funktion Verwendung psych KMO() Kaiser-Meyer-Olkin-Kriterium (MSA) stats bartlett.test() Bartlett-Test psych scree() Scree-Test psych principal() Hauptkomponentenanalyse psych fa() Faktoranalyse psych fa_diagram() Grafik library(psych) KMO() Das Kaiser-Meyer-Olkin-Kriterium berechnen wir mit der Funktion KMO(). Ausgegeben wird KMO (bzw. MSA) gesamt sowie einzeln für jedes Item. Achtung! Ungewichtete Analyse. Syntax: # Ohne Pipe KMO(datensatz[c(&quot;Variable1&quot;, &quot;variable2&quot;, &quot;variable3&quot;)]) # Mit Pipe datensatz %&gt;% select(variable1, variable2, variable3) %&gt;% KMO() Beispielcode: # KMO/MSA allbus2018 %&gt;% select(im19:im21, id01) %&gt;% KMO() #&gt; Kaiser-Meyer-Olkin factor adequacy #&gt; Call: KMO(r = .) #&gt; Overall MSA = 0.63 #&gt; MSA for each item = #&gt; im19 im20 im21 id01 #&gt; 0.66 0.61 0.66 0.45 Bartlett.test() Den Bartlett Test führen wir mit der Funktion bartlett.test aus. Ausgegeben werden die Test Statistics, die Freiheitsgrade sowie der p-wert. Achtung! Ungewichtete Analyse. Syntax: # Ohne Pipe bartlett.test(datensatz[c(&quot;Variable1&quot;, &quot;variable2&quot;, &quot;variable3&quot;)]) # Mit Pipe datensatz %&gt;% select(variable1, variable2, variable3) %&gt;% bartlett.test() Beispielcode: # Bartlett-Test allbus2018 %&gt;% select(im19:im21, id01) %&gt;% bartlett.test() #&gt; #&gt; Bartlett test of homogeneity of variances #&gt; #&gt; data: . #&gt; Bartlett&#39;s K-squared = 299.4, df = 3, p-value &lt; 2.2e-16 Scree() Einen Screeplot können wir mit der Funktion scree() abrufen. Im default wird dabei der Graph für Komponenten und Faktoren angezeigt und zur Lesehilfe eine horizontale Linie bei einem Eigenwert von 1.0 gezeichnet. Achtung! Ungewichtete Analyse. Syntax: # Ohne Pipe scree(datensatz[c(&quot;Variable1&quot;, &quot;variable2&quot;, &quot;variable3&quot;)]) # Mit Pipe datensatz %&gt;% select(variable1, variable2, variable3) %&gt;% scree() Beispielcode: # Scree-Plot allbus2018 %&gt;% select(im19:im21, id01) %&gt;% scree() Principal() Für eine Hauptkomponentenanalyse verwenden wir die Funktion principal(). Über die Argumente können verschiedene Spezifikationen wie beispielweise die Anzahl der zu extrahierenden Komponenten (nfactors) oder die Rotationsmethode (rotate) festgelegt werden. Syntax: # Ohne Pipe principal(datensatz[c(&quot;Variable1&quot;, &quot;variable2&quot;, &quot;variable3&quot;)], weight = datensatz$gewicht, nfactors = 1, rotate = &quot;varimax&quot;, use = &quot;pairwise&quot;, scores = T) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Datensatz erstellen ds &lt;- allbus2018 %&gt;% select(im19:im21, id01, wghtpew) # Hauptkomponentenanalyse pca &lt;- principal(ds[1:4], weight = ds$wghtpew, nfactors = 2, rotate = &quot;varimax&quot;, use = &quot;pairwise&quot;) pca #&gt; Principal Components Analysis #&gt; Call: principal(r = ds[1:4], nfactors = 2, rotate = &quot;varimax&quot;, use = &quot;pairwise&quot;, #&gt; weight = ds$wghtpew) #&gt; Standardized loadings (pattern matrix) based upon correlation matrix #&gt; RC1 RC2 h2 u2 com #&gt; im19 0.79 0.17 0.65 0.351 1.1 #&gt; im20 0.86 0.00 0.73 0.268 1.0 #&gt; im21 0.74 -0.31 0.65 0.355 1.4 #&gt; id01 0.00 0.96 0.93 0.071 1.0 #&gt; #&gt; RC1 RC2 #&gt; SS loadings 1.90 1.06 #&gt; Proportion Var 0.47 0.26 #&gt; Cumulative Var 0.47 0.74 #&gt; Proportion Explained 0.64 0.36 #&gt; Cumulative Proportion 0.64 1.00 #&gt; #&gt; Mean item complexity = 1.1 #&gt; Test of the hypothesis that 2 components are sufficient. #&gt; #&gt; The root mean square of the residuals (RMSR) is 0.14 #&gt; with the empirical chi square 813.23 with prob &lt; NA #&gt; #&gt; Fit based upon off diagonal values = 0.82 # Ladungen (Übersichtlicher) print(pca$loadings, digits = 2, cutoff = .2) #&gt; #&gt; Loadings: #&gt; RC1 RC2 #&gt; im19 0.79 #&gt; im20 0.86 #&gt; im21 0.74 -0.31 #&gt; id01 0.96 #&gt; #&gt; RC1 RC2 #&gt; SS loadings 1.90 1.06 #&gt; Proportion Var 0.47 0.26 #&gt; Cumulative Var 0.47 0.74 Fa() Eine explorative Faktorenanalyse führen wir über die Funktion fa() aus. Auch wie bei der vorherigen Funktionen können die Spezifikationen der Analyse über die Argumente festgelegt werden. Syntax: # Ohne Pipe fa(datensatz[c(&quot;Variable1&quot;, &quot;variable2&quot;, &quot;variable3&quot;)], weight = datensatz$gewicht, nfactors = 1, rotate = &quot;varimax&quot;, use = &quot;pairwise&quot;, scores = &quot;regression&quot;) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Datensatz erstellen ds &lt;- allbus2018 %&gt;% select(im19:im21, id01, wghtpew) # Hauptkomponentenanalyse fa &lt;- fa(ds[1:4], weight = ds$wghtpew, nfactors = 2, rotate = &quot;varimax&quot;, use = &quot;pairwise&quot;, scores = &quot;regression&quot;) fa #&gt; Factor Analysis using method = minres #&gt; Call: fa(r = ds[1:4], nfactors = 2, rotate = &quot;varimax&quot;, scores = &quot;regression&quot;, #&gt; use = &quot;pairwise&quot;, weight = ds$wghtpew) #&gt; Standardized loadings (pattern matrix) based upon correlation matrix #&gt; MR1 MR2 h2 u2 com #&gt; im19 0.64 0.10 0.42 0.58 1.0 #&gt; im20 0.81 -0.04 0.65 0.35 1.0 #&gt; im21 0.59 -0.37 0.49 0.51 1.7 #&gt; id01 0.00 0.42 0.18 0.82 1.0 #&gt; #&gt; MR1 MR2 #&gt; SS loadings 1.41 0.33 #&gt; Proportion Var 0.35 0.08 #&gt; Cumulative Var 0.35 0.43 #&gt; Proportion Explained 0.81 0.19 #&gt; Cumulative Proportion 0.81 1.00 #&gt; #&gt; Mean item complexity = 1.2 #&gt; Test of the hypothesis that 2 factors are sufficient. #&gt; #&gt; The degrees of freedom for the null model are 6 and the objective function was 0.63 with Chi Square of 2202.75 #&gt; The degrees of freedom for the model are -1 and the objective function was 0 #&gt; #&gt; The root mean square of the residuals (RMSR) is 0 #&gt; The df corrected root mean square of the residuals is NA #&gt; #&gt; The harmonic number of observations is 3341 with the empirical chi square 0 with prob &lt; NA #&gt; The total number of observations was 3477 with Likelihood Chi Square = 0 with prob &lt; NA #&gt; #&gt; Tucker Lewis Index of factoring reliability = 1.003 #&gt; Fit based upon off diagonal values = 1 #&gt; Measures of factor score adequacy #&gt; MR1 MR2 #&gt; Correlation of (regression) scores with factors 0.87 0.56 #&gt; Multiple R square of scores with factors 0.76 0.32 #&gt; Minimum correlation of possible factor scores 0.52 -0.36 # Ladungen (Übersichtlicher) print(fa$loadings, digits = 2, cutoff = .2) #&gt; #&gt; Loadings: #&gt; MR1 MR2 #&gt; im19 0.64 #&gt; im20 0.81 #&gt; im21 0.59 -0.37 #&gt; id01 0.42 #&gt; #&gt; MR1 MR2 #&gt; SS loadings 1.41 0.33 #&gt; Proportion Var 0.35 0.08 #&gt; Cumulative Var 0.35 0.43 Fa.diagram() Eine einfache grafische Aufbereitung der durchgeführten Analysen (Hauptkomponenten- bzw. Faktorenanalysen) kann mit der Funktion fa.diagram() erstellt werden. Die folgenden Beispiele illustieren dies für die beiden vorherigen Analysen. Syntax: # Ohne Pipe fa.diagram(modell) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # PCA fa.diagram(pca) # FA fa.diagram(fa) 5.3 Konfirmatorische Faktorenanalyse Wir wollen an dieser Stelle kurz auf Möglichkeiten konfirmatorischer Faktorenanalyse eingehen. Dies geschieht hier vor allem aus dem Grund, da über diesen kleinen Umweg eine gewichtete Realiabilitätsanalyse durchführbar ist. Eine andere Möglichkeit gewichtete Realiabilitätsanalysen zu berechnen ist uns derzeit nicht bekannt. Zur Berechnung konfirmatorischen Faktorenanalyse verwenden wir die cfa() Funktion aus dem lavaanPaket, welches vor allem auch zur Strukturgleichungsmodellierung eignesetzt werden kann. Mit der semPath()Funktion (aus dem semPlot Paket) können wir die berechnete Faktorenanalyse grafisch aufbereiten. Packet Funktion Verwendung lavaan cfa() Konfirmatorische Faktorenanalyse semPlot semPaths() Grafik library(lavaan) library(semPlot) 5.3.0.1 Modellspezifikation Zur Berechnung der konfirmatorischen Faktorenanalyse müssen wir zunächst das Modell spezifizieren. Mit faktorname, =~ und den folgenden Variablen legen wir die Faktorenstruktur fest. Für Details zur verwendeten Syntax kann sich auf den Hilfeseiten des lavaan Pakets weitergehend informiert werden. m1 &lt;- &quot;faktor =~ im19 + im20 + im21 + id01&quot; Cfa() Mit der cfa Funktion berechnen wir unser Modell, welche wir unter m1 spezifiziert haben. Wir speichern das Ergebnis als neues Objekt cfa ab und lassen uns die mit den Argumenten festgelegten Werte mit der summary Funktion ausgeben. Syntax: # ohne Pipe cfa(model = modell, data = datensatz[c(&quot;Variable1&quot;, &quot;variable2&quot;, &quot;variable3&quot;)], sampling.weights = &quot;gewicht&quot;, estimator = &quot;MLR&quot;) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: # Datensatz erstellen ds &lt;- allbus2018 %&gt;% select(im19:im21, id01, wghtpew) # Faktorenanalyse cfa &lt;- cfa(model = m1, data = ds, sampling.weights = &quot;wghtpew&quot;, estimator = &quot;MLR&quot;) summary(cfa, fit.measures = T, standardized = T, rsquar = T) #&gt; lavaan 0.6-10 ended normally after 21 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 8 #&gt; #&gt; Used Total #&gt; Number of observations 3227 3477 #&gt; Sampling weights variable wghtpew #&gt; #&gt; Model Test User Model: #&gt; Standard Robust #&gt; Test Statistic 124.514 119.760 #&gt; Degrees of freedom 2 2 #&gt; P-value (Chi-square) 0.000 0.000 #&gt; Scaling correction factor 1.040 #&gt; Yuan-Bentler correction (Mplus variant) #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 2117.930 1603.994 #&gt; Degrees of freedom 6 6 #&gt; P-value 0.000 0.000 #&gt; Scaling correction factor 1.320 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 0.942 0.926 #&gt; Tucker-Lewis Index (TLI) 0.826 0.779 #&gt; #&gt; Robust Comparative Fit Index (CFI) 0.942 #&gt; Robust Tucker-Lewis Index (TLI) 0.826 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -14929.146 -14929.146 #&gt; Scaling correction factor 1.153 #&gt; for the MLR correction #&gt; Loglikelihood unrestricted model (H1) -14866.889 -14866.889 #&gt; Scaling correction factor 1.131 #&gt; for the MLR correction #&gt; #&gt; Akaike (AIC) 29874.293 29874.293 #&gt; Bayesian (BIC) 29922.927 29922.927 #&gt; Sample-size adjusted Bayesian (BIC) 29897.508 29897.508 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.138 0.135 #&gt; 90 Percent confidence interval - lower 0.118 0.115 #&gt; 90 Percent confidence interval - upper 0.159 0.156 #&gt; P-value RMSEA &lt;= 0.05 0.000 0.000 #&gt; #&gt; Robust RMSEA 0.138 #&gt; 90 Percent confidence interval - lower 0.117 #&gt; 90 Percent confidence interval - upper 0.159 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.049 0.049 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Sandwich #&gt; Information bread Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; faktor =~ #&gt; im19 1.000 0.560 0.596 #&gt; im20 1.380 0.064 21.512 0.000 0.773 0.865 #&gt; im21 0.843 0.038 22.336 0.000 0.472 0.583 #&gt; id01 -0.062 0.027 -2.262 0.024 -0.035 -0.050 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .im19 0.569 0.021 27.188 0.000 0.569 0.645 #&gt; .im20 0.202 0.028 7.246 0.000 0.202 0.252 #&gt; .im21 0.434 0.017 25.717 0.000 0.434 0.660 #&gt; .id01 0.490 0.013 37.103 0.000 0.490 0.998 #&gt; faktor 0.314 0.021 14.696 0.000 1.000 1.000 #&gt; #&gt; R-Square: #&gt; Estimate #&gt; im19 0.355 #&gt; im20 0.748 #&gt; im21 0.340 #&gt; id01 0.002 semPaths() Mit der semPath Funktion kann eine grafische Aufbereitung der Faktorenanalyse erstellt werden. Auch hier können über verschiedene Argumente der Funktion die Grafik den eigenen Wünschen angepasst werden. Syntax: # ohne Pipe semPaths(object = cfa-Objekt, whatLabels = &quot;std&quot;, layout = &quot;tree&quot;, edge.color = &quot;black&quot;) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: semPaths(cfa, whatLabels = &quot;std&quot;, layout = &quot;tree&quot;, edge.color = &quot;black&quot;) 5.4 Realiabilitätsanalyse Mit der reliability() Funktion aus dem semTools Paket können wir nun im Anschluss an die berechnete konfirmatorische Faktorenanalyse die Realiabilitätsanalyse durchführen. Packet Funktion Verwendung semTools reliability() Reliabilitätsmaße library(semTools) reliability() Zur Berechnung der Realiabilität setzen wir einfach die im Objekt cfa gespeicherten Ergebnisse der konfirmatorischen Faktorenanalyse in die realiability() Funktion ein. Syntax: # ohne Pipe reliability(object = cfa-Objekt) # Mit Pipe # Nicht gut zu handhaben! Beispielcode: reliability(cfa) ## faktor ## alpha 0.5428065 ## omega 0.6491118 ## omega2 0.6491118 ## omega3 0.6567407 ## avevar 0.4012226 5.5 Regressionsanalyse Im abschließenden Kapitel zur multivarianten Datenanalyse behandeln wir noch Möglichkeiten der Regressionsanalysen, verschiedene Möglichkeiten zum Testen der Modellgüte sowie der grafischen Aufbereitung der Modelle. Packet Funktion Verwendung stats lm() lineare Regressionsmodelle parameters model_parameters() Modellparameter ausgeben stats anova() F-Tests auf Gesamtsignifikanz performance model_performance() Modellgüte performance compare_performance() Vergleich der Modellgüte texreg screenreg() tabellarischer Modellvergleich sjplot plot_model() grafische Darstellungen von Regressionsmodellen sjplot plot_models() grafischer Modellvergleich sjplot check_model() 6 Grafiken zur Modellgüte stats glm() logistische Regressionsmodelle (u.A.) Lm() Ein lineares Regressionsmodell können wir mit der lm() Funktion berechnen. Syntax: # Ohne Pipe lm(av ~ uv1 + uv2*uv3 + uv4 + uv1:uv4, datensatz, weights = gewicht) # Mit Pipe # Nicht gut zu handhaben! Zur Veranschaulichung ist im Beispiel dazu die Datenaufbereitung aufgeführt, dessen Ergebnis im neuen Datensatz ds gespeichert wird. Anschließend wird das Nullmodell spezifiziert, mit dem unser Modell verglichen werden soll. Dann folgt die Spezifikation unserer Modelle, ohne (model1) und mit Interaktion (model2.1 und model2.2, unterschiedliche Schreibweise). Beispielcode: # Datensatz erstellen ds &lt;- allbus2018 %&gt;% select(im19, sex, age, educ, di08, wghtpew) %&gt;% # Z-Standardisierung Einkommen mutate(wMean = weighted_mean(di08, weights = wghtpew), wSD = weighted_sd(di08, weights = wghtpew), zEinkommen = (di08-wMean)/wSD) %&gt;% # Rekodierung Geschlecht und Bildung mutate(sex = rec(sex, rec = &quot;1=1 [Mann]; 2=0 [Frau]&quot;), bildung = rec(educ, rec = &quot;1:2=1 [niedrig]; 3=2 [mittel]; 4:5=3 [hoch]; else=NA&quot;)) %&gt;% # Konvertierung in Faktor Geschlecht und Bildung to_label(sex, bildung) %&gt;% # Refrenzkategorie Bildung auf mittel ref_lvl(bildung, lvl = 2) %&gt;% # Löschung NA drop_na() # Nullmodell nullmodel &lt;- lm(im19 ~ 1, ds, weights = wghtpew) summary(nullmodel) #&gt; #&gt; Call: #&gt; lm(formula = im19 ~ 1, data = ds, weights = wghtpew) #&gt; #&gt; Weighted Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -1.653 -0.554 0.366 0.545 1.644 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 2.50410 0.01722 145.4 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.9323 on 2947 degrees of freedom # Modellierung erstes Modell model1 &lt;- lm(im19 ~ sex + age + bildung + zEinkommen, ds, weights = ds$wghtpew) summary(model1) #&gt; #&gt; Call: #&gt; lm(formula = im19 ~ sex + age + bildung + zEinkommen, data = ds, #&gt; weights = ds$wghtpew) #&gt; #&gt; Weighted Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.0162 -0.6219 0.1575 0.5760 2.0835 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 2.708765 0.063434 42.702 &lt; 2e-16 *** #&gt; sexMann -0.179526 0.033839 -5.305 1.21e-07 *** #&gt; age -0.002105 0.001042 -2.020 0.043423 * #&gt; bildungniedrig -0.265591 0.046215 -5.747 1.00e-08 *** #&gt; bildunghoch 0.153043 0.040719 3.759 0.000174 *** #&gt; zEinkommen -0.021174 0.017799 -1.190 0.234299 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.9113 on 2942 degrees of freedom #&gt; Multiple R-squared: 0.04614, Adjusted R-squared: 0.04452 #&gt; F-statistic: 28.46 on 5 and 2942 DF, p-value: &lt; 2.2e-16 # Prüfung auf Interaktioneffekt zwischen Geschlecht und zEinkommen model2.1 &lt;- lm(im19 ~ zEinkommen + sex + age + bildung + zEinkommen:sex, ds, weights = ds$wghtpew) summary(model2.1) #&gt; #&gt; Call: #&gt; lm(formula = im19 ~ zEinkommen + sex + age + bildung + zEinkommen:sex, #&gt; data = ds, weights = ds$wghtpew) #&gt; #&gt; Weighted Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.0060 -0.6160 0.1637 0.5931 2.1158 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 2.707154 0.063416 42.689 &lt; 2e-16 *** #&gt; zEinkommen 0.012940 0.025846 0.501 0.616637 #&gt; sexMann -0.179216 0.033826 -5.298 1.26e-07 *** #&gt; age -0.002042 0.001042 -1.960 0.050066 . #&gt; bildungniedrig -0.265051 0.046198 -5.737 1.06e-08 *** #&gt; bildunghoch 0.154179 0.040707 3.787 0.000155 *** #&gt; zEinkommen:sexMann -0.061611 0.033856 -1.820 0.068896 . #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.9109 on 2941 degrees of freedom #&gt; Multiple R-squared: 0.04722, Adjusted R-squared: 0.04527 #&gt; F-statistic: 24.29 on 6 and 2941 DF, p-value: &lt; 2.2e-16 # ODER model2.2 &lt;- lm(im19 ~ zEinkommen*sex + age + bildung, ds, weights = ds$wghtpew) summary(model2.2) #&gt; #&gt; Call: #&gt; lm(formula = im19 ~ zEinkommen * sex + age + bildung, data = ds, #&gt; weights = ds$wghtpew) #&gt; #&gt; Weighted Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.0060 -0.6160 0.1637 0.5931 2.1158 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 2.707154 0.063416 42.689 &lt; 2e-16 *** #&gt; zEinkommen 0.012940 0.025846 0.501 0.616637 #&gt; sexMann -0.179216 0.033826 -5.298 1.26e-07 *** #&gt; age -0.002042 0.001042 -1.960 0.050066 . #&gt; bildungniedrig -0.265051 0.046198 -5.737 1.06e-08 *** #&gt; bildunghoch 0.154179 0.040707 3.787 0.000155 *** #&gt; zEinkommen:sexMann -0.061611 0.033856 -1.820 0.068896 . #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.9109 on 2941 degrees of freedom #&gt; Multiple R-squared: 0.04722, Adjusted R-squared: 0.04527 #&gt; F-statistic: 24.29 on 6 and 2941 DF, p-value: &lt; 2.2e-16 Model_parameters() Mit der Funktion model_parameters können wir eine tabellarische Übersicht der Modellparameter erstellen. Mit der plot Funktion erstellen wir eine simple übersichtliche Grafik des Modells (Koeffizienten mit Konfidenzintervall). Beispielcode: # Modellparameter in übersichtlicher Darstellung m1Parameter &lt;- model_parameters(model2.1) m1Parameter #&gt; Parameter | Coefficient | SE | 95% CI | t(2941) | p #&gt; ------------------------------------------------------------------------------------ #&gt; (Intercept) | 2.71 | 0.06 | [ 2.58, 2.83] | 42.69 | &lt; .001 #&gt; zEinkommen | 0.01 | 0.03 | [-0.04, 0.06] | 0.50 | 0.617 #&gt; sex [Mann] | -0.18 | 0.03 | [-0.25, -0.11] | -5.30 | &lt; .001 #&gt; age | -2.04e-03 | 1.04e-03 | [ 0.00, 0.00] | -1.96 | 0.050 #&gt; bildung [niedrig] | -0.27 | 0.05 | [-0.36, -0.17] | -5.74 | &lt; .001 #&gt; bildung [hoch] | 0.15 | 0.04 | [ 0.07, 0.23] | 3.79 | &lt; .001 #&gt; zEinkommen * sex [Mann] | -0.06 | 0.03 | [-0.13, 0.00] | -1.82 | 0.069 #&gt; #&gt; Uncertainty intervals (equal-tailed) and p values (two-tailed) computed using a #&gt; Wald t-distribution approximation. plot(m1Parameter) Anova() Um zu überprüfen, ob unsere Modelle eine Verbesserung der Anpassung an die Daten darstellen (im Vergleich zum Nullmodell oder unter einander) verwenden wir die anvoa() Funktion. Beispielcode: # F-Tests auf Gesamtsignifikanz (Anpassung an Daten) anova(nullmodel, model1) #&gt; Analysis of Variance Table #&gt; #&gt; Model 1: im19 ~ 1 #&gt; Model 2: im19 ~ sex + age + bildung + zEinkommen #&gt; Res.Df RSS Df Sum of Sq F Pr(&gt;F) #&gt; 1 2947 2561.4 #&gt; 2 2942 2443.2 5 118.2 28.465 &lt; 2.2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(model1, model2.1) #&gt; Analysis of Variance Table #&gt; #&gt; Model 1: im19 ~ sex + age + bildung + zEinkommen #&gt; Model 2: im19 ~ zEinkommen + sex + age + bildung + zEinkommen:sex #&gt; Res.Df RSS Df Sum of Sq F Pr(&gt;F) #&gt; 1 2942 2443.2 #&gt; 2 2941 2440.5 1 2.748 3.3116 0.0689 . #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Model_performance() Mit der model_performance () Funktion lassen wir uns verschiedene Kennzahlen ausgeben, um die Modellgüte zu beurteilen. Beispielcode: # Modellgüte nach verschiedenen Kennzahlen model_performance(model2.1) #&gt; # Indices of model performance #&gt; #&gt; AIC | BIC | R2 | R2 (adj.) | RMSE | Sigma #&gt; ------------------------------------------------------- #&gt; 8023.960 | 8071.871 | 0.047 | 0.045 | 0.926 | 0.911 Compare_performance() Die Kannzahlen der model_performance() Funktion könen wir uns mit der compare_performance() Funktion tabellarisch auch für mehrere Modell ausgeben lassen, sodass wir diese im direkten Vergleich betrachten können. Dieser berechnete Modellvergleich kann mit der plot() Funktion auch grafisch ausgegeben werden. Beispielcode: # Vergleich von Modellgüte cperf &lt;- compare_performance(model1, model2.1) cperf #&gt; # Comparison of Model Performance Indices #&gt; #&gt; Name | Model | AIC | AIC weights | BIC | BIC weights | R2 | R2 (adj.) | RMSE | Sigma #&gt; ------------------------------------------------------------------------------------------------------ #&gt; model1 | lm | 8025.277 | 0.341 | 8067.199 | 0.912 | 0.046 | 0.045 | 0.926 | 0.911 #&gt; model2.1 | lm | 8023.960 | 0.659 | 8071.871 | 0.088 | 0.047 | 0.045 | 0.926 | 0.911 plot(cperf) Screenreg() Mit der screenreg() Funktion können wir uns mehrere vollständige Modelle mit verschiedenen Kennzahlen tabellarisch ausgeben lassen und direkt mit einander vergleichen. library(texreg) Beispielcode: # Tabellarische Darstellung im Modellvergleich mit Kennzahlen der Modellgüte screenreg(list(model1, model2.1), single.row = T) #&gt; #&gt; ========================================================== #&gt; Model 1 Model 2 #&gt; ---------------------------------------------------------- #&gt; (Intercept) 2.71 (0.06) *** 2.71 (0.06) *** #&gt; sexMann -0.18 (0.03) *** -0.18 (0.03) *** #&gt; age -0.00 (0.00) * -0.00 (0.00) #&gt; bildungniedrig -0.27 (0.05) *** -0.27 (0.05) *** #&gt; bildunghoch 0.15 (0.04) *** 0.15 (0.04) *** #&gt; zEinkommen -0.02 (0.02) 0.01 (0.03) #&gt; zEinkommen:sexMann -0.06 (0.03) #&gt; ---------------------------------------------------------- #&gt; R^2 0.05 0.05 #&gt; Adj. R^2 0.04 0.05 #&gt; Num. obs. 2948 2948 #&gt; ========================================================== #&gt; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05 Plot_model() Die plot_model() Funktion bietet sowohl die Möglichkeit sich die Regressionkoeffizienten sowie die Konfidenzintervalle des Gesamtmodells grafisch ausgeben zu lassen als auch die Schätzwärte einzelner Prädiktoren. Die folgenden Beispiele illustieren dies anhand des berechneten model2.1. Beispielcode: # Regressionskoeffizienten plot_model(model2.1) # Schätzwerte (predicted values) plot_model(model2.1, type = &quot;pred&quot;) #&gt; $zEinkommen #&gt; #&gt; $sex #&gt; #&gt; $age #&gt; #&gt; $bildung # Gruppierung von Effekten plot_model(model2.1, type = &quot;pred&quot;, terms = c(&quot;zEinkommen&quot;,&quot;bildung&quot;)) # Interaktion plot_model(model2.1, type = &quot;int&quot;) Plot_models() Eine grafische Lösung des Modellvergleichs haben wir mit der plot_models() Funktion. Auch in dieser Darstellung werden Regressionskoeffizienten und Konfidenzintervalle ausgegeben. Beispielcode: # Vergleich Regressionskoeffizienten plot_models(model1, model2.1) Check_model() Zur visuellen Überprüfung der Modellannahmen können wir uns mit check_model() sechs Grafiken ausgeben lassen (u. A. Homogenität der Varianz, Kollinearität). Beispielcode: # Annahmenprüfung check_model(model2.1) Glm() Für die Analyse logistischer Regressionsmodelle verwenden wir die glm Funktion. Diese erlaubt mit dem Argument family=binomial die Analyse von Regressionsmodellen mit einer dichotomen abhängigen Variable. Syntax: # Ohne Pipe glm(av ~ uv1 + uv2*uv3 + uv4 + uv1:uv4, family = binomial, datensatz, weights = gewicht) # Mit Pipe # Nicht gut zu handhaben! Das Vorgehen im Beispiel entspricht dabei den Beispielen der Funktion lm() weiter oben. Lediglich die abhängige Variable wurde ausgetauscht - hier wird pp26 als abhängige Variable verwendet. Diese Variable misst, ob die befragte Person sich schon einmal bei Versammlungen an öffentlichen Diskussionen beteiligt hat. Beispielcode: # Datensatz erstellen ds &lt;- allbus2018 %&gt;% select(pp26, sex, age, educ, di08, wghtpew) %&gt;% # Rekodierung AV: Partizipation an öffent. Diskussion und Bildung mutate(partDisk = rec(pp26, rec = &quot;1=1 [ja]; 0=0 [nein]; else=NA&quot;)) %&gt;% # Z-Standardisierung Einkommen mutate(wMean = weighted_mean(di08, weights = wghtpew), wSD = weighted_sd(di08, weights = wghtpew), zEinkommen = (di08-wMean)/wSD) %&gt;% # Rekodierung Geschlecht und Bildung mutate(sex = rec(sex, rec = &quot;1=1 [Mann]; 2=0 [Frau]&quot;), bildung = rec(educ, rec = &quot;1:2=1 [niedrig]; 3=2 [mittel]; 4:5=3 [hoch]; else=NA&quot;)) %&gt;% # Konvertierung in Faktor Geschlecht und Bildung to_label(sex, bildung) %&gt;% # Refrenzkategorie Bildung auf mittel ref_lvl(bildung, lvl = 2) %&gt;% # Löschung NA drop_na() # Nullmodell nullmodel2 &lt;- glm(pp26 ~ 1, family = binomial, ds, weights = wghtpew) #&gt; Warning in eval(family$initialize): non-integer #successes in a binomial glm! summary(nullmodel2) #&gt; #&gt; Call: #&gt; glm(formula = pp26 ~ 1, family = binomial, data = ds, weights = wghtpew) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -1.0090 -1.0090 -0.6776 1.0785 1.6058 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -0.6460 0.0388 -16.65 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 3789.2 on 2955 degrees of freedom #&gt; Residual deviance: 3789.2 on 2955 degrees of freedom #&gt; AIC: 3784.2 #&gt; #&gt; Number of Fisher Scoring iterations: 4 # Modellierung erstes Modell model3 &lt;- glm(pp26 ~ sex + age + bildung + zEinkommen, family = binomial, ds, weights = ds$wghtpew) #&gt; Warning in eval(family$initialize): non-integer #successes in a binomial glm! summary(model3) #&gt; #&gt; Call: #&gt; glm(formula = pp26 ~ sex + age + bildung + zEinkommen, family = binomial, #&gt; data = ds, weights = ds$wghtpew) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.0424 -0.9312 -0.6964 1.1712 2.1315 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -1.565736 0.153664 -10.189 &lt; 2e-16 *** #&gt; sexMann 0.393326 0.079867 4.925 8.45e-07 *** #&gt; age 0.012294 0.002484 4.949 7.46e-07 *** #&gt; bildungniedrig -0.375874 0.113258 -3.319 0.000904 *** #&gt; bildunghoch 0.354192 0.094785 3.737 0.000186 *** #&gt; zEinkommen 0.167601 0.042706 3.925 8.69e-05 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 3789.2 on 2955 degrees of freedom #&gt; Residual deviance: 3665.6 on 2950 degrees of freedom #&gt; AIC: 3670.8 #&gt; #&gt; Number of Fisher Scoring iterations: 4 # Prüfung auf Interaktioneffekt zwischen Geschlecht und zEinkommen model4.1 &lt;- glm(pp26 ~ zEinkommen + sex + age + bildung + zEinkommen:sex, family = binomial, ds, weights = ds$wghtpew) #&gt; Warning in eval(family$initialize): non-integer #successes in a binomial glm! summary(model4.1) #&gt; #&gt; Call: #&gt; glm(formula = pp26 ~ zEinkommen + sex + age + bildung + zEinkommen:sex, #&gt; family = binomial, data = ds, weights = ds$wghtpew) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -1.8231 -0.9293 -0.6897 1.1482 2.0970 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -1.555180 0.153425 -10.136 &lt; 2e-16 *** #&gt; zEinkommen 0.074123 0.059512 1.246 0.212942 #&gt; sexMann 0.383025 0.080032 4.786 1.70e-06 *** #&gt; age 0.012126 0.002485 4.879 1.07e-06 *** #&gt; bildungniedrig -0.375851 0.113225 -3.320 0.000902 *** #&gt; bildunghoch 0.350101 0.094669 3.698 0.000217 *** #&gt; zEinkommen:sexMann 0.174405 0.081048 2.152 0.031408 * #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 3789.2 on 2955 degrees of freedom #&gt; Residual deviance: 3660.9 on 2949 degrees of freedom #&gt; AIC: 3666.3 #&gt; #&gt; Number of Fisher Scoring iterations: 4 # ODER model4.2 &lt;- glm(pp26 ~ zEinkommen*sex + age + bildung, family = binomial, ds, weights = ds$wghtpew) #&gt; Warning in eval(family$initialize): non-integer #successes in a binomial glm! summary(model4.2) #&gt; #&gt; Call: #&gt; glm(formula = pp26 ~ zEinkommen * sex + age + bildung, family = binomial, #&gt; data = ds, weights = ds$wghtpew) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -1.8231 -0.9293 -0.6897 1.1482 2.0970 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -1.555180 0.153425 -10.136 &lt; 2e-16 *** #&gt; zEinkommen 0.074123 0.059512 1.246 0.212942 #&gt; sexMann 0.383025 0.080032 4.786 1.70e-06 *** #&gt; age 0.012126 0.002485 4.879 1.07e-06 *** #&gt; bildungniedrig -0.375851 0.113225 -3.320 0.000902 *** #&gt; bildunghoch 0.350101 0.094669 3.698 0.000217 *** #&gt; zEinkommen:sexMann 0.174405 0.081048 2.152 0.031408 * #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 3789.2 on 2955 degrees of freedom #&gt; Residual deviance: 3660.9 on 2949 degrees of freedom #&gt; AIC: 3666.3 #&gt; #&gt; Number of Fisher Scoring iterations: 4 "],["grafiken-erstellen.html", "6 Grafiken erstellen 6.1 Schritt 1: Plot-Objekt erstellen 6.2 Schritt 2: Aesthetic mapping 6.3 Schritt 3: Schichten (“Layer”) hinzufügen 6.4 Verschiedene Grafiken für verschiedene Datentypen", " 6 Grafiken erstellen In diesem Kapitel werden wir lernen, welche Werkzeuge uns R zur Erstellung von Grafiken zur Verfügung stellt und wie uns das Paket ggplot2 aus dem tidyverse ermöglicht durch explorative Datenanalyse verborgene Zusammenhänge zu entdecken, sowie Resultate darzustellen und zu kommunizieren. Im Gegensatz zum ursprünglichen Grafiksystem R Base Graphics, welches auf Base R aufsetzt, basiert ggplot2 auf der intuitiven Syntax Grammar of Graphics. Hiermit lassen sich durch eleganten, flexiblen und konsistenten Code sehr komplexe Grafiken erstellen und nahtlos mit den Funktionen des tidyverse verbinden. Achtung! ggplot2 benötigt Datensätze im long Format. (siehe hierzu: R for Data Science - Tidy Data) Da Grafiken mit ggplot2 immer nach dem gleichen Prinzip erstellt werden, ergeben sich immer folgende Schritte: Schritt 1: Erstellung eines Objekts mit der Funktion ggplot(). Schritt 2: Definition der Datengrundlage mit dem ersten Argument data = datensatz. Schritt 3: Definition von “aesthetic mappings,” also der Wahl einer Variable für die x-Achse: x = var1, y-Achse: y = var2, Gewichtung: weight = gewicht und zur Gruppierung der Daten: group bzw. colour, shape, linetype oder fill = var3 über die Funktion mapping = aes(). Schritt 4: Definition verschiedener “Layer” bzw. “Schichten.” Hierbei definieren wir, was dargestellt werden soll - z.B. ein Histogramm oder Linien. Dabei wird uns in der Anzahl an Schichten kein Limit gesetzt. Die Funktionen beginnen dabei immer mit dem Präfix geom_, z.B. geom_bar() und werden über den Operator + hinzugefügt. Im Verlauf des Kapitels werden wir die einzelnen Schritte noch einmal vertiefen, gleichwohl wollen wir mit eingängigen Beispiel beginnen. Beispiel 1: Grundlage unserer Grafik und damit erstes Argument der Funktion ggplot() ist der allbus2018. Aufbauend definieren wir in der Funktion aes(), welche Variablen in unserer Grafik auf welcher Achse abgebildet werden sollen. Da wir lediglich eine Abbildung der Häufigkeitsverteilung der Variable im19 anstreben, müssen wir nur das Argument x = spezifizieren. Anschließend wird über das Argument weight = eine Gewichtung vorgenommen. Damit haben wir unser Fundament gelegt. Über den Operator + fügen wir nun weitere Schichte hinzu. Als erstes “Layer” fügen wir über die Funktion geom_bar das gewünschte Balkendiagramm hinzu. Die Funktion führt dabei voreingestellt über das Argument stat = \"count\" einen Zählbefehl aus, welcher uns in Folge die Häufigkeitswerte der einzelnen Ausprägungen ausgibt. Als weitere Argumente definieren wir noch die Farbe der Balken mit fill = und das Auslassen fehlender Werte über na.rm = T. Als Endpunkt fügen wir noch eine zweite Schicht hinzu, die uns mit der Funktion labs() ermöglicht alle Achsen frei zu Beschriften. Fertig! allbus2018 %&gt;% ggplot(aes(x = im19, weight = wghtpew)) + geom_bar(fill = &quot;steelblue&quot;, na.rm = T) + labs(y = &quot;Anzahl&quot;, title = &quot;Häufigkeitsverteilung der Variable im19&quot;) Die folgende Grafik erweitert unsere Fähigkeiten zusätzlich um vier Punkte. Durch die nahtlose Integration der Funktionen des tidyverse und strengejacke ist es uns möglich innerhalb eines Objekts sowohl die Daten zu manipulieren, als auch diese in die nachfolgende Grafik einzubeziehen. So war es in unserem Beispiel von Nöten die Grupperungsvariable sex (Geschlecht) erst zu einem Faktor zu konvertieren, um sie nachstehend nutzen zu können - Funktion to_label(). Weiterhin haben wir das Nettoeinkommen der Befragten mit dem Argument y = auf der y-Achse abgebildet und das Geschlecht der Befragten über das Argument colour = als Gruppierungvariable gewählt. Damit erlaubt uns ggplot() die einzelnen Datenpunkte farblich hervorzuheben, sowie über die Funktion stat_summary() einen Mittelwertvergleich zwischen beiden Gruppen über ein Liniendiagramm abzubilden. allbus2018 %&gt;% to_label(sex) %&gt;% ggplot(aes(x = age, y = inc, colour = sex, weight = wghtpew)) + geom_point(na.rm = T, alpha = 0.1) + stat_summary(fun = &quot;mean&quot;, geom = &quot;line&quot;, na.rm = T, size = 0.8) + labs(x = &quot;Alter&quot;, y = &quot;Einkommen&quot;, colour = &quot;Geschlecht&quot;, title = &quot;Mittleres Einkommen nach Alter und Geschlecht&quot;) Nun wollen wir uns die einzelnen Schritte nochmal im Detail ansehen. 6.1 Schritt 1: Plot-Objekt erstellen Wir beginnen mit einem Datensatz und erstellen ein Plot-Objekt mit der Funktion ggplot(). Als erstes Argument fügen wir unseren Datensatz ein data = datensatz. Hierbei bestehen zwei Möglichkeiten der Umsetzung. # Ohne Pipe g &lt;- ggplot(data = allbus2018) # Mit Pipe g &lt;- allbus2018 %&gt;% ggplot() 6.2 Schritt 2: Aesthetic mapping Im zweiten Schritt definieren wir das zweite Argument mapping = über die Funktion aes() - “aesthetic mappings.” Damit bestimmen wir welche Variablen benutzt werden sollen, um die Daten darzustellen. Im Folgenden wollen wir ergründen, inwieweit das Geschlecht der Befragten einen Einfluss auf ihr individuelles Nettoeinkommen (inc) hat. So definieren wir sex als Variable auf der x-Achse mit x = sex und die Variable inc mit y = inc auf der y-Achse. Da wir Gesamtdeutschland betrachten wollen, definieren wir noch mit weight = wghtpew das nötige Designgewicht. Der vorläufiger Befehl lautet entsprechend: mapping = aes(x = sex, y = im21, weight = wghtpew). Zusätzlich erlaubt die Funktion aes() weitere Anpassungen über fill =, colour =, shape =, linetype = und group =. Diese Argumente helfen zum Einen der Gruppierungsvariable auf der x-Achse eine Farbe, Form oder Zugehörigkeit zuzuweisen, zum Anderen lässt sich damit aber auch eine dritte Variable (z) als Gruppierungsvariable (siehe Beispiel 2) zuweisen. In unserem Beispiel wollen wir, dass die beiden Ausprägungsmerkmale von Geschlecht verschiedene Farben zugewiesen bekommen und die nachfolgenden Objekte entsprechend ausgefülllt werden. Der fertige Befehl lautet damit: mapping = aes(x = sex, y = inc, weight = wghtpew, fill = sex, colour = sex). Das Argument colour = ist folglich ein Attribut für Linien und Punkte; das Argument fill = ist ein Attribut für Flächen. Wichtig! Wenn wir die Funktion aes() innerhalb der Funktion ggplot() definieren, gelten sie für alle Schichten, d.h. für alle Elemente der Grafik. Wir können später die “mappings” auch für jede Schicht einzeln definieren und damit auf verschiedene Datensätze zugreifen, oder andere Variablen verwenden. g &lt;- allbus2018 %&gt;% to_label(sex) %&gt;% ggplot(mapping = aes( x = sex, y = inc, weight = wghtpew, fill = sex, colour = sex )) g ist damit ein “leeres” Plot-Objekt, dass noch nichts anzeigt, da wir noch keine “Layer” definiert haben. Das Objekt ist damit ein ggplot2-Objekt, welches im R-Studio Fenster Plots ausgegeben werden kann. Wir sehen folglich ein Grafikgerüst mit der richtigen Achsenzuweisung. g 6.3 Schritt 3: Schichten (“Layer”) hinzufügen Dem Plot-Objekt g wollen wir nun mit den Funktionstypen geom_ weitere Schichten beifügen. So addieren wir mit dem + Operator einfach ein weiteres “Layer” - g + geom_. 6.3.1 Punktdiagramm Als erstes möchten wir die einzelnen Beobachtungen als Datenpunkte abgetragen haben. Hierbei können wir entweder unsere Ausgangssytax optimieren, oder das Objekt g einfach erweitern. Anmerkung: Mit dem Argument na.rm = T werden fehlende Werte in den Schichten außen vor gelassen und wir verhindern eine Warnmeldung. # Ausgangssyntax optimieren allbus2018 %&gt;% to_label(sex) %&gt;% ggplot(mapping = aes(x = sex, y = inc, weight = wghtpew, fill = sex, colour = sex)) + geom_point(na.rm = T) # Objekt erweitern g + geom_point(na.rm = T) Wollen wir das Überlagern der Datenpunkte (overplotting) verhindern, können wir auch auf die Funktion geom_jitter() zurückgreifen. In Anwendung werden uns die Punkte nebeneinander gezeigt. g + geom_jitter(na.rm = T) Mit dem Argument width = können wir zusätzlich bestimmen, wie breit die Streuung der Punkte sein soll. g + geom_jitter(width = 0.5, na.rm = T) Weitere Argumente sind size = für die größe der Punkte und alpha = zur Bestimmung der Transparenz. Zudem lassen sich wie gehabt im Fenster Help über den Befehl ?geom_jitter in der Konsole weitere Argumente einsehen. g + geom_jitter(size = 1, alpha = 0.3, na.rm = T) 6.3.2 Zentrale Tendenz und Streuung abbilden Zur Darstellung der zentralen Tendenz und Streuung gibt uns ggplot2 zusätzliche Schichten an die Hand. Genannt seien hier geom_boxplot() zur Darstellung von Boxplot-Diagrammen und geom_violin() für Violin-Diagramme. g + geom_boxplot(na.rm = T) In einem Boxplot wird der Median abgetragen, d.h. das Rechteck repräsentiert die mittleren 50% und die Striche (“whiskers”) zeigen den 1,5 * IQR (Interquantilbereich). Die einzelnen Punkte stellen Ausreisser dar. Wollen wir den Median sehen, müssen wir das Argument fill = sex weglassen. g &lt;- allbus2018 %&gt;% to_label(sex) %&gt;% ggplot(mapping = aes(x = sex, y = inc, weight = wghtpew, colour = sex)) g + geom_boxplot(na.rm = T) Violin-Diagramme sind Boxplot-Diagrammen sehr ähnlichen, wenngleich sie nicht die Quantile, sondern ein “kernel density estimate” zeigen - d.h. eine Abbildung der Kerndichte. Hier bietet sich das Argument fill = sex zudem ideal an. g &lt;- allbus2018 %&gt;% to_label(sex) %&gt;% ggplot(mapping = aes(x = sex, y = inc, weight = wghtpew, fill = sex)) g + geom_violin(na.rm = T) Stellen wir fest, dass die Farbgebung immer wieder neu angepasst werden muss, sollten wir das mapping entsprechend anpassen. # Ausgang g &lt;- allbus2018 %&gt;% to_label(sex) %&gt;% ggplot(mapping = aes(x = sex, y = inc, weight = wghtpew)) # Boxplot g + geom_boxplot(aes(colour = sex), na.rm = T) # Violin g + geom_violin(aes(fill = sex), na.rm = T) 6.3.3 Mehrere Schichten kombinieren So ist es uns auch möglich mehrere “Layer” zu kombinieren. So müssen wir lediglich mehrere geom_ Funktionen mit dem + Operator verbinden: g + geom_violin(aes(fill = sex), na.rm = T) + geom_jitter(aes(colour = sex), alpha = 0.2, width = 0.4, na.rm = T) 6.4 Verschiedene Grafiken für verschiedene Datentypen "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
